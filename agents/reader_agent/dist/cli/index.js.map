{"version":3,"sources":["../../src/cli/index.ts","../../src/client.ts","../../src/scraper.ts","../../src/formatters/markdown.ts","../../src/utils/content-cleaner.ts","../../src/utils/metadata-extractor.ts","../../src/utils/url-helpers.ts","../../src/utils/logger.ts","../../src/utils/robots-parser.ts","../../src/types.ts","../../src/engines/types.ts","../../src/engines/errors.ts","../../src/engines/http/index.ts","../../src/engines/tlsclient/index.ts","../../src/cloudflare/detector.ts","../../src/cloudflare/handler.ts","../../src/engines/hero/index.ts","../../src/engines/orchestrator.ts","../../src/crawler.ts","../../src/utils/rate-limiter.ts","../../src/browser/pool.ts","../../src/proxy/config.ts","../../src/browser/hero-config.ts","../../src/daemon/server.ts","../../src/daemon/client.ts"],"sourcesContent":["#!/usr/bin/env node\n/**\n * Reader CLI\n *\n * Command-line interface for web scraping with Cloudflare bypass.\n *\n * @example\n * # Start daemon (once)\n * npx reader start --pool-size 5\n *\n * # Scrape a single URL (auto-detects daemon)\n * npx reader scrape https://example.com\n *\n * # Scrape multiple URLs with markdown and text output\n * npx reader scrape https://example.com https://example.org -f markdown,text\n *\n * # Crawl a website\n * npx reader crawl https://example.com -d 2 -m 20\n *\n * # Force standalone mode (bypass daemon)\n * npx reader scrape https://example.com --standalone\n *\n * # Check daemon status\n * npx reader status\n *\n * # Stop daemon\n * npx reader stop\n */\n\nimport { Command } from \"commander\";\nimport { ReaderClient } from \"../client\";\nimport { DaemonServer, DaemonClient, isDaemonRunning, getDaemonInfo, DEFAULT_DAEMON_PORT } from \"../daemon\";\nimport { readFileSync, writeFileSync } from \"fs\";\nimport { dirname, join } from \"path\";\nimport { fileURLToPath } from \"url\";\n\n// Get version from package.json\nconst __dirname = dirname(fileURLToPath(import.meta.url));\nconst pkg = JSON.parse(readFileSync(join(__dirname, \"../../package.json\"), \"utf-8\"));\n\nconst program = new Command();\n\nprogram\n  .name(\"reader\")\n  .description(\n    \"Production-grade web scraping engine for LLMs. Clean markdown output, ready for your agents.\"\n  )\n  .version(pkg.version);\n\n// =============================================================================\n// Daemon Commands\n// =============================================================================\n\nprogram\n  .command(\"start\")\n  .description(\"Start the reader daemon server\")\n  .option(\"-p, --port <n>\", `Port to listen on (default: ${DEFAULT_DAEMON_PORT})`, String(DEFAULT_DAEMON_PORT))\n  .option(\"--pool-size <n>\", \"Browser pool size\", \"5\")\n  .option(\"--show-chrome\", \"Show browser windows for debugging\")\n  .option(\"-v, --verbose\", \"Enable verbose logging\")\n  .action(async (options) => {\n    const port = parseInt(options.port, 10);\n\n    // Check if daemon is already running\n    if (await isDaemonRunning(port)) {\n      console.error(`Error: Daemon is already running on port ${port}`);\n      process.exit(1);\n    }\n\n    const daemon = new DaemonServer({\n      port,\n      poolSize: parseInt(options.poolSize, 10),\n      verbose: options.verbose || false,\n      showChrome: options.showChrome || false,\n    });\n\n    try {\n      await daemon.start();\n      console.log(`Reader daemon started on port ${port} with pool size ${options.poolSize}`);\n      console.log(`Use \"npx reader stop\" to stop the daemon`);\n\n      // Keep process running\n      process.on(\"SIGINT\", async () => {\n        console.log(\"\\nShutting down daemon...\");\n        await daemon.stop();\n        process.exit(0);\n      });\n\n      process.on(\"SIGTERM\", async () => {\n        await daemon.stop();\n        process.exit(0);\n      });\n    } catch (error: any) {\n      console.error(`Error: ${error.message}`);\n      process.exit(1);\n    }\n  });\n\nprogram\n  .command(\"stop\")\n  .description(\"Stop the running reader daemon\")\n  .option(\"-p, --port <n>\", `Daemon port (default: ${DEFAULT_DAEMON_PORT})`, String(DEFAULT_DAEMON_PORT))\n  .action(async (options) => {\n    const port = parseInt(options.port, 10);\n    const client = new DaemonClient({ port });\n\n    try {\n      if (!(await client.isRunning())) {\n        console.log(\"Daemon is not running\");\n        return;\n      }\n\n      await client.shutdown();\n      console.log(\"Daemon stopped\");\n    } catch (error: any) {\n      console.error(`Error: ${error.message}`);\n      process.exit(1);\n    }\n  });\n\nprogram\n  .command(\"status\")\n  .description(\"Check daemon status\")\n  .option(\"-p, --port <n>\", `Daemon port (default: ${DEFAULT_DAEMON_PORT})`, String(DEFAULT_DAEMON_PORT))\n  .action(async (options) => {\n    // First check PID file\n    const daemonInfo = await getDaemonInfo();\n\n    if (!daemonInfo) {\n      console.log(\"Daemon is not running\");\n      return;\n    }\n\n    // Use port from options if specified, otherwise from PID file\n    const port = options.port ? parseInt(options.port, 10) : daemonInfo.port;\n\n    // Verify it's actually running by connecting\n    const client = new DaemonClient({ port });\n    try {\n      const status = await client.status();\n      console.log(\"Daemon is running:\");\n      console.log(`  Port: ${status.port}`);\n      console.log(`  PID: ${status.pid}`);\n      console.log(`  Pool size: ${status.poolSize}`);\n      console.log(`  Uptime: ${Math.round(status.uptime / 1000)}s`);\n    } catch {\n      console.log(\"Daemon is not running (stale PID file)\");\n    }\n  });\n\n// =============================================================================\n// Scrape Command\n// =============================================================================\n\nprogram\n  .command(\"scrape <urls...>\")\n  .description(\"Scrape one or more URLs\")\n  .option(\n    \"-f, --format <formats>\",\n    \"Content formats to include (comma-separated: markdown,html)\",\n    \"markdown\"\n  )\n  .option(\"-o, --output <file>\", \"Output file (stdout if omitted)\")\n  .option(\"-c, --concurrency <n>\", \"Parallel requests\", \"1\")\n  .option(\"-t, --timeout <ms>\", \"Request timeout in milliseconds\", \"30000\")\n  .option(\"--proxy <url>\", \"Proxy URL (e.g., http://user:pass@host:port)\")\n  .option(\"--user-agent <string>\", \"Custom user agent string\")\n  .option(\"--batch-timeout <ms>\", \"Total timeout for entire batch operation\", \"300000\")\n  .option(\"--show-chrome\", \"Show browser window for debugging\")\n  .option(\"--standalone\", \"Force standalone mode (bypass daemon)\")\n  .option(\"-p, --port <n>\", `Daemon port (default: ${DEFAULT_DAEMON_PORT})`, String(DEFAULT_DAEMON_PORT))\n  .option(\"-v, --verbose\", \"Enable verbose logging\")\n  .option(\"--no-main-content\", \"Disable main content extraction (include full page)\")\n  .option(\"--include-tags <selectors>\", \"CSS selectors for elements to include (comma-separated)\")\n  .option(\"--exclude-tags <selectors>\", \"CSS selectors for elements to exclude (comma-separated)\")\n  .option(\"--engine <name>\", \"Force a specific engine (http, tlsclient, hero)\")\n  .option(\"--skip-engine <names>\", \"Skip specific engines (comma-separated: http,tlsclient,hero)\")\n  .action(async (urls: string[], options) => {\n    const port = parseInt(options.port, 10);\n    const useStandalone = options.standalone || false;\n\n    // Auto-detect daemon unless --standalone is specified\n    let useDaemon = false;\n    if (!useStandalone) {\n      useDaemon = await isDaemonRunning(port);\n      if (options.verbose && useDaemon) {\n        console.error(`Using daemon on port ${port}`);\n      }\n    }\n\n    // Create client (daemon or standalone)\n    const daemonClient = useDaemon ? new DaemonClient({ port }) : null;\n    const standaloneClient = !useDaemon\n      ? new ReaderClient({\n          verbose: options.verbose || false,\n          showChrome: options.showChrome || false,\n        })\n      : null;\n\n    try {\n      const formats = options.format.split(\",\").map((f: string) => f.trim());\n\n      // Validate formats\n      const validFormats = [\"markdown\", \"html\"];\n      for (const format of formats) {\n        if (!validFormats.includes(format)) {\n          console.error(\n            `Error: Invalid format \"${format}\". Valid formats: ${validFormats.join(\", \")}`\n          );\n          process.exit(1);\n        }\n      }\n\n      if (options.verbose) {\n        console.error(`Scraping ${urls.length} URL(s)...`);\n        console.error(`Formats: ${formats.join(\", \")}`);\n      }\n\n      // Parse tag selectors\n      const includeTags = options.includeTags\n        ? options.includeTags.split(\",\").map((s: string) => s.trim())\n        : undefined;\n      const excludeTags = options.excludeTags\n        ? options.excludeTags.split(\",\").map((s: string) => s.trim())\n        : undefined;\n\n      // Parse engine options\n      const skipEngines = options.skipEngine\n        ? options.skipEngine.split(\",\").map((s: string) => s.trim())\n        : undefined;\n\n      const scrapeOptions = {\n        urls,\n        formats,\n        batchConcurrency: parseInt(options.concurrency, 10),\n        timeoutMs: parseInt(options.timeout, 10),\n        batchTimeoutMs: parseInt(options.batchTimeout, 10),\n        proxy: options.proxy ? { url: options.proxy } : undefined,\n        userAgent: options.userAgent,\n        verbose: options.verbose || false,\n        showChrome: options.showChrome || false,\n        // Content cleaning options\n        onlyMainContent: options.mainContent !== false, // --no-main-content sets this to false\n        includeTags,\n        excludeTags,\n        // Engine options\n        forceEngine: options.engine,\n        skipEngines,\n        onProgress: options.verbose\n          ? ({ completed, total, currentUrl }: { completed: number; total: number; currentUrl: string }) => {\n              console.error(`[${completed}/${total}] ${currentUrl}`);\n            }\n          : undefined,\n      };\n\n      const result = useDaemon\n        ? await daemonClient!.scrape(scrapeOptions)\n        : await standaloneClient!.scrape(scrapeOptions);\n\n      // Always output JSON\n      const output = JSON.stringify(result, null, 2);\n\n      // Write output\n      if (options.output) {\n        writeFileSync(options.output, output);\n        if (options.verbose) {\n          console.error(`Output written to ${options.output}`);\n        }\n      } else {\n        console.log(output);\n      }\n\n      // Print summary to stderr\n      if (options.verbose) {\n        console.error(`\\nSummary:`);\n        console.error(\n          `  Successful: ${result.batchMetadata.successfulUrls}/${result.batchMetadata.totalUrls}`\n        );\n        console.error(`  Duration: ${result.batchMetadata.totalDuration}ms`);\n      }\n\n      // Exit with error code if any URLs failed\n      if (result.batchMetadata.failedUrls > 0) {\n        process.exit(1);\n      }\n    } catch (error: any) {\n      console.error(`Error: ${error.message}`);\n      process.exit(1);\n    } finally {\n      if (standaloneClient) {\n        await standaloneClient.close();\n        process.exit(0);\n      }\n    }\n  });\n\n// =============================================================================\n// Crawl Command\n// =============================================================================\n\nprogram\n  .command(\"crawl <url>\")\n  .description(\"Crawl a website to discover and optionally scrape pages\")\n  .option(\"-d, --depth <n>\", \"Maximum crawl depth\", \"1\")\n  .option(\"-m, --max-pages <n>\", \"Maximum pages to discover\", \"20\")\n  .option(\"-s, --scrape\", \"Also scrape content of discovered pages\")\n  .option(\"-f, --format <formats>\", \"Content formats when scraping (comma-separated: markdown,html)\", \"markdown\")\n  .option(\"-o, --output <file>\", \"Output file (stdout if omitted)\")\n  .option(\"--delay <ms>\", \"Delay between requests in milliseconds\", \"1000\")\n  .option(\"-t, --timeout <ms>\", \"Total timeout for crawl operation in milliseconds\")\n  .option(\"--include <patterns>\", \"URL patterns to include (comma-separated regex)\")\n  .option(\"--exclude <patterns>\", \"URL patterns to exclude (comma-separated regex)\")\n  .option(\"--proxy <url>\", \"Proxy URL (e.g., http://user:pass@host:port)\")\n  .option(\"--user-agent <string>\", \"Custom user agent string\")\n  .option(\"--show-chrome\", \"Show browser window for debugging\")\n  .option(\"--standalone\", \"Force standalone mode (bypass daemon)\")\n  .option(\"-p, --port <n>\", `Daemon port (default: ${DEFAULT_DAEMON_PORT})`, String(DEFAULT_DAEMON_PORT))\n  .option(\"-v, --verbose\", \"Enable verbose logging\")\n  .action(async (url: string, options) => {\n    const port = parseInt(options.port, 10);\n    const useStandalone = options.standalone || false;\n\n    // Auto-detect daemon unless --standalone is specified\n    let useDaemon = false;\n    if (!useStandalone) {\n      useDaemon = await isDaemonRunning(port);\n      if (options.verbose && useDaemon) {\n        console.error(`Using daemon on port ${port}`);\n      }\n    }\n\n    // Create client (daemon or standalone)\n    const daemonClient = useDaemon ? new DaemonClient({ port }) : null;\n    const standaloneClient = !useDaemon\n      ? new ReaderClient({\n          verbose: options.verbose || false,\n          showChrome: options.showChrome || false,\n        })\n      : null;\n\n    try {\n      if (options.verbose) {\n        console.error(`Crawling ${url}...`);\n        console.error(`Max depth: ${options.depth}, Max pages: ${options.maxPages}`);\n      }\n\n      // Parse include/exclude patterns\n      const includePatterns = options.include\n        ? options.include.split(\",\").map((p: string) => p.trim())\n        : undefined;\n      const excludePatterns = options.exclude\n        ? options.exclude.split(\",\").map((p: string) => p.trim())\n        : undefined;\n\n      const crawlOptions = {\n        url,\n        depth: parseInt(options.depth, 10),\n        maxPages: parseInt(options.maxPages, 10),\n        scrape: options.scrape || false,\n        delayMs: parseInt(options.delay, 10),\n        timeoutMs: options.timeout ? parseInt(options.timeout, 10) : undefined,\n        includePatterns,\n        excludePatterns,\n        proxy: options.proxy ? { url: options.proxy } : undefined,\n        userAgent: options.userAgent,\n        verbose: options.verbose || false,\n        showChrome: options.showChrome || false,\n      };\n\n      // Add formats to crawl options if scraping\n      const formats = options.format.split(\",\").map((f: string) => f.trim());\n      const crawlOptionsWithFormats = {\n        ...crawlOptions,\n        formats,\n      };\n\n      const result = useDaemon\n        ? await daemonClient!.crawl(crawlOptionsWithFormats)\n        : await standaloneClient!.crawl(crawlOptionsWithFormats);\n\n      // Always output JSON\n      const output = JSON.stringify(result, null, 2);\n\n      // Write output\n      if (options.output) {\n        writeFileSync(options.output, output);\n        if (options.verbose) {\n          console.error(`Output written to ${options.output}`);\n        }\n      } else {\n        console.log(output);\n      }\n\n      // Print summary to stderr\n      if (options.verbose) {\n        console.error(`\\nSummary:`);\n        console.error(`  Discovered: ${result.urls.length} URLs`);\n        console.error(`  Duration: ${result.metadata.totalDuration}ms`);\n      }\n    } catch (error: any) {\n      console.error(`Error: ${error.message}`);\n      process.exit(1);\n    } finally {\n      if (standaloneClient) {\n        await standaloneClient.close();\n        process.exit(0);\n      }\n    }\n  });\n\n// =============================================================================\n// Parse and execute\n// =============================================================================\n\nprogram.parse();\n","/**\n * ReaderClient\n *\n * A client wrapper that manages HeroCore lifecycle and provides\n * a simple interface for scraping and crawling.\n *\n * @example\n * const reader = new ReaderClient();\n *\n * const result = await reader.scrape({\n *   urls: ['https://example.com'],\n *   formats: ['markdown'],\n * });\n *\n * console.log(result.data[0].markdown);\n *\n * // When done (optional - auto-closes on process exit)\n * await reader.close();\n */\n\nimport HeroCore from \"@ulixee/hero-core\";\nimport { TransportBridge } from \"@ulixee/net\";\nimport { ConnectionToHeroCore } from \"@ulixee/hero\";\nimport { scrape } from \"./scraper\";\nimport { crawl } from \"./crawler\";\nimport { HeroBrowserPool } from \"./browser/pool\";\nimport type { ScrapeOptions, ScrapeResult, ProxyConfig, BrowserPoolConfig } from \"./types\";\nimport type { CrawlOptions, CrawlResult } from \"./crawl-types\";\nimport { createLogger } from \"./utils/logger\";\n\nconst logger = createLogger(\"client\");\n\n/**\n * Proxy rotation strategy\n */\nexport type ProxyRotation = \"round-robin\" | \"random\";\n\n/**\n * Configuration options for ReaderClient\n */\nexport interface ReaderClientOptions {\n  /** Enable verbose logging (default: false) */\n  verbose?: boolean;\n  /** Show Chrome browser window (default: false) */\n  showChrome?: boolean;\n\n  /** Browser pool configuration */\n  browserPool?: BrowserPoolConfig;\n\n  /** List of proxies to rotate through */\n  proxies?: ProxyConfig[];\n\n  /** Proxy rotation strategy (default: \"round-robin\") */\n  proxyRotation?: ProxyRotation;\n\n  /** Skip TLS/SSL certificate verification (default: true) */\n  skipTLSVerification?: boolean;\n}\n\n/**\n * ReaderClient manages the HeroCore lifecycle and provides\n * scrape/crawl methods with automatic initialization.\n */\nexport class ReaderClient {\n  private heroCore: HeroCore | null = null;\n  private pool: HeroBrowserPool | null = null;\n  private initialized = false;\n  private initializing: Promise<void> | null = null;\n  private closed = false;\n  private options: ReaderClientOptions;\n  private proxyIndex = 0;\n  private cleanupHandler: (() => Promise<void>) | null = null;\n\n  constructor(options: ReaderClientOptions = {}) {\n    this.options = options;\n\n    // Configure TLS verification\n    // Hero uses MITM_ALLOW_INSECURE env var to skip certificate verification\n    // Default is true (skip verification) for compatibility with various sites\n    const skipTLS = options.skipTLSVerification ?? true;\n    if (skipTLS) {\n      process.env.MITM_ALLOW_INSECURE = \"true\";\n    }\n\n    // Register cleanup on process exit\n    this.registerCleanup();\n  }\n\n  /**\n   * Get the next proxy from the rotation pool\n   */\n  private getNextProxy(): ProxyConfig | undefined {\n    const { proxies, proxyRotation = \"round-robin\" } = this.options;\n\n    if (!proxies || proxies.length === 0) {\n      return undefined;\n    }\n\n    if (proxyRotation === \"random\") {\n      return proxies[Math.floor(Math.random() * proxies.length)];\n    }\n\n    // Round-robin (default)\n    const proxy = proxies[this.proxyIndex % proxies.length];\n    this.proxyIndex++;\n    return proxy;\n  }\n\n  /**\n   * Initialize HeroCore. Called automatically on first scrape/crawl.\n   * Can be called explicitly if you want to pre-warm the client.\n   */\n  async start(): Promise<void> {\n    if (this.closed) {\n      throw new Error(\"ReaderClient has been closed. Create a new instance.\");\n    }\n\n    if (this.initialized) {\n      return;\n    }\n\n    // Prevent concurrent initialization\n    if (this.initializing) {\n      await this.initializing;\n      return;\n    }\n\n    this.initializing = this.initializeCore();\n    await this.initializing;\n    this.initializing = null;\n  }\n\n  /**\n   * Internal initialization logic\n   */\n  private async initializeCore(): Promise<void> {\n    try {\n      if (this.options.verbose) {\n        logger.info(\"Starting HeroCore...\");\n      }\n\n      this.heroCore = new HeroCore();\n      await this.heroCore.start();\n\n      if (this.options.verbose) {\n        logger.info(\"HeroCore started successfully\");\n      }\n\n      // Initialize browser pool\n      if (this.options.verbose) {\n        logger.info(\"Initializing browser pool...\");\n      }\n\n      const browserPoolConfig = this.options.browserPool;\n      const poolConfig = {\n        size: browserPoolConfig?.size ?? 2,\n        retireAfterPageCount: browserPoolConfig?.retireAfterPages ?? 100,\n        retireAfterAgeMs: (browserPoolConfig?.retireAfterMinutes ?? 30) * 60 * 1000,\n        maxQueueSize: browserPoolConfig?.maxQueueSize ?? 100,\n      };\n\n      this.pool = new HeroBrowserPool(\n        poolConfig,\n        undefined, // proxy set per-request\n        this.options.showChrome,\n        this.createConnection(),\n        undefined, // userAgent\n        this.options.verbose\n      );\n      await this.pool.initialize();\n\n      this.initialized = true;\n\n      if (this.options.verbose) {\n        logger.info(\"Browser pool initialized successfully\");\n      }\n    } catch (error: any) {\n      // Clean up on failure\n      if (this.pool) {\n        await this.pool.shutdown().catch(() => {});\n        this.pool = null;\n      }\n      if (this.heroCore) {\n        await this.heroCore.close().catch(() => {});\n        this.heroCore = null;\n      }\n      this.initialized = false;\n\n      // Provide helpful error messages\n      const message = error.message || String(error);\n\n      if (message.includes(\"EADDRINUSE\")) {\n        throw new Error(\n          \"Failed to start HeroCore: Port already in use. \" +\n            \"Another instance may be running. \" +\n            \"Close it or use a different port.\"\n        );\n      }\n\n      if (message.includes(\"chrome\") || message.includes(\"Chrome\")) {\n        throw new Error(\n          \"Failed to start HeroCore: Chrome/Chromium not found. \" +\n            \"Please install Chrome or set CHROME_PATH environment variable.\"\n        );\n      }\n\n      throw new Error(`Failed to start HeroCore: ${message}`);\n    }\n  }\n\n  /**\n   * Create a connection to the HeroCore instance\n   */\n  private createConnection(): ConnectionToHeroCore {\n    if (!this.heroCore) {\n      throw new Error(\"HeroCore not initialized. This should not happen.\");\n    }\n\n    const bridge = new TransportBridge();\n    this.heroCore.addConnection(bridge.transportToClient);\n    return new ConnectionToHeroCore(bridge.transportToCore);\n  }\n\n  /**\n   * Ensure client is initialized before operation\n   */\n  private async ensureInitialized(): Promise<void> {\n    if (this.closed) {\n      throw new Error(\"ReaderClient has been closed. Create a new instance.\");\n    }\n\n    if (!this.initialized) {\n      await this.start();\n    }\n  }\n\n  /**\n   * Scrape one or more URLs\n   *\n   * @param options - Scrape options (urls, formats, etc.)\n   * @returns Scrape result with data and metadata\n   *\n   * @example\n   * const result = await reader.scrape({\n   *   urls: ['https://example.com'],\n   *   formats: ['markdown', 'html'],\n   * });\n   */\n  async scrape(options: Omit<ScrapeOptions, \"connectionToCore\" | \"pool\">): Promise<ScrapeResult> {\n    await this.ensureInitialized();\n\n    if (!this.pool) {\n      throw new Error(\"Browser pool not initialized. This should not happen.\");\n    }\n\n    // Use proxy rotation if proxies are configured and no specific proxy is provided\n    const proxy = options.proxy ?? this.getNextProxy();\n\n    return await scrape({\n      ...options,\n      proxy,\n      showChrome: options.showChrome ?? this.options.showChrome,\n      verbose: options.verbose ?? this.options.verbose,\n      pool: this.pool,\n    });\n  }\n\n  /**\n   * Crawl a website to discover URLs\n   *\n   * @param options - Crawl options (url, depth, maxPages, etc.)\n   * @returns Crawl result with discovered URLs and optional scraped content\n   *\n   * @example\n   * const result = await reader.crawl({\n   *   url: 'https://example.com',\n   *   depth: 2,\n   *   maxPages: 50,\n   *   scrape: true,\n   * });\n   */\n  async crawl(options: Omit<CrawlOptions, \"connectionToCore\" | \"pool\">): Promise<CrawlResult> {\n    await this.ensureInitialized();\n\n    if (!this.pool) {\n      throw new Error(\"Browser pool not initialized. This should not happen.\");\n    }\n\n    // Use proxy rotation if proxies are configured and no specific proxy is provided\n    const proxy = options.proxy ?? this.getNextProxy();\n\n    return await crawl({\n      ...options,\n      proxy,\n      pool: this.pool,\n    });\n  }\n\n  /**\n   * Check if the client is initialized and ready\n   */\n  isReady(): boolean {\n    return this.initialized && !this.closed;\n  }\n\n  /**\n   * Close the client and release resources\n   *\n   * Note: This is optional - the client will auto-close on process exit.\n   */\n  async close(): Promise<void> {\n    if (this.closed) {\n      return;\n    }\n\n    this.closed = true;\n\n    // Remove process event handlers to allow clean exit\n    this.removeCleanupHandlers();\n\n    // Shutdown pool first (closes browser instances)\n    if (this.pool) {\n      if (this.options.verbose) {\n        logger.info(\"Shutting down browser pool...\");\n      }\n\n      try {\n        await this.pool.shutdown();\n      } catch (error: any) {\n        if (this.options.verbose) {\n          logger.warn(`Error shutting down pool: ${error.message}`);\n        }\n      }\n\n      this.pool = null;\n    }\n\n    // Then close HeroCore\n    if (this.heroCore) {\n      if (this.options.verbose) {\n        logger.info(\"Closing HeroCore...\");\n      }\n\n      try {\n        await this.heroCore.close();\n        // Also call static shutdown to clean up any remaining resources\n        await HeroCore.shutdown();\n      } catch (error: any) {\n        // Ignore close errors\n        if (this.options.verbose) {\n          logger.warn(`Error closing HeroCore: ${error.message}`);\n        }\n      }\n\n      this.heroCore = null;\n    }\n\n    this.initialized = false;\n\n    if (this.options.verbose) {\n      logger.info(\"ReaderClient closed\");\n    }\n  }\n\n  /**\n   * Register cleanup handlers for process exit\n   */\n  private registerCleanup(): void {\n    this.cleanupHandler = async () => {\n      await this.close();\n    };\n\n    // Handle various exit signals\n    process.once(\"beforeExit\", this.cleanupHandler);\n    process.once(\"SIGINT\", async () => {\n      await this.cleanupHandler?.();\n      process.exit(0);\n    });\n    process.once(\"SIGTERM\", async () => {\n      await this.cleanupHandler?.();\n      process.exit(0);\n    });\n  }\n\n  /**\n   * Remove process cleanup handlers\n   */\n  private removeCleanupHandlers(): void {\n    if (this.cleanupHandler) {\n      process.removeListener(\"beforeExit\", this.cleanupHandler);\n      this.cleanupHandler = null;\n    }\n  }\n}\n","import pLimit from \"p-limit\";\nimport { htmlToMarkdown } from \"./formatters/markdown\";\nimport { cleanContent } from \"./utils/content-cleaner\";\nimport { extractMetadata } from \"./utils/metadata-extractor\";\nimport { createLogger } from \"./utils/logger\";\nimport { fetchRobotsTxt, isUrlAllowed, type RobotsRules } from \"./utils/robots-parser\";\nimport {\n  DEFAULT_OPTIONS,\n  type ScrapeOptions,\n  type ScrapeResult,\n  type WebsiteScrapeResult,\n  type BatchMetadata,\n  type ProxyMetadata,\n} from \"./types\";\nimport { EngineOrchestrator, AllEnginesFailedError } from \"./engines/index.js\";\n\n/**\n * Scraper class with built-in concurrency support\n *\n * Features:\n * - Hero-based browser automation\n * - Automatic Cloudflare challenge detection and bypass\n * - Built-in concurrency via browser pool\n * - Progress tracking\n * - Error handling per URL\n *\n * @example\n * const scraper = new Scraper({\n *   urls: ['https://example.com', 'https://example.org'],\n *   formats: ['markdown', 'html'],\n *   batchConcurrency: 2,\n *   proxy: { type: 'residential', ... }\n * });\n *\n * const result = await scraper.scrape();\n * console.log(`Scraped ${result.batchMetadata.successfulUrls} URLs`);\n */\nexport class Scraper {\n  private options: Required<ScrapeOptions>;\n  private logger = createLogger(\"scraper\");\n  private robotsCache: Map<string, RobotsRules | null> = new Map();\n\n  constructor(options: ScrapeOptions) {\n    // Merge with defaults\n    this.options = {\n      ...DEFAULT_OPTIONS,\n      ...options,\n    } as Required<ScrapeOptions>;\n\n    // Pool is required for Hero engine (but may not be needed if using http/tlsclient only)\n    // The orchestrator will check availability when needed\n  }\n\n  /**\n   * Get robots.txt rules for a URL, cached per domain\n   */\n  private async getRobotsRules(url: string): Promise<RobotsRules | null> {\n    const origin = new URL(url).origin;\n    if (!this.robotsCache.has(origin)) {\n      const rules = await fetchRobotsTxt(origin);\n      this.robotsCache.set(origin, rules);\n    }\n    return this.robotsCache.get(origin) ?? null;\n  }\n\n  /**\n   * Scrape all URLs\n   *\n   * @returns Scrape result with pages and metadata\n   */\n  async scrape(): Promise<ScrapeResult> {\n    const startTime = Date.now();\n\n    // Pool is managed by ReaderClient - just use it\n    // Scrape URLs with concurrency control\n    const results = await this.scrapeWithConcurrency();\n\n    // Build response\n    return this.buildScrapeResult(results, startTime);\n  }\n\n  /**\n   * Scrape URLs with concurrency control\n   */\n  private async scrapeWithConcurrency(): Promise<\n    Array<{ result: WebsiteScrapeResult | null; error?: string }>\n  > {\n    const limit = pLimit(this.options.batchConcurrency || 1);\n    const tasks = this.options.urls.map((url, index) =>\n      limit(() => this.scrapeSingleUrlWithRetry(url, index))\n    );\n\n    const batchPromise = Promise.all(tasks);\n\n    // Apply batch timeout if specified\n    if (this.options.batchTimeoutMs && this.options.batchTimeoutMs > 0) {\n      const timeoutPromise = new Promise<never>((_, reject) => {\n        setTimeout(() => {\n          reject(new Error(`Batch operation timed out after ${this.options.batchTimeoutMs}ms`));\n        }, this.options.batchTimeoutMs);\n      });\n\n      return Promise.race([batchPromise, timeoutPromise]);\n    }\n\n    return batchPromise;\n  }\n\n  /**\n   * Scrape a single URL with retry logic\n   */\n  private async scrapeSingleUrlWithRetry(\n    url: string,\n    index: number\n  ): Promise<{ result: WebsiteScrapeResult | null; error?: string }> {\n    const maxRetries = this.options.maxRetries || 2;\n    let lastError: string | undefined;\n\n    for (let attempt = 0; attempt <= maxRetries; attempt++) {\n      try {\n        const result = await this.scrapeSingleUrl(url, index);\n        if (result) {\n          return { result };\n        }\n        // Result is null but no exception - unexpected state\n        lastError = `Failed to scrape ${url}: No content returned`;\n      } catch (error: any) {\n        lastError = error.message;\n        if (attempt < maxRetries) {\n          // Exponential backoff: 1s, 2s, 4s...\n          const delay = Math.pow(2, attempt) * 1000;\n          this.logger.warn(`Retry ${attempt + 1}/${maxRetries} for ${url} in ${delay}ms`);\n          await new Promise((resolve) => setTimeout(resolve, delay));\n        }\n      }\n    }\n\n    this.logger.error(`Failed to scrape ${url} after ${maxRetries + 1} attempts: ${lastError}`);\n    return { result: null, error: lastError };\n  }\n\n  /**\n   * Scrape a single URL using the engine orchestrator\n   */\n  private async scrapeSingleUrl(url: string, index: number): Promise<WebsiteScrapeResult | null> {\n    const startTime = Date.now();\n\n    // Check robots.txt before scraping\n    const robotsRules = await this.getRobotsRules(url);\n    if (!isUrlAllowed(url, robotsRules)) {\n      throw new Error(`URL blocked by robots.txt: ${url}`);\n    }\n\n    try {\n      // Create orchestrator with configured engines\n      const orchestrator = new EngineOrchestrator({\n        engines: this.options.engines,\n        skipEngines: this.options.skipEngines,\n        forceEngine: this.options.forceEngine,\n        logger: this.logger,\n        verbose: this.options.verbose,\n      });\n\n      // Use orchestrator to fetch HTML\n      const engineResult = await orchestrator.scrape({\n        url,\n        options: this.options,\n        logger: this.logger,\n      });\n\n      if (this.options.verbose) {\n        this.logger.info(\n          `[scraper] ${url} scraped with ${engineResult.engine} engine in ${engineResult.duration}ms ` +\n            `(attempted: ${engineResult.attemptedEngines.join(\" â†’ \")})`\n        );\n      }\n\n      // Clean content with configurable options\n      const cleanedHtml = cleanContent(engineResult.html, engineResult.url, {\n        removeAds: this.options.removeAds,\n        removeBase64Images: this.options.removeBase64Images,\n        onlyMainContent: this.options.onlyMainContent,\n        includeTags: this.options.includeTags,\n        excludeTags: this.options.excludeTags,\n      });\n\n      // Extract metadata\n      const websiteMetadata = extractMetadata(cleanedHtml, engineResult.url);\n\n      const duration = Date.now() - startTime;\n\n      // Convert to requested formats\n      const markdown = this.options.formats.includes(\"markdown\")\n        ? htmlToMarkdown(cleanedHtml)\n        : undefined;\n\n      const htmlOutput = this.options.formats.includes(\"html\") ? cleanedHtml : undefined;\n\n      // Report progress\n      if (this.options.onProgress) {\n        this.options.onProgress({\n          completed: index + 1,\n          total: this.options.urls.length,\n          currentUrl: url,\n        });\n      }\n\n      // Build proxy metadata if proxy was used\n      let proxyMetadata: ProxyMetadata | undefined;\n      if (this.options.proxy) {\n        const proxy = this.options.proxy;\n        // Extract host and port from either url or direct config\n        if (proxy.url) {\n          try {\n            const proxyUrl = new URL(proxy.url);\n            proxyMetadata = {\n              host: proxyUrl.hostname,\n              port: parseInt(proxyUrl.port, 10) || 80,\n              country: proxy.country,\n            };\n          } catch {\n            // Invalid URL, skip proxy metadata\n          }\n        } else if (proxy.host && proxy.port) {\n          proxyMetadata = {\n            host: proxy.host,\n            port: proxy.port,\n            country: proxy.country,\n          };\n        }\n      }\n\n      // Build result\n      const result: WebsiteScrapeResult = {\n        markdown,\n        html: htmlOutput,\n        metadata: {\n          baseUrl: url,\n          totalPages: 1,\n          scrapedAt: new Date().toISOString(),\n          duration,\n          website: websiteMetadata,\n          proxy: proxyMetadata,\n        },\n      };\n\n      return result;\n    } catch (error: unknown) {\n      // Handle AllEnginesFailedError with detailed logging\n      if (error instanceof AllEnginesFailedError) {\n        const engineSummary = error.attemptedEngines\n          .map((e) => `${e}: ${error.errors.get(e)?.message || \"unknown\"}`)\n          .join(\"; \");\n        this.logger.error(`Failed to scrape ${url}: All engines failed - ${engineSummary}`);\n      } else if (error instanceof Error) {\n        this.logger.error(`Failed to scrape ${url}: ${error.message}`);\n      } else {\n        this.logger.error(`Failed to scrape ${url}: ${String(error)}`);\n      }\n\n      // Report progress (failed)\n      if (this.options.onProgress) {\n        this.options.onProgress({\n          completed: index + 1,\n          total: this.options.urls.length,\n          currentUrl: url,\n        });\n      }\n\n      return null; // Return null for failed URLs\n    }\n  }\n\n  /**\n   * Build final scrape result\n   */\n  private buildScrapeResult(\n    results: Array<{ result: WebsiteScrapeResult | null; error?: string }>,\n    startTime: number\n  ): ScrapeResult {\n    const successful = results\n      .filter((r) => r.result !== null)\n      .map((r) => r.result as WebsiteScrapeResult);\n\n    const errors: Array<{ url: string; error: string }> = [];\n    results.forEach((r, index) => {\n      if (r.result === null && r.error) {\n        errors.push({ url: this.options.urls[index], error: r.error });\n      }\n    });\n\n    const batchMetadata: BatchMetadata = {\n      totalUrls: this.options.urls.length,\n      successfulUrls: successful.length,\n      failedUrls: results.filter((r) => r.result === null).length,\n      scrapedAt: new Date().toISOString(),\n      totalDuration: Date.now() - startTime,\n      errors,\n    };\n\n    return {\n      data: successful,\n      batchMetadata,\n    };\n  }\n}\n\n/**\n * Convenience function to scrape URLs\n *\n * @param options - Scrape options\n * @returns Scrape result\n *\n * @example\n * const result = await scrape({\n *   urls: ['https://example.com'],\n *   formats: ['markdown']\n * });\n */\nexport async function scrape(options: ScrapeOptions): Promise<ScrapeResult> {\n  const scraper = new Scraper(options);\n  return scraper.scrape();\n}\n","import { convert } from \"@vakra-dev/supermarkdown\";\n\n/**\n * Convert HTML to Markdown\n *\n * Simple conversion without any headers, metadata, or formatting wrappers.\n * Returns clean markdown content ready for LLM consumption.\n *\n * Uses supermarkdown (Rust-based) for high-performance conversion.\n */\nexport function htmlToMarkdown(html: string): string {\n  try {\n    return convert(html, {\n      headingStyle: \"atx\",\n      bulletMarker: \"-\",\n      codeFence: \"`\",\n      linkStyle: \"inline\",\n    });\n  } catch (error) {\n    console.warn(\"Error converting HTML to Markdown:\", error);\n    // Fallback: extract text content\n    return html.replace(/<[^>]*>/g, \"\").trim();\n  }\n}\n\n/**\n * Alias for htmlToMarkdown (backward compatibility)\n */\nexport const formatToMarkdown = htmlToMarkdown;\n","import { parseHTML } from \"linkedom\";\n\n/**\n * HTML content cleaning utilities using DOM parsing\n *\n * Layered extraction strategy:\n * 1. Remove scripts, styles, hidden elements (always safe)\n * 2. Remove overlays/modals (always safe)\n * 3. Remove ads (if enabled)\n * 4. Remove navigation with protection (check each element before removing)\n * 5. Find and isolate main content\n */\n\n/**\n * Content cleaning options\n */\nexport interface CleaningOptions {\n  /** Remove ads and tracking elements (default: true) */\n  removeAds?: boolean;\n  /** Remove base64-encoded images (default: true) */\n  removeBase64Images?: boolean;\n  /** Extract only main content, removing nav/header/footer/sidebar (default: true) */\n  onlyMainContent?: boolean;\n  /** CSS selectors for elements to include (if set, only these elements are kept) */\n  includeTags?: string[];\n  /** CSS selectors for elements to exclude (removed from output) */\n  excludeTags?: string[];\n}\n\n/**\n * Selectors for elements that should ALWAYS be removed (never content)\n */\nconst ALWAYS_REMOVE_SELECTORS = [\n  // Scripts and styles\n  \"script\",\n  \"style\",\n  \"noscript\",\n  \"link[rel='stylesheet']\",\n\n  // Hidden elements\n  \"[hidden]\",\n  \"[aria-hidden='true']\",\n  \"[style*='display: none']\",\n  \"[style*='display:none']\",\n  \"[style*='visibility: hidden']\",\n  \"[style*='visibility:hidden']\",\n\n  // SVG icons and decorative elements\n  \"svg[aria-hidden='true']\",\n  \"svg.icon\",\n  \"svg[class*='icon']\",\n\n  // Template and metadata\n  \"template\",\n  \"meta\",\n\n  // Embeds that don't convert to text\n  \"iframe\",\n  \"canvas\",\n  \"object\",\n  \"embed\",\n\n  // Forms (usually not main content)\n  \"form\",\n  \"input\",\n  \"select\",\n  \"textarea\",\n  \"button\",\n];\n\n/**\n * Selectors for overlays, modals, popups (always remove)\n */\nconst OVERLAY_SELECTORS = [\n  \"[class*='modal']\",\n  \"[class*='popup']\",\n  \"[class*='overlay']\",\n  \"[class*='dialog']\",\n  \"[role='dialog']\",\n  \"[role='alertdialog']\",\n  \"[class*='cookie']\",\n  \"[class*='consent']\",\n  \"[class*='gdpr']\",\n  \"[class*='privacy-banner']\",\n  \"[class*='notification-bar']\",\n  \"[id*='cookie']\",\n  \"[id*='consent']\",\n  \"[id*='gdpr']\",\n  // Fixed/sticky positioned elements\n  \"[style*='position: fixed']\",\n  \"[style*='position:fixed']\",\n  \"[style*='position: sticky']\",\n  \"[style*='position:sticky']\",\n];\n\n/**\n * Navigation/boilerplate selectors - exact matches only\n * No wildcards like [class*=\"nav-\"] which are too aggressive\n */\nconst NAVIGATION_SELECTORS = [\n  // Semantic elements\n  \"header\",\n  \"footer\",\n  \"nav\",\n  \"aside\",\n\n  // Header variations\n  \".header\",\n  \".top\",\n  \".navbar\",\n  \"#header\",\n\n  // Footer variations\n  \".footer\",\n  \".bottom\",\n  \"#footer\",\n\n  // Sidebars\n  \".sidebar\",\n  \".side\",\n  \".aside\",\n  \"#sidebar\",\n\n  // Modals/popups (backup if not caught by OVERLAY_SELECTORS)\n  \".modal\",\n  \".popup\",\n  \"#modal\",\n  \".overlay\",\n\n  // Ads\n  \".ad\",\n  \".ads\",\n  \".advert\",\n  \"#ad\",\n\n  // Language selectors\n  \".lang-selector\",\n  \".language\",\n  \"#language-selector\",\n\n  // Social\n  \".social\",\n  \".social-media\",\n  \".social-links\",\n  \"#social\",\n\n  // Navigation/menus\n  \".menu\",\n  \".navigation\",\n  \"#nav\",\n\n  // Breadcrumbs\n  \".breadcrumbs\",\n  \"#breadcrumbs\",\n\n  // Share buttons\n  \".share\",\n  \"#share\",\n\n  // Widgets\n  \".widget\",\n  \"#widget\",\n\n  // Cookie notices (backup)\n  \".cookie\",\n  \"#cookie\",\n];\n\n/**\n * Force-include selectors - elements containing these are PROTECTED from removal\n */\nconst FORCE_INCLUDE_SELECTORS = [\n  // IDs\n  \"#main\",\n  \"#content\",\n  \"#main-content\",\n  \"#article\",\n  \"#post\",\n  \"#page-content\",\n\n  // Semantic elements\n  \"main\",\n  \"article\",\n  \"[role='main']\",\n\n  // Classes\n  \".main-content\",\n  \".content\",\n  \".post-content\",\n  \".article-content\",\n  \".entry-content\",\n  \".page-content\",\n  \".article-body\",\n  \".post-body\",\n  \".story-content\",\n  \".blog-content\",\n];\n\n/**\n * Ad-related selectors (removed when removeAds is true)\n */\nconst AD_SELECTORS = [\n  // Google ads\n  \"ins.adsbygoogle\",\n  \".google-ad\",\n  \".adsense\",\n\n  // Generic ad containers\n  \"[data-ad]\",\n  \"[data-ads]\",\n  \"[data-ad-slot]\",\n  \"[data-ad-client]\",\n\n  // Common ad class patterns\n  \".ad-container\",\n  \".ad-wrapper\",\n  \".advertisement\",\n  \".sponsored-content\",\n\n  // Tracking pixels\n  \"img[width='1'][height='1']\",\n  \"img[src*='pixel']\",\n  \"img[src*='tracking']\",\n  \"img[src*='analytics']\",\n];\n\n// ============================================================================\n// Content Scoring Heuristics\n// ============================================================================\n\n/**\n * Calculate link density of an element (ratio of link text to total text)\n * High link density (>0.5) indicates navigation, not content\n */\nfunction getLinkDensity(element: Element): number {\n  const text = element.textContent || \"\";\n  const textLength = text.trim().length;\n  if (textLength === 0) return 1;\n\n  let linkLength = 0;\n  element.querySelectorAll(\"a\").forEach((link: Element) => {\n    linkLength += (link.textContent || \"\").trim().length;\n  });\n\n  return linkLength / textLength;\n}\n\n/**\n * Calculate content score for an element\n * Higher scores indicate more likely to be main content\n */\nfunction getContentScore(element: Element): number {\n  let score = 0;\n  const text = element.textContent || \"\";\n  const textLength = text.trim().length;\n\n  // Positive signals\n  score += Math.min(textLength / 100, 50); // Text density (capped)\n  score += element.querySelectorAll(\"p\").length * 3; // Paragraphs\n  score += element.querySelectorAll(\"h1, h2, h3, h4, h5, h6\").length * 2; // Headings\n  score += element.querySelectorAll(\"img\").length * 1; // Images (slight bonus)\n\n  // Negative signals\n  score -= element.querySelectorAll(\"a\").length * 0.5; // Too many links\n  score -= element.querySelectorAll(\"li\").length * 0.2; // Too many list items\n\n  // Link density penalty\n  const linkDensity = getLinkDensity(element);\n  if (linkDensity > 0.5) score -= 30;\n  else if (linkDensity > 0.3) score -= 15;\n\n  // Class/ID signals\n  const classAndId = (element.className || \"\") + \" \" + (element.id || \"\");\n  if (/article|content|post|body|main|entry/i.test(classAndId)) score += 25;\n  if (/comment|sidebar|footer|nav|menu|header|widget|ad/i.test(classAndId)) score -= 25;\n\n  return score;\n}\n\n/**\n * Check if an element looks like navigation (high link density, list-heavy)\n */\nfunction looksLikeNavigation(element: Element): boolean {\n  const linkDensity = getLinkDensity(element);\n  if (linkDensity > 0.5) return true;\n\n  // Check for menu-like structures (many list items with links)\n  const listItems = element.querySelectorAll(\"li\");\n  const links = element.querySelectorAll(\"a\");\n  if (listItems.length > 5 && links.length > listItems.length * 0.8) return true;\n\n  return false;\n}\n\n// ============================================================================\n// Removal Functions\n// ============================================================================\n\n/**\n * Simple removal without protection checks (for always-safe selectors)\n */\nfunction removeElements(document: Document, selectors: string[]): void {\n  for (const selector of selectors) {\n    try {\n      document.querySelectorAll(selector).forEach((el: Element) => el.remove());\n    } catch {\n      // Some selectors may not be supported, skip them\n    }\n  }\n}\n\n/**\n * Remove elements WITH PROTECTION - checks each element before removing\n * This is the key fix: if an element contains protected content, don't remove it\n */\nfunction removeWithProtection(\n  document: Document,\n  selectorsToRemove: string[],\n  protectedSelectors: string[]\n): void {\n  for (const selector of selectorsToRemove) {\n    try {\n      document.querySelectorAll(selector).forEach((element: Element) => {\n        // Check 1: Is this element itself protected?\n        const isProtected = protectedSelectors.some((ps) => {\n          try {\n            return element.matches(ps);\n          } catch {\n            return false;\n          }\n        });\n        if (isProtected) return;\n\n        // Check 2: Does element CONTAIN protected content?\n        const containsProtected = protectedSelectors.some((ps) => {\n          try {\n            return element.querySelector(ps) !== null;\n          } catch {\n            return false;\n          }\n        });\n        if (containsProtected) return;\n\n        // Safe to remove\n        element.remove();\n      });\n    } catch {\n      // Skip invalid selector\n    }\n  }\n}\n\n// ============================================================================\n// Main Content Extraction\n// ============================================================================\n\n/**\n * Find the main content container using multiple strategies\n */\nfunction findMainContent(document: Document): Element | null {\n  // Helper to validate a content element\n  const isValidContent = (el: Element | null): el is Element => {\n    if (!el) return false;\n    const text = el.textContent || \"\";\n    if (text.trim().length < 100) return false;\n    // Reject if it looks like navigation\n    if (looksLikeNavigation(el)) return false;\n    return true;\n  };\n\n  // Priority 1: Semantic <main> element\n  const main = document.querySelector(\"main\");\n  if (isValidContent(main) && getLinkDensity(main) < 0.4) {\n    return main;\n  }\n\n  // Priority 2: [role=\"main\"]\n  const roleMain = document.querySelector('[role=\"main\"]');\n  if (isValidContent(roleMain) && getLinkDensity(roleMain) < 0.4) {\n    return roleMain;\n  }\n\n  // Priority 3: Single <article> element\n  const articles = document.querySelectorAll(\"article\");\n  if (articles.length === 1 && isValidContent(articles[0])) {\n    return articles[0];\n  }\n\n  // Priority 4: Content container by ID/class\n  const contentSelectors = [\n    \"#content\",\n    \"#main-content\",\n    \"#main\",\n    \".content\",\n    \".main-content\",\n    \".post-content\",\n    \".article-content\",\n    \".entry-content\",\n    \".page-content\",\n    \".article-body\",\n    \".post-body\",\n    \".story-content\",\n    \".blog-content\",\n  ];\n\n  for (const selector of contentSelectors) {\n    try {\n      const el = document.querySelector(selector);\n      if (isValidContent(el) && getLinkDensity(el) < 0.4) {\n        return el;\n      }\n    } catch {\n      // Invalid selector, skip\n    }\n  }\n\n  // Priority 5: Score-based selection (find highest scoring element)\n  const candidates: Array<{ el: Element; score: number }> = [];\n  const containers = document.querySelectorAll(\"div, section, article\");\n\n  containers.forEach((el: Element) => {\n    const text = el.textContent || \"\";\n    if (text.trim().length < 200) return;\n\n    const score = getContentScore(el);\n    if (score > 0) {\n      candidates.push({ el, score });\n    }\n  });\n\n  // Sort by score and return highest\n  candidates.sort((a, b) => b.score - a.score);\n\n  if (candidates.length > 0 && candidates[0].score > 20) {\n    return candidates[0].el;\n  }\n\n  // No main content found\n  return null;\n}\n\n/**\n * Clean HTML content using layered extraction strategy\n */\nexport function cleanHtml(html: string, baseUrl: string, options: CleaningOptions = {}): string {\n  const {\n    removeAds = true,\n    removeBase64Images = true,\n    onlyMainContent = true,\n    includeTags,\n    excludeTags,\n  } = options;\n\n  const { document } = parseHTML(html);\n\n  // ============================================================================\n  // Layer 1: Always remove scripts, styles, hidden elements, overlays\n  // ============================================================================\n  removeElements(document, ALWAYS_REMOVE_SELECTORS);\n  removeElements(document, OVERLAY_SELECTORS);\n\n  // ============================================================================\n  // Layer 2: Remove ad-related elements (if enabled)\n  // ============================================================================\n  if (removeAds) {\n    removeElements(document, AD_SELECTORS);\n  }\n\n  // ============================================================================\n  // Layer 3: Apply user-provided excludeTags\n  // ============================================================================\n  if (excludeTags && excludeTags.length > 0) {\n    removeElements(document, excludeTags);\n  }\n\n  // ============================================================================\n  // Layer 4: Extract main content (if enabled)\n  // KEY FIX: Use protection-aware removal\n  // ============================================================================\n  if (onlyMainContent) {\n    // Remove navigation elements WITH PROTECTION\n    // Each element is checked: if it contains #main, .content, etc., don't remove\n    removeWithProtection(document, NAVIGATION_SELECTORS, FORCE_INCLUDE_SELECTORS);\n\n    // Then try to find and isolate main content\n    const mainContent = findMainContent(document);\n\n    if (mainContent) {\n      // Replace body with just the main content\n      const body = document.body;\n      if (body) {\n        const clone = mainContent.cloneNode(true) as Element;\n        body.innerHTML = \"\";\n        body.appendChild(clone);\n      }\n    }\n    // If no main content found, we've removed navigation with protection, which is good\n  }\n\n  // ============================================================================\n  // Layer 5: Apply user-provided includeTags (whitelist mode)\n  // ============================================================================\n  if (includeTags && includeTags.length > 0) {\n    const matchedElements: Element[] = [];\n\n    for (const selector of includeTags) {\n      try {\n        document.querySelectorAll(selector).forEach((el: Element) => {\n          matchedElements.push(el.cloneNode(true) as Element);\n        });\n      } catch {\n        // Invalid selector, skip\n      }\n    }\n\n    if (matchedElements.length > 0) {\n      const body = document.body;\n      if (body) {\n        body.innerHTML = \"\";\n        matchedElements.forEach((el) => body.appendChild(el));\n      }\n    }\n  }\n\n  // ============================================================================\n  // Layer 6: Clean up remaining elements\n  // ============================================================================\n\n  // Remove base64 images\n  if (removeBase64Images) {\n    removeBase64ImagesFromDocument(document);\n  }\n\n  // Remove HTML comments\n  const walker = document.createTreeWalker(document, 128 /* NodeFilter.SHOW_COMMENT */);\n  const comments: Node[] = [];\n  while (walker.nextNode()) {\n    comments.push(walker.currentNode);\n  }\n  comments.forEach((comment) => comment.parentNode?.removeChild(comment));\n\n  // Convert relative URLs to absolute\n  convertRelativeUrls(document, baseUrl);\n\n  return document.documentElement?.outerHTML || html;\n}\n\n/**\n * Remove base64-encoded images from the document\n */\nfunction removeBase64ImagesFromDocument(document: Document): void {\n  // Remove img elements with base64 src\n  document.querySelectorAll(\"img[src^='data:']\").forEach((el: Element) => {\n    el.remove();\n  });\n\n  // Remove elements with base64 background images\n  document.querySelectorAll(\"[style*='data:image']\").forEach((el: Element) => {\n    const style = el.getAttribute(\"style\");\n    if (style) {\n      const cleanedStyle = style.replace(\n        /background(-image)?:\\s*url\\([^)]*data:image[^)]*\\)[^;]*;?/gi,\n        \"\"\n      );\n      if (cleanedStyle.trim()) {\n        el.setAttribute(\"style\", cleanedStyle);\n      } else {\n        el.removeAttribute(\"style\");\n      }\n    }\n  });\n\n  // Remove source elements with base64 src/srcset\n  document.querySelectorAll(\"source[src^='data:'], source[srcset*='data:']\").forEach((el: Element) => {\n    el.remove();\n  });\n}\n\n/**\n * Convert relative URLs to absolute URLs\n */\nfunction convertRelativeUrls(document: Document, baseUrl: string): void {\n  // Convert src attributes\n  document.querySelectorAll(\"[src]\").forEach((el: Element) => {\n    const src = el.getAttribute(\"src\");\n    if (src && !src.startsWith(\"http\") && !src.startsWith(\"//\") && !src.startsWith(\"data:\")) {\n      try {\n        el.setAttribute(\"src\", new URL(src, baseUrl).toString());\n      } catch {\n        // Invalid URL, leave as-is\n      }\n    }\n  });\n\n  // Convert href attributes\n  document.querySelectorAll(\"[href]\").forEach((el: Element) => {\n    const href = el.getAttribute(\"href\");\n    if (\n      href &&\n      !href.startsWith(\"http\") &&\n      !href.startsWith(\"//\") &&\n      !href.startsWith(\"#\") &&\n      !href.startsWith(\"mailto:\") &&\n      !href.startsWith(\"tel:\") &&\n      !href.startsWith(\"javascript:\")\n    ) {\n      try {\n        el.setAttribute(\"href\", new URL(href, baseUrl).toString());\n      } catch {\n        // Invalid URL, leave as-is\n      }\n    }\n  });\n}\n\n/**\n * Main export - clean HTML content\n */\nexport function cleanContent(html: string, baseUrl: string, options: CleaningOptions = {}): string {\n  return cleanHtml(html, baseUrl, options);\n}\n","import { parseHTML } from \"linkedom\";\nimport type { WebsiteMetadata } from \"../types\";\nimport { normalizeUrl } from \"./url-helpers\";\n\n/**\n * Extract comprehensive website metadata from HTML content\n * Uses proper DOM parsing for reliable attribute extraction\n */\nexport function extractMetadata(html: string, baseUrl: string): WebsiteMetadata {\n  return extractWebsiteMetadata(html, baseUrl);\n}\n\n/**\n * Extract comprehensive website metadata from HTML content\n */\nexport function extractWebsiteMetadata(html: string, baseUrl: string): WebsiteMetadata {\n  const { document } = parseHTML(html);\n\n  const metadata: WebsiteMetadata = {\n    title: null,\n    description: null,\n    author: null,\n    language: null,\n    charset: null,\n    favicon: null,\n    canonical: null,\n    image: null,\n    keywords: null,\n    robots: null,\n    themeColor: null,\n    openGraph: null,\n    twitter: null,\n  };\n\n  // Extract basic meta tags\n  metadata.title = extractTitle(document);\n  metadata.description = extractMetaContent(document, \"description\");\n  metadata.author = extractMetaContent(document, \"author\");\n  metadata.language = extractLanguage(document);\n  metadata.charset = extractCharset(document);\n\n  // Extract links\n  metadata.favicon = extractFavicon(document, baseUrl);\n  metadata.canonical = extractCanonical(document, baseUrl);\n  metadata.image =\n    extractMetaContent(document, \"og:image\") || extractMetaContent(document, \"twitter:image\");\n\n  // Extract SEO metadata\n  metadata.keywords = extractKeywords(document);\n  metadata.robots = extractMetaContent(document, \"robots\");\n  metadata.themeColor = extractMetaContent(document, \"theme-color\");\n\n  // Extract Open Graph metadata\n  metadata.openGraph = extractOpenGraph(document);\n\n  // Extract Twitter Card metadata\n  metadata.twitter = extractTwitterCard(document);\n\n  return metadata;\n}\n\n/**\n * Extract page title from HTML\n */\nfunction extractTitle(document: Document): string | null {\n  // Try <title> tag first\n  const titleElement = document.querySelector(\"title\");\n  if (titleElement?.textContent) {\n    return titleElement.textContent.trim();\n  }\n\n  // Fallback to og:title\n  return extractMetaContent(document, \"og:title\");\n}\n\n/**\n * Extract content from meta tag by name or property\n * Works regardless of attribute order\n */\nfunction extractMetaContent(document: Document, name: string): string | null {\n  // Try name attribute first\n  const byName = document.querySelector(`meta[name=\"${name}\"]`);\n  if (byName) {\n    const content = byName.getAttribute(\"content\");\n    if (content) return content.trim();\n  }\n\n  // Try property attribute (for Open Graph)\n  const byProperty = document.querySelector(`meta[property=\"${name}\"]`);\n  if (byProperty) {\n    const content = byProperty.getAttribute(\"content\");\n    if (content) return content.trim();\n  }\n\n  return null;\n}\n\n/**\n * Extract language from HTML tag\n */\nfunction extractLanguage(document: Document): string | null {\n  const lang = document.documentElement?.getAttribute(\"lang\");\n  return lang?.trim() || null;\n}\n\n/**\n * Extract character set from meta tag\n */\nfunction extractCharset(document: Document): string | null {\n  // Try <meta charset=\"...\">\n  const charsetMeta = document.querySelector(\"meta[charset]\");\n  if (charsetMeta) {\n    const charset = charsetMeta.getAttribute(\"charset\");\n    if (charset) return charset.trim();\n  }\n\n  // Try <meta http-equiv=\"Content-Type\" content=\"...charset=...\">\n  const httpEquivMeta = document.querySelector('meta[http-equiv=\"Content-Type\"]');\n  if (httpEquivMeta) {\n    const content = httpEquivMeta.getAttribute(\"content\");\n    if (content) {\n      const charsetMatch = content.match(/charset=([^\\s;]+)/i);\n      if (charsetMatch) return charsetMatch[1].trim();\n    }\n  }\n\n  return null;\n}\n\n/**\n * Extract favicon URL\n */\nfunction extractFavicon(document: Document, baseUrl: string): string | null {\n  // Try various icon link types\n  const iconSelectors = [\n    'link[rel=\"icon\"]',\n    'link[rel=\"shortcut icon\"]',\n    'link[rel=\"apple-touch-icon\"]',\n    'link[rel*=\"icon\"]',\n  ];\n\n  for (const selector of iconSelectors) {\n    const iconLink = document.querySelector(selector);\n    if (iconLink) {\n      const href = iconLink.getAttribute(\"href\");\n      if (href) {\n        return normalizeUrl(href, baseUrl);\n      }\n    }\n  }\n\n  // Fallback to /favicon.ico\n  try {\n    return normalizeUrl(\"/favicon.ico\", baseUrl);\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Extract canonical URL\n */\nfunction extractCanonical(document: Document, baseUrl: string): string | null {\n  const canonicalLink = document.querySelector('link[rel=\"canonical\"]');\n  if (canonicalLink) {\n    const href = canonicalLink.getAttribute(\"href\");\n    if (href) {\n      return normalizeUrl(href, baseUrl);\n    }\n  }\n\n  return null;\n}\n\n/**\n * Extract keywords from meta tag\n */\nfunction extractKeywords(document: Document): string[] | null {\n  const keywordsContent = extractMetaContent(document, \"keywords\");\n  if (!keywordsContent) {\n    return null;\n  }\n\n  return keywordsContent\n    .split(\",\")\n    .map((keyword) => keyword.trim())\n    .filter((keyword) => keyword.length > 0);\n}\n\n/**\n * Extract Open Graph metadata\n */\nfunction extractOpenGraph(document: Document): WebsiteMetadata[\"openGraph\"] {\n  const openGraph: WebsiteMetadata[\"openGraph\"] = {\n    title: null,\n    description: null,\n    type: null,\n    url: null,\n    image: null,\n    siteName: null,\n    locale: null,\n  };\n\n  openGraph.title = extractMetaContent(document, \"og:title\");\n  openGraph.description = extractMetaContent(document, \"og:description\");\n  openGraph.type = extractMetaContent(document, \"og:type\");\n  openGraph.url = extractMetaContent(document, \"og:url\");\n  openGraph.image = extractMetaContent(document, \"og:image\");\n  openGraph.siteName = extractMetaContent(document, \"og:site_name\");\n  openGraph.locale = extractMetaContent(document, \"og:locale\");\n\n  // Return null if no Open Graph data found\n  if (Object.values(openGraph).every((value) => !value)) {\n    return null;\n  }\n\n  return openGraph;\n}\n\n/**\n * Extract Twitter Card metadata\n */\nfunction extractTwitterCard(document: Document): WebsiteMetadata[\"twitter\"] {\n  const twitter: WebsiteMetadata[\"twitter\"] = {\n    card: null,\n    site: null,\n    creator: null,\n    title: null,\n    description: null,\n    image: null,\n  };\n\n  twitter.card = extractMetaContent(document, \"twitter:card\");\n  twitter.site = extractMetaContent(document, \"twitter:site\");\n  twitter.creator = extractMetaContent(document, \"twitter:creator\");\n  twitter.title = extractMetaContent(document, \"twitter:title\");\n  twitter.description = extractMetaContent(document, \"twitter:description\");\n  twitter.image = extractMetaContent(document, \"twitter:image\");\n\n  // Return null if no Twitter Card data found\n  if (Object.values(twitter).every((value) => !value)) {\n    return null;\n  }\n\n  return twitter;\n}\n\n/**\n * Extract structured data (JSON-LD) from HTML\n */\nexport function extractStructuredData(html: string): unknown[] {\n  const { document } = parseHTML(html);\n  const structuredData: unknown[] = [];\n\n  document.querySelectorAll('script[type=\"application/ld+json\"]').forEach((script: Element) => {\n    try {\n      const jsonData = JSON.parse(script.textContent || \"\");\n      structuredData.push(jsonData);\n    } catch {\n      // Invalid JSON, skip\n    }\n  });\n\n  return structuredData;\n}\n\n/**\n * Extract microdata from HTML (basic implementation)\n */\nexport function extractMicrodata(_html: string): unknown[] {\n  const microdata: unknown[] = [];\n  // This is a simplified implementation\n  // In a real-world scenario, you'd want to use a proper microdata parser\n  return microdata;\n}\n\n/**\n * Get a summary of the website metadata for debugging\n */\nexport function getMetadataSummary(metadata: WebsiteMetadata): string {\n  const parts: string[] = [];\n\n  if (metadata.title) parts.push(`Title: ${metadata.title}`);\n  if (metadata.description) parts.push(`Description: ${metadata.description.substring(0, 100)}...`);\n  if (metadata.author) parts.push(`Author: ${metadata.author}`);\n  if (metadata.language) parts.push(`Language: ${metadata.language}`);\n  if (metadata.keywords) parts.push(`Keywords: ${metadata.keywords.length} found`);\n  if (metadata.openGraph)\n    parts.push(`Open Graph: ${Object.keys(metadata.openGraph).length} fields`);\n  if (metadata.twitter) parts.push(`Twitter Card: ${Object.keys(metadata.twitter).length} fields`);\n\n  return parts.join(\" | \") || \"No metadata found\";\n}\n","import { URL } from \"url\";\nimport RE2 from \"re2\";\n\n/**\n * URL validation and normalization utilities\n */\n\n/**\n * Resolve a relative URL against a base URL\n */\nexport function resolveUrl(relative: string, base: string): string {\n  try {\n    return new URL(relative, base).toString();\n  } catch {\n    return relative;\n  }\n}\n\n/**\n * Validate if a string is a valid URL\n */\nexport function isValidUrl(string: string): boolean {\n  try {\n    new URL(string);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Normalize a URL by removing fragments and ensuring proper format\n */\nexport function normalizeUrl(url: string, baseUrl?: string): string {\n  try {\n    let parsedUrl: URL;\n\n    if (url.startsWith(\"http://\") || url.startsWith(\"https://\")) {\n      parsedUrl = new URL(url);\n    } else if (baseUrl) {\n      parsedUrl = new URL(url, baseUrl);\n    } else {\n      throw new Error(\"Relative URL requires base URL\");\n    }\n\n    // Remove fragment and search params for consistency\n    parsedUrl.hash = \"\";\n\n    return parsedUrl.toString();\n  } catch {\n    throw new Error(`Invalid URL: ${url}`);\n  }\n}\n\n/**\n * Extract base domain from a URL\n */\nexport function extractBaseDomain(url: string): string {\n  try {\n    const parsedUrl = new URL(url);\n    return parsedUrl.hostname;\n  } catch {\n    throw new Error(`Invalid URL for domain extraction: ${url}`);\n  }\n}\n\n/**\n * Extract the root domain from a hostname (e.g., \"blog.example.com\" -> \"example.com\")\n */\nfunction getRootDomain(hostname: string): string {\n  const parts = hostname.split(\".\");\n\n  // Handle edge cases\n  if (parts.length <= 2) {\n    return hostname;\n  }\n\n  // Handle common two-part TLDs (co.uk, com.au, etc.)\n  const twoPartTLDs = [\"co.uk\", \"com.au\", \"co.nz\", \"com.br\", \"co.jp\", \"co.kr\", \"com.mx\", \"org.uk\"];\n  const lastTwo = parts.slice(-2).join(\".\");\n\n  if (twoPartTLDs.includes(lastTwo)) {\n    // Return last 3 parts for two-part TLDs\n    return parts.slice(-3).join(\".\");\n  }\n\n  // Standard case: return last 2 parts\n  return parts.slice(-2).join(\".\");\n}\n\n/**\n * Check if a URL belongs to the same domain as the base URL\n * Supports subdomains: blog.example.com matches example.com\n */\nexport function isSameDomain(url: string, baseUrl: string): boolean {\n  try {\n    const urlDomain = extractBaseDomain(url);\n    const baseDomain = extractBaseDomain(baseUrl);\n\n    // Exact match\n    if (urlDomain === baseDomain) {\n      return true;\n    }\n\n    // Check if URL is a subdomain of base domain\n    // e.g., \"blog.example.com\" should match \"example.com\"\n    const urlRoot = getRootDomain(urlDomain);\n    const baseRoot = getRootDomain(baseDomain);\n\n    return urlRoot === baseRoot;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Generate a URL key for deduplication\n * Normalizes:\n * - Removes fragments (hash)\n * - Removes search params\n * - Removes trailing slashes (except root)\n * - Lowercases\n * - Normalizes www vs non-www\n * - Removes default ports (80 for http, 443 for https)\n * - Normalizes index files (index.html, index.htm, default.html)\n */\nexport function getUrlKey(url: string): string {\n  try {\n    const parsedUrl = new URL(url);\n\n    // Remove hash fragments\n    parsedUrl.hash = \"\";\n\n    // Remove search params for consistency\n    parsedUrl.search = \"\";\n\n    // Normalize www vs non-www (remove www. prefix for deduplication)\n    if (parsedUrl.hostname.startsWith(\"www.\")) {\n      parsedUrl.hostname = parsedUrl.hostname.slice(4);\n    }\n\n    // Remove default ports (80 for http, 443 for https)\n    if (\n      (parsedUrl.protocol === \"http:\" && parsedUrl.port === \"80\") ||\n      (parsedUrl.protocol === \"https:\" && parsedUrl.port === \"443\")\n    ) {\n      parsedUrl.port = \"\";\n    }\n\n    // Normalize index files (treat /path/index.html as /path/)\n    const indexFiles = [\"index.html\", \"index.htm\", \"default.html\", \"default.htm\", \"index.php\"];\n    for (const indexFile of indexFiles) {\n      if (parsedUrl.pathname.endsWith(`/${indexFile}`)) {\n        parsedUrl.pathname = parsedUrl.pathname.slice(0, -indexFile.length);\n        break;\n      }\n    }\n\n    // Normalize trailing slashes (keep for root path only)\n    let normalized = parsedUrl.toString().toLowerCase();\n    if (normalized.endsWith(\"/\") && parsedUrl.pathname !== \"/\") {\n      normalized = normalized.slice(0, -1);\n    }\n\n    return normalized;\n  } catch {\n    return url.toLowerCase();\n  }\n}\n\n/**\n * Validate an array of URLs and return validation results\n */\nexport function validateUrls(urls: string[]): {\n  isValid: boolean;\n  validUrls: string[];\n  errors: Array<{ url: string; error: string }>;\n} {\n  const validUrls: string[] = [];\n  const errors: Array<{ url: string; error: string }> = [];\n\n  if (!urls || urls.length === 0) {\n    return {\n      isValid: false,\n      validUrls: [],\n      errors: [{ url: \"\", error: \"At least one URL is required\" }],\n    };\n  }\n\n  for (const url of urls) {\n    if (!url || typeof url !== \"string\") {\n      errors.push({\n        url: String(url),\n        error: \"URL must be a non-empty string\",\n      });\n      continue;\n    }\n\n    const trimmedUrl = url.trim();\n    if (trimmedUrl === \"\") {\n      errors.push({ url: String(url), error: \"URL cannot be empty\" });\n      continue;\n    }\n\n    if (!isValidUrl(trimmedUrl)) {\n      errors.push({ url: trimmedUrl, error: \"Invalid URL format\" });\n      continue;\n    }\n\n    if (!trimmedUrl.startsWith(\"http://\") && !trimmedUrl.startsWith(\"https://\")) {\n      errors.push({\n        url: trimmedUrl,\n        error: \"URL must start with http:// or https://\",\n      });\n      continue;\n    }\n\n    validUrls.push(trimmedUrl);\n  }\n\n  // Remove duplicates while preserving order\n  const uniqueValidUrls = Array.from(new Set(validUrls));\n\n  return {\n    isValid: uniqueValidUrls.length > 0 && errors.length === 0,\n    validUrls: uniqueValidUrls,\n    errors,\n  };\n}\n\n/**\n * Check if a URL matches any of the given regex patterns\n *\n * Uses Google's RE2 engine which guarantees linear time execution,\n * preventing ReDoS attacks from malicious or pathological patterns.\n */\nexport function matchesPatterns(url: string, patterns: string[]): boolean {\n  if (!patterns || patterns.length === 0) {\n    return false;\n  }\n\n  return patterns.some((pattern) => {\n    try {\n      const regex = new RE2(pattern, \"i\");\n      return regex.test(url);\n    } catch {\n      // Invalid regex pattern or unsupported RE2 syntax, skip it\n      return false;\n    }\n  });\n}\n\n/**\n * Check if a URL should be included based on include/exclude patterns\n * - If includePatterns is set, URL must match at least one\n * - If excludePatterns is set, URL must not match any\n */\nexport function shouldIncludeUrl(\n  url: string,\n  includePatterns?: string[],\n  excludePatterns?: string[]\n): boolean {\n  // If include patterns are specified, URL must match at least one\n  if (includePatterns && includePatterns.length > 0) {\n    if (!matchesPatterns(url, includePatterns)) {\n      return false;\n    }\n  }\n\n  // If exclude patterns are specified, URL must not match any\n  if (excludePatterns && excludePatterns.length > 0) {\n    if (matchesPatterns(url, excludePatterns)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Check if a URL is likely a content page (not legal, policy, or utility page)\n * Used by crawler to filter out non-content pages\n */\nexport function isContentUrl(url: string): boolean {\n  const lowerUrl = url.toLowerCase();\n\n  // Skip legal and policy pages\n  const nonContentPatterns = [\n    // Legal and policy pages\n    /\\/(privacy|terms|tos|legal|cookie|gdpr|disclaimer|imprint|impressum)\\b/i,\n    /\\/(privacy-policy|terms-of-service|terms-of-use|terms-and-conditions)\\b/i,\n    /\\/(cookie-policy|data-protection|acceptable-use|user-agreement)\\b/i,\n    /\\/(refund|cancellation|shipping|return)-?(policy)?\\b/i,\n    // Contact and support pages (usually not main content)\n    /\\/(contact|support|help|faq|feedback)\\/?$/i,\n    // About pages that are typically boilerplate\n    /\\/(about-us|careers|jobs|press|investors|team)\\/?$/i,\n    // Authentication and admin areas\n    /\\/(admin|login|auth|account|dashboard|profile|settings)\\//i,\n    // E-commerce utility pages\n    /\\/(cart|checkout|payment|subscription|wishlist)\\//i,\n    // File downloads and assets\n    /\\/(uploads|assets|files|static|media|resources)\\//i,\n    // API endpoints\n    /\\/(api|graphql|rest|webhook)\\//i,\n  ];\n\n  if (nonContentPatterns.some((pattern) => pattern.test(lowerUrl))) {\n    return false;\n  }\n\n  // Skip common non-content file extensions\n  const skipExtensions = [\".pdf\", \".doc\", \".docx\", \".xls\", \".xlsx\", \".zip\", \".exe\"];\n  if (skipExtensions.some((ext) => lowerUrl.endsWith(ext))) {\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Check if a URL should be crawled based on various criteria\n */\nexport function shouldCrawlUrl(\n  url: string,\n  baseUrl: string,\n  maxDepth: number,\n  currentDepth: number,\n  visited: Set<string>\n): boolean {\n  // Check depth limit - FIXED: use > instead of >=\n  if (currentDepth > maxDepth) {\n    return false;\n  }\n\n  // Check if already visited\n  const urlKey = getUrlKey(url);\n  if (visited.has(urlKey)) {\n    return false;\n  }\n\n  // Check if same domain\n  if (!isSameDomain(url, baseUrl)) {\n    return false;\n  }\n\n  // Enhanced filtering for non-content files and patterns\n  const lowerUrl = url.toLowerCase();\n\n  // Skip common non-content file extensions\n  const skipExtensions = [\n    \".pdf\",\n    \".doc\",\n    \".docx\",\n    \".xls\",\n    \".xlsx\",\n    \".ppt\",\n    \".pptx\",\n    \".zip\",\n    \".rar\",\n    \".tar\",\n    \".gz\",\n    \".exe\",\n    \".dmg\",\n    \".pkg\",\n    \".deb\",\n    \".rpm\",\n    \".apk\",\n    \".ipa\",\n    // Image files\n    \".jpg\",\n    \".jpeg\",\n    \".png\",\n    \".gif\",\n    \".bmp\",\n    \".svg\",\n    \".webp\",\n    \".ico\",\n    \".favicon\",\n    // Video files\n    \".mp4\",\n    \".avi\",\n    \".mov\",\n    \".wmv\",\n    \".flv\",\n    \".webm\",\n    // Audio files\n    \".mp3\",\n    \".wav\",\n    \".ogg\",\n    \".m4a\",\n    \".aac\",\n    // Font files\n    \".woff\",\n    \".woff2\",\n    \".ttf\",\n    \".otf\",\n    \".eot\",\n    // Style and script files\n    \".css\",\n    \".js\",\n    \".mjs\",\n    \".ts\",\n    \".jsx\",\n    \".tsx\",\n    // Data and config files\n    \".json\",\n    \".xml\",\n    \".txt\",\n    \".md\",\n    \".rss\",\n    \".atom\",\n    \".sitemap\",\n    \".robots\",\n    \".webmanifest\",\n    // Archive files\n    \".zip\",\n    \".tar\",\n    \".gz\",\n    \".bz2\",\n    \".7z\",\n  ];\n\n  if (skipExtensions.some((ext) => lowerUrl.includes(ext))) {\n    return false;\n  }\n\n  // Skip common non-content URL patterns\n  const skipPatterns = [\n    // File downloads and assets\n    /\\/(uploads|assets|files|static|media|resources)\\//i,\n    // Authentication and admin areas\n    /\\/(admin|login|auth|account|dashboard|profile|settings)\\//i,\n    // API endpoints\n    /\\/(api|graphql|rest|ws:|webhook)\\//i,\n    // Common tracking and analytics\n    /\\/(analytics|tracking|pixel|beacon|ads)\\//i,\n    // Development and testing areas\n    /\\/(test|dev|staging|beta|demo)\\//i,\n    // Common utility and service pages\n    /\\/(search|cart|checkout|payment|subscription)\\//i,\n    // Social media and external services\n    /\\/(facebook|twitter|instagram|youtube|linkedin|github)\\//i,\n    // Legal and policy pages\n    /\\/(privacy|terms|tos|legal|cookie|gdpr|disclaimer|imprint|impressum)\\b/i,\n    /\\/(privacy-policy|terms-of-service|terms-of-use|terms-and-conditions)\\b/i,\n    /\\/(cookie-policy|data-protection|acceptable-use|user-agreement)\\b/i,\n    /\\/(refund|cancellation|shipping|return)-?(policy)?\\b/i,\n    // Contact and support pages (usually not main content)\n    /\\/(contact|support|help|faq|feedback)\\/?$/i,\n    // About pages that are typically boilerplate\n    /\\/(about-us|careers|jobs|press|investors|team)\\/?$/i,\n  ];\n\n  if (skipPatterns.some((pattern) => pattern.test(url))) {\n    return false;\n  }\n\n  // Skip URLs with query parameters that indicate non-content\n  if (\n    url.includes(\"?\") &&\n    [\"download\", \"file\", \"attachment\", \"export\", \"print\", \"share\", \"email\"].some((param) =>\n      url.toLowerCase().includes(param)\n    )\n  ) {\n    return false;\n  }\n\n  // Skip very short URLs (likely navigation or utility)\n  if (url.split(\"/\").filter(Boolean).length < 2 && url.split(\"?\")[0].split(\"/\").length <= 2) {\n    return false;\n  }\n\n  return true;\n}\n","import pino from \"pino\";\n\n/**\n * Logger type\n */\nexport type Logger = ReturnType<typeof createLogger>;\n\n/**\n * Check if pino-pretty is available\n */\nfunction hasPinoPretty(): boolean {\n  try {\n    require.resolve(\"pino-pretty\");\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Create a logger instance\n *\n * @param name - Logger name\n * @param level - Log level (default: from env or 'info')\n * @returns Pino logger instance\n */\nexport function createLogger(\n  name: string = \"reader\",\n  level: string = process.env.LOG_LEVEL || \"info\"\n) {\n  const usePretty =\n    process.env.NODE_ENV !== \"production\" && hasPinoPretty();\n\n  return pino({\n    name,\n    level,\n    transport: usePretty\n      ? {\n          target: \"pino-pretty\",\n          options: {\n            colorize: true,\n            translateTime: \"SYS:standard\",\n            ignore: \"pid,hostname\",\n          },\n        }\n      : undefined,\n  });\n}\n\n/**\n * Default logger instance\n */\nexport const logger = createLogger();\n","/**\n * Simple robots.txt parser for crawler compliance\n */\n\nexport interface RobotsRules {\n  disallowedPaths: string[];\n  allowedPaths: string[];\n  crawlDelay: number | null;\n}\n\n/**\n * Parse robots.txt content and extract rules for a specific user agent\n */\nexport function parseRobotsTxt(content: string, userAgent: string = \"*\"): RobotsRules {\n  const rules: RobotsRules = {\n    disallowedPaths: [],\n    allowedPaths: [],\n    crawlDelay: null,\n  };\n\n  const lines = content.split(\"\\n\").map((line) => line.trim());\n  let currentUserAgent = \"\";\n  let matchesUserAgent = false;\n\n  for (const line of lines) {\n    // Skip empty lines and comments\n    if (!line || line.startsWith(\"#\")) {\n      continue;\n    }\n\n    const colonIndex = line.indexOf(\":\");\n    if (colonIndex === -1) {\n      continue;\n    }\n\n    const directive = line.substring(0, colonIndex).trim().toLowerCase();\n    const value = line.substring(colonIndex + 1).trim();\n\n    if (directive === \"user-agent\") {\n      currentUserAgent = value.toLowerCase();\n      // Match specific user agent or wildcard\n      matchesUserAgent = currentUserAgent === \"*\" || currentUserAgent === userAgent.toLowerCase();\n    } else if (matchesUserAgent) {\n      if (directive === \"disallow\" && value) {\n        rules.disallowedPaths.push(value);\n      } else if (directive === \"allow\" && value) {\n        rules.allowedPaths.push(value);\n      } else if (directive === \"crawl-delay\") {\n        const delay = parseFloat(value);\n        if (!isNaN(delay)) {\n          rules.crawlDelay = delay * 1000; // Convert to milliseconds\n        }\n      }\n    }\n  }\n\n  return rules;\n}\n\n/**\n * Check if a URL path is allowed by robots.txt rules\n */\nexport function isPathAllowed(path: string, rules: RobotsRules): boolean {\n  // Normalize path\n  const normalizedPath = path.startsWith(\"/\") ? path : \"/\" + path;\n\n  // Check allow rules first (they take precedence)\n  for (const allowedPath of rules.allowedPaths) {\n    if (pathMatches(normalizedPath, allowedPath)) {\n      return true;\n    }\n  }\n\n  // Check disallow rules\n  for (const disallowedPath of rules.disallowedPaths) {\n    if (pathMatches(normalizedPath, disallowedPath)) {\n      return false;\n    }\n  }\n\n  // Default: allowed\n  return true;\n}\n\n/**\n * Check if a path matches a robots.txt pattern\n * Supports * (wildcard) and $ (end anchor)\n */\nfunction pathMatches(path: string, pattern: string): boolean {\n  // Empty pattern matches nothing\n  if (!pattern) {\n    return false;\n  }\n\n  // Convert robots.txt pattern to regex\n  let regexPattern = pattern\n    .replace(/[.+?^${}()|[\\]\\\\]/g, \"\\\\$&\") // Escape regex special chars except * and $\n    .replace(/\\*/g, \".*\"); // * becomes .*\n\n  // Handle $ end anchor\n  if (regexPattern.endsWith(\"\\\\$\")) {\n    regexPattern = regexPattern.slice(0, -2) + \"$\";\n  } else {\n    regexPattern = \"^\" + regexPattern;\n  }\n\n  try {\n    const regex = new RegExp(regexPattern);\n    return regex.test(path);\n  } catch {\n    // Invalid pattern, treat as literal prefix match\n    return path.startsWith(pattern);\n  }\n}\n\n/**\n * Fetch and parse robots.txt for a given base URL\n */\nexport async function fetchRobotsTxt(baseUrl: string): Promise<RobotsRules | null> {\n  try {\n    const url = new URL(\"/robots.txt\", baseUrl);\n    const response = await fetch(url.toString(), {\n      headers: {\n        \"User-Agent\": \"ReaderEngine/1.0\",\n      },\n    });\n\n    if (!response.ok) {\n      // No robots.txt or error - allow everything\n      return null;\n    }\n\n    const content = await response.text();\n    return parseRobotsTxt(content, \"ReaderEngine\");\n  } catch {\n    // Network error or invalid URL - allow everything\n    return null;\n  }\n}\n\n/**\n * Check if a URL is allowed by robots.txt\n */\nexport function isUrlAllowed(url: string, rules: RobotsRules | null): boolean {\n  if (!rules) {\n    return true;\n  }\n\n  try {\n    const parsedUrl = new URL(url);\n    return isPathAllowed(parsedUrl.pathname + parsedUrl.search, rules);\n  } catch {\n    return true;\n  }\n}\n","import type { IBrowserPool } from \"./browser/types\";\nimport type { EngineName } from \"./engines/types.js\";\n\n/**\n * Proxy configuration for Hero\n */\nexport interface ProxyConfig {\n  /** Full proxy URL (takes precedence over other fields) */\n  url?: string;\n  /** Proxy type */\n  type?: \"datacenter\" | \"residential\";\n  /** Proxy username */\n  username?: string;\n  /** Proxy password */\n  password?: string;\n  /** Proxy host */\n  host?: string;\n  /** Proxy port */\n  port?: number;\n  /** Country code for residential proxies (e.g., 'us', 'uk') */\n  country?: string;\n}\n\n/**\n * Proxy metadata in scrape results\n */\nexport interface ProxyMetadata {\n  /** Proxy host that was used */\n  host: string;\n  /** Proxy port that was used */\n  port: number;\n  /** Country code if geo-targeting was used */\n  country?: string;\n}\n\n/**\n * Browser pool configuration for ReaderClient\n */\nexport interface BrowserPoolConfig {\n  /** Number of browser instances (default: 2) */\n  size?: number;\n  /** Retire browser after this many page loads (default: 100) */\n  retireAfterPages?: number;\n  /** Retire browser after this many minutes (default: 30) */\n  retireAfterMinutes?: number;\n  /** Maximum pending requests in queue (default: 100) */\n  maxQueueSize?: number;\n}\n\n/**\n * Main scraping options interface\n */\nexport interface ScrapeOptions {\n  /** Array of URLs to scrape */\n  urls: string[];\n\n  /** Output formats - which content fields to include (default: ['markdown']) */\n  formats?: Array<\"markdown\" | \"html\">;\n\n  /** Custom user agent string */\n  userAgent?: string;\n\n  /** Custom headers for requests */\n  headers?: Record<string, string>;\n\n  /** Request timeout in milliseconds (default: 30000) */\n  timeoutMs?: number;\n\n  /** URL patterns to include (regex strings) */\n  includePatterns?: string[];\n\n  /** URL patterns to exclude (regex strings) */\n  excludePatterns?: string[];\n\n  // ============================================================================\n  // Content cleaning options\n  // ============================================================================\n\n  /** Remove ads and tracking elements (default: true) */\n  removeAds?: boolean;\n\n  /** Remove base64-encoded images to reduce output size (default: true) */\n  removeBase64Images?: boolean;\n\n  /** Extract only main content, removing nav/header/footer/sidebar (default: true) */\n  onlyMainContent?: boolean;\n\n  /** CSS selectors for elements to include (if set, only these elements are kept) */\n  includeTags?: string[];\n\n  /** CSS selectors for elements to exclude (removed from output) */\n  excludeTags?: string[];\n\n  /** Skip TLS/SSL certificate verification (default: true) */\n  skipTLSVerification?: boolean;\n\n  // ============================================================================\n  // Batch processing options\n  // ============================================================================\n\n  /** Number of URLs to process in parallel (default: 1 - sequential) */\n  batchConcurrency?: number;\n\n  /** Total timeout for the entire batch operation in milliseconds (default: 300000) */\n  batchTimeoutMs?: number;\n\n  /** Maximum retry attempts for failed URLs (default: 2) */\n  maxRetries?: number;\n\n  /** Progress callback for batch operations */\n  onProgress?: (progress: { completed: number; total: number; currentUrl: string }) => void;\n\n  // ============================================================================\n  // Hero-specific options\n  // ============================================================================\n\n  /** Proxy configuration for Hero */\n  proxy?: ProxyConfig;\n\n  /** CSS selector to wait for before considering page loaded */\n  waitForSelector?: string;\n\n  /** Enable verbose logging (default: false) */\n  verbose?: boolean;\n\n  /** Show Chrome window (default: false) */\n  showChrome?: boolean;\n\n  /** Connection to Hero Core (for shared Core usage) */\n  connectionToCore?: any;\n\n  /** Browser pool configuration (passed from ReaderClient) */\n  browserPool?: BrowserPoolConfig;\n\n  /** Browser pool instance (internal, provided by ReaderClient) */\n  pool?: IBrowserPool;\n\n  // ============================================================================\n  // Engine options\n  // ============================================================================\n\n  /** Engines to use in order (default: ['http', 'tlsclient', 'hero']) */\n  engines?: EngineName[];\n\n  /** Skip specific engines (e.g., ['http'] to skip native fetch) */\n  skipEngines?: EngineName[];\n\n  /** Force a specific engine, skipping the cascade */\n  forceEngine?: EngineName;\n}\n\n/**\n * Website metadata extracted from the base page\n */\nexport interface WebsiteMetadata {\n  /** Basic meta tags */\n  title: string | null /** <title> or <meta property=\"og:title\"> */;\n  description: string | null /** <meta name=\"description\"> */;\n  author: string | null /** <meta name=\"author\"> */;\n  language: string | null /** <html lang=\"...\"> */;\n  charset: string | null /** <meta charset=\"...\"> */;\n\n  /** Links */\n  favicon: string | null /** <link rel=\"icon\"> */;\n  image: string | null /** <meta property=\"og:image\"> */;\n  canonical: string | null /** <link rel=\"canonical\"> */;\n\n  /** SEO */\n  keywords: string[] | null /** <meta name=\"keywords\"> */;\n  robots: string | null /** <meta name=\"robots\"> */;\n\n  /** Branding */\n  themeColor: string | null /** <meta name=\"theme-color\"> */;\n\n  /** Open Graph */\n  openGraph: {\n    title: string | null /** <meta property=\"og:title\"> */;\n    description: string | null /** <meta property=\"og:description\"> */;\n    type: string | null /** <meta property=\"og:type\"> */;\n    url: string | null /** <meta property=\"og:url\"> */;\n    image: string | null /** <meta property=\"og:image\"> */;\n    siteName: string | null /** <meta property=\"og:site_name\"> */;\n    locale: string | null /** <meta property=\"og:locale\"> */;\n  } | null;\n\n  /** Twitter Card */\n  twitter: {\n    card: string | null /** <meta name=\"twitter:card\"> */;\n    site: string | null /** <meta name=\"twitter:site\"> */;\n    creator: string | null /** <meta name=\"twitter:creator\"> */;\n    title: string | null /** <meta name=\"twitter:title\"> */;\n    description: string | null /** <meta name=\"twitter:description\"> */;\n    image: string | null /** <meta name=\"twitter:image\"> */;\n  } | null;\n}\n\n/**\n * Individual page data\n */\nexport interface Page {\n  /** Full URL of the page */\n  url: string;\n\n  /** Page title */\n  title: string;\n\n  /** Markdown content */\n  markdown: string;\n\n  /** HTML content */\n  html: string;\n\n  /** When the page was fetched */\n  fetchedAt: string;\n\n  /** Crawl depth from base URL */\n  depth: number;\n\n  // ============================================================================\n  // Hero-specific fields\n  // ============================================================================\n\n  /** Whether a Cloudflare challenge was detected */\n  hadChallenge?: boolean;\n\n  /** Type of challenge encountered */\n  challengeType?: string;\n\n  /** Time spent waiting for challenge resolution (ms) */\n  waitTimeMs?: number;\n}\n\n/**\n * Individual website scrape result\n */\nexport interface WebsiteScrapeResult {\n  /** Markdown content (present if 'markdown' in formats) */\n  markdown?: string;\n\n  /** HTML content (present if 'html' in formats) */\n  html?: string;\n\n  /** Metadata about the scraping operation */\n  metadata: {\n    /** Base URL that was scraped */\n    baseUrl: string;\n\n    /** Total number of pages scraped */\n    totalPages: number;\n\n    /** ISO timestamp when scraping started */\n    scrapedAt: string;\n\n    /** Duration in milliseconds */\n    duration: number;\n\n    /** Website metadata extracted from base page */\n    website: WebsiteMetadata;\n\n    /** Proxy used for this request (if proxy pooling was enabled) */\n    proxy?: ProxyMetadata;\n  };\n}\n\n/**\n * Batch metadata for multi-URL operations\n */\nexport interface BatchMetadata {\n  /** Total number of URLs provided */\n  totalUrls: number;\n\n  /** Number of URLs successfully scraped */\n  successfulUrls: number;\n\n  /** Number of URLs that failed */\n  failedUrls: number;\n\n  /** ISO timestamp when the batch operation started */\n  scrapedAt: string;\n\n  /** Total duration for the entire batch in milliseconds */\n  totalDuration: number;\n\n  /** Array of errors for failed URLs */\n  errors?: Array<{ url: string; error: string }>;\n}\n\n/**\n * Main scrape result interface\n */\nexport interface ScrapeResult {\n  /** Array of individual website results */\n  data: WebsiteScrapeResult[];\n\n  /** Metadata about the batch operation */\n  batchMetadata: BatchMetadata;\n}\n\n/**\n * Internal crawler state\n */\nexport interface CrawlerState {\n  /** Set of visited URLs to avoid duplicates */\n  visited: Set<string>;\n\n  /** Queue of URLs to process */\n  queue: Array<{ url: string; depth: number }>;\n\n  /** Completed pages */\n  pages: Page[];\n}\n\n/**\n * Internal scraper configuration\n */\nexport interface ScraperConfig {\n  /** Merged options with defaults */\n  options: Required<ScrapeOptions>;\n\n  /** Parsed base URL */\n  baseUrl: URL;\n\n  /** Base domain for same-origin checking */\n  baseDomain: string;\n}\n\n/**\n * Default scrape options\n */\nexport const DEFAULT_OPTIONS: Omit<\n  Required<ScrapeOptions>,\n  \"proxy\" | \"waitForSelector\" | \"connectionToCore\" | \"userAgent\" | \"headers\" | \"browserPool\" | \"pool\" | \"engines\" | \"skipEngines\" | \"forceEngine\"\n> & {\n  proxy?: ProxyConfig;\n  waitForSelector?: string;\n  connectionToCore?: any;\n  userAgent?: string;\n  headers?: Record<string, string>;\n  browserPool?: BrowserPoolConfig;\n  pool?: IBrowserPool;\n  engines?: EngineName[];\n  skipEngines?: EngineName[];\n  forceEngine?: EngineName;\n} = {\n  urls: [],\n  formats: [\"markdown\"],\n  timeoutMs: 30000,\n  includePatterns: [],\n  excludePatterns: [],\n  // Content cleaning defaults\n  removeAds: true,\n  removeBase64Images: true,\n  onlyMainContent: true,\n  includeTags: [],\n  excludeTags: [],\n  skipTLSVerification: true,\n  // Batch defaults\n  batchConcurrency: 1,\n  batchTimeoutMs: 300000,\n  maxRetries: 2,\n  onProgress: () => {}, // Default no-op progress callback\n  // Hero-specific defaults\n  verbose: false,\n  showChrome: false,\n};\n\n/**\n * Format type guard\n */\nexport function isValidFormat(format: string): format is \"markdown\" | \"html\" {\n  return format === \"markdown\" || format === \"html\";\n}\n\n/**\n * Check if a URL should be crawled based on base domain\n */\nexport function shouldCrawlUrl(url: URL, baseDomain: string): boolean {\n  return url.hostname === baseDomain || url.hostname.endsWith(`.${baseDomain}`);\n}\n","/**\n * Engine types for multi-engine scraping architecture\n *\n * Engine stack (in order of preference):\n * 1. http - Native fetch, fastest, no browser\n * 2. tlsclient - TLS fingerprinting via got-scraping\n * 3. hero - Full browser with JavaScript execution\n */\n\nimport type { ScrapeOptions } from \"../types.js\";\nimport type { Logger } from \"../utils/logger.js\";\n\n/**\n * Available engine names\n */\nexport type EngineName = \"http\" | \"tlsclient\" | \"hero\";\n\n/**\n * Result returned by an engine after scraping\n */\nexport interface EngineResult {\n  /** Raw HTML content */\n  html: string;\n  /** Final URL after redirects */\n  url: string;\n  /** HTTP status code */\n  statusCode: number;\n  /** Content-Type header */\n  contentType?: string;\n  /** Response headers */\n  headers?: Record<string, string>;\n\n  /** Engine that produced this result */\n  engine: EngineName;\n  /** Time taken in milliseconds */\n  duration: number;\n}\n\n/**\n * Metadata passed to engine scrape method\n */\nexport interface EngineMeta {\n  /** URL to scrape */\n  url: string;\n  /** Scrape options */\n  options: ScrapeOptions;\n  /** Logger instance */\n  logger?: Logger;\n  /** Abort signal for cancellation */\n  abortSignal?: AbortSignal;\n}\n\n/**\n * Engine configuration\n */\nexport interface EngineConfig {\n  /** Engine name */\n  name: EngineName;\n  /** Timeout before starting next engine (ms) */\n  timeout: number;\n  /** Absolute max time before killing (ms) */\n  maxTimeout: number;\n  /** Quality score - higher means preferred (for sorting) */\n  quality: number;\n  /** Engine capabilities */\n  features: EngineFeatures;\n}\n\n/**\n * Engine feature flags\n */\nexport interface EngineFeatures {\n  /** Can execute JavaScript */\n  javascript: boolean;\n  /** Can handle Cloudflare challenges */\n  cloudflare: boolean;\n  /** Matches browser TLS fingerprint */\n  tlsFingerprint: boolean;\n  /** Supports waitFor selector */\n  waitFor: boolean;\n  /** Can take screenshots */\n  screenshots: boolean;\n}\n\n/**\n * Engine interface - all engines must implement this\n */\nexport interface Engine {\n  /** Engine configuration */\n  readonly config: EngineConfig;\n\n  /**\n   * Scrape a URL\n   * @param meta - Scrape metadata (url, options, logger, abortSignal)\n   * @returns Engine result with HTML and metadata\n   * @throws EngineError on failure\n   */\n  scrape(meta: EngineMeta): Promise<EngineResult>;\n\n  /**\n   * Check if engine is available and configured\n   * @returns true if engine can be used\n   */\n  isAvailable(): boolean;\n}\n\n/**\n * Default engine configurations\n */\nexport const ENGINE_CONFIGS: Record<EngineName, EngineConfig> = {\n  http: {\n    name: \"http\",\n    timeout: 3000,\n    maxTimeout: 10000,\n    quality: 100,\n    features: {\n      javascript: false,\n      cloudflare: false,\n      tlsFingerprint: false,\n      waitFor: false,\n      screenshots: false,\n    },\n  },\n  tlsclient: {\n    name: \"tlsclient\",\n    timeout: 5000,\n    maxTimeout: 15000,\n    quality: 80,\n    features: {\n      javascript: false,\n      cloudflare: false,\n      tlsFingerprint: true,\n      waitFor: false,\n      screenshots: false,\n    },\n  },\n  hero: {\n    name: \"hero\",\n    timeout: 30000,\n    maxTimeout: 60000,\n    quality: 50,\n    features: {\n      javascript: true,\n      cloudflare: true,\n      tlsFingerprint: true,\n      waitFor: true,\n      screenshots: true,\n    },\n  },\n};\n\n/**\n * Default engine order (by quality, highest first)\n */\nexport const DEFAULT_ENGINE_ORDER: EngineName[] = [\"http\", \"tlsclient\", \"hero\"];\n","/**\n * Engine-specific error classes\n *\n * These errors are used internally by engines and the orchestrator\n * to signal specific failure conditions and control flow.\n */\n\nimport type { EngineName } from \"./types.js\";\n\n/**\n * Base error for all engine errors\n */\nexport class EngineError extends Error {\n  readonly engine: EngineName;\n  readonly retryable: boolean;\n\n  constructor(engine: EngineName, message: string, options?: { cause?: Error; retryable?: boolean }) {\n    super(`[${engine}] ${message}`);\n    this.name = \"EngineError\";\n    this.engine = engine;\n    this.retryable = options?.retryable ?? true;\n    this.cause = options?.cause;\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n}\n\n/**\n * Challenge detected (Cloudflare, CAPTCHA, etc.)\n * Signals orchestrator to try next engine\n */\nexport class ChallengeDetectedError extends EngineError {\n  readonly challengeType: string;\n\n  constructor(engine: EngineName, challengeType?: string) {\n    super(engine, `Challenge detected: ${challengeType || \"unknown\"}`, { retryable: true });\n    this.name = \"ChallengeDetectedError\";\n    this.challengeType = challengeType || \"unknown\";\n  }\n}\n\n/**\n * Content too short or empty\n * May indicate blocked page or JS-required content\n */\nexport class InsufficientContentError extends EngineError {\n  readonly contentLength: number;\n  readonly threshold: number;\n\n  constructor(engine: EngineName, contentLength: number, threshold: number = 100) {\n    super(engine, `Insufficient content: ${contentLength} chars (threshold: ${threshold})`, { retryable: true });\n    this.name = \"InsufficientContentError\";\n    this.contentLength = contentLength;\n    this.threshold = threshold;\n  }\n}\n\n/**\n * HTTP error status (4xx, 5xx)\n */\nexport class HttpError extends EngineError {\n  readonly statusCode: number;\n\n  constructor(engine: EngineName, statusCode: number, statusText?: string) {\n    const retryable = statusCode >= 500 || statusCode === 429;\n    super(engine, `HTTP ${statusCode}${statusText ? `: ${statusText}` : \"\"}`, { retryable });\n    this.name = \"HttpError\";\n    this.statusCode = statusCode;\n  }\n}\n\n/**\n * Engine timeout\n */\nexport class EngineTimeoutError extends EngineError {\n  readonly timeoutMs: number;\n\n  constructor(engine: EngineName, timeoutMs: number) {\n    super(engine, `Timeout after ${timeoutMs}ms`, { retryable: true });\n    this.name = \"EngineTimeoutError\";\n    this.timeoutMs = timeoutMs;\n  }\n}\n\n/**\n * Engine not available (not configured, missing dependency)\n */\nexport class EngineUnavailableError extends EngineError {\n  constructor(engine: EngineName, reason?: string) {\n    super(engine, reason || \"Engine not available\", { retryable: false });\n    this.name = \"EngineUnavailableError\";\n  }\n}\n\n/**\n * Signal to orchestrator to move to next engine\n * Not a real error - used for control flow\n */\nexport class NextEngineSignal extends Error {\n  readonly fromEngine: EngineName;\n  readonly reason: string;\n\n  constructor(fromEngine: EngineName, reason: string) {\n    super(`Next engine signal from ${fromEngine}: ${reason}`);\n    this.name = \"NextEngineSignal\";\n    this.fromEngine = fromEngine;\n    this.reason = reason;\n  }\n}\n\n/**\n * All engines exhausted without success\n */\nexport class AllEnginesFailedError extends Error {\n  readonly attemptedEngines: EngineName[];\n  readonly errors: Map<EngineName, Error>;\n\n  constructor(attemptedEngines: EngineName[], errors: Map<EngineName, Error>) {\n    const summary = attemptedEngines\n      .map((e) => `${e}: ${errors.get(e)?.message || \"unknown\"}`)\n      .join(\"; \");\n    super(`All engines failed: ${summary}`);\n    this.name = \"AllEnginesFailedError\";\n    this.attemptedEngines = attemptedEngines;\n    this.errors = errors;\n  }\n}\n","/**\n * HTTP Engine - Native fetch\n *\n * Fastest engine, no browser overhead.\n * Works for ~60-70% of static sites.\n * Falls back to tlsclient/hero when blocked or challenged.\n */\n\nimport type { Engine, EngineConfig, EngineMeta, EngineResult } from \"../types.js\";\nimport {\n  EngineError,\n  ChallengeDetectedError,\n  InsufficientContentError,\n  HttpError,\n  EngineTimeoutError,\n} from \"../errors.js\";\nimport { ENGINE_CONFIGS } from \"../types.js\";\n\n/**\n * Browser-like headers for fetch requests\n */\nconst DEFAULT_HEADERS: Record<string, string> = {\n  \"User-Agent\":\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n  Accept: \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n  \"Accept-Language\": \"en-US,en;q=0.9\",\n  \"Accept-Encoding\": \"gzip, deflate, br\",\n  \"Cache-Control\": \"no-cache\",\n  Pragma: \"no-cache\",\n  \"Sec-Fetch-Dest\": \"document\",\n  \"Sec-Fetch-Mode\": \"navigate\",\n  \"Sec-Fetch-Site\": \"none\",\n  \"Sec-Fetch-User\": \"?1\",\n  \"Upgrade-Insecure-Requests\": \"1\",\n};\n\n/**\n * Challenge indicators in HTML content\n * These patterns suggest the page requires JS execution or is blocked\n */\nconst CHALLENGE_PATTERNS = [\n  // Cloudflare\n  \"cf-browser-verification\",\n  \"cf_chl_opt\",\n  \"challenge-platform\",\n  \"cf-spinner\",\n  \"Just a moment\",\n  \"Checking your browser\",\n  \"checking if the site connection is secure\",\n  \"Enable JavaScript and cookies\",\n  \"Attention Required\",\n  \"_cf_chl_tk\",\n  \"Verifying you are human\",\n  \"cf-turnstile\",\n  \"/cdn-cgi/challenge-platform/\",\n\n  // Generic bot detection\n  \"Please Wait...\",\n  \"DDoS protection by\",\n  \"Access denied\",\n  \"bot detection\",\n  \"are you a robot\",\n  \"complete the security check\",\n];\n\n/**\n * Patterns indicating Cloudflare infrastructure\n */\nconst CLOUDFLARE_INFRA_PATTERNS = [\"/cdn-cgi/\", \"cloudflare\", \"__cf_bm\", \"cf-ray\"];\n\n/**\n * Minimum content length threshold (characters)\n */\nconst MIN_CONTENT_LENGTH = 100;\n\n/**\n * HTTP Engine implementation using native fetch\n */\nexport class HttpEngine implements Engine {\n  readonly config: EngineConfig = ENGINE_CONFIGS.http;\n\n  async scrape(meta: EngineMeta): Promise<EngineResult> {\n    const startTime = Date.now();\n    const { url, options, logger, abortSignal } = meta;\n\n    try {\n      // Create abort controller for timeout\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), this.config.maxTimeout);\n\n      // Link external abort signal\n      if (abortSignal) {\n        abortSignal.addEventListener(\"abort\", () => controller.abort(), { once: true });\n      }\n\n      logger?.debug(`[http] Fetching ${url}`);\n\n      const response = await fetch(url, {\n        method: \"GET\",\n        headers: {\n          ...DEFAULT_HEADERS,\n          ...(options.headers || {}),\n        },\n        redirect: \"follow\",\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeoutId);\n\n      const duration = Date.now() - startTime;\n      const html = await response.text();\n\n      logger?.debug(`[http] Got response: ${response.status} (${html.length} chars) in ${duration}ms`);\n\n      // Check for HTTP errors\n      if (response.status >= 400) {\n        throw new HttpError(\"http\", response.status, response.statusText);\n      }\n\n      // Check for challenge pages\n      const challengeType = this.detectChallenge(html);\n      if (challengeType) {\n        logger?.debug(`[http] Challenge detected: ${challengeType}`);\n        throw new ChallengeDetectedError(\"http\", challengeType);\n      }\n\n      // Check for sufficient content\n      const textContent = this.extractText(html);\n      if (textContent.length < MIN_CONTENT_LENGTH) {\n        logger?.debug(`[http] Insufficient content: ${textContent.length} chars`);\n        throw new InsufficientContentError(\"http\", textContent.length, MIN_CONTENT_LENGTH);\n      }\n\n      return {\n        html,\n        url: response.url,\n        statusCode: response.status,\n        contentType: response.headers.get(\"content-type\") || undefined,\n        headers: this.headersToRecord(response.headers),\n        engine: \"http\",\n        duration,\n      };\n    } catch (error: unknown) {\n      // Re-throw our own errors\n      if (\n        error instanceof ChallengeDetectedError ||\n        error instanceof InsufficientContentError ||\n        error instanceof HttpError\n      ) {\n        throw error;\n      }\n\n      // Handle abort/timeout\n      if (error instanceof Error) {\n        if (error.name === \"AbortError\") {\n          throw new EngineTimeoutError(\"http\", this.config.maxTimeout);\n        }\n\n        // Wrap other errors\n        throw new EngineError(\"http\", error.message, { cause: error });\n      }\n\n      throw new EngineError(\"http\", String(error));\n    }\n  }\n\n  /**\n   * Detect challenge patterns in HTML\n   * @returns Challenge type or null if no challenge detected\n   */\n  private detectChallenge(html: string): string | null {\n    const htmlLower = html.toLowerCase();\n\n    // Check for Cloudflare infrastructure + challenge patterns\n    const hasCloudflare = CLOUDFLARE_INFRA_PATTERNS.some((p) => htmlLower.includes(p.toLowerCase()));\n\n    for (const pattern of CHALLENGE_PATTERNS) {\n      if (htmlLower.includes(pattern.toLowerCase())) {\n        if (hasCloudflare || pattern.includes(\"cf\")) {\n          return \"cloudflare\";\n        }\n        return \"bot-detection\";\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Convert Headers to Record<string, string>\n   */\n  private headersToRecord(headers: Headers): Record<string, string> {\n    const record: Record<string, string> = {};\n    headers.forEach((value, key) => {\n      record[key] = value;\n    });\n    return record;\n  }\n\n  /**\n   * Extract visible text from HTML (rough extraction)\n   */\n  private extractText(html: string): string {\n    return html\n      .replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\")\n      .replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\")\n      .replace(/<[^>]+>/g, \" \")\n      .replace(/\\s+/g, \" \")\n      .trim();\n  }\n\n  isAvailable(): boolean {\n    return true; // Native fetch is always available in Node.js 18+\n  }\n}\n\n/**\n * Singleton instance\n */\nexport const httpEngine = new HttpEngine();\n","/**\n * TLS Client Engine - got-scraping\n *\n * Uses got-scraping for browser-like TLS fingerprinting.\n * Better compatibility with sites that check TLS signatures.\n * Falls back to hero when JS execution is required.\n */\n\nimport { gotScraping } from \"got-scraping\";\nimport type { Engine, EngineConfig, EngineMeta, EngineResult } from \"../types.js\";\nimport {\n  EngineError,\n  ChallengeDetectedError,\n  InsufficientContentError,\n  HttpError,\n  EngineTimeoutError,\n  EngineUnavailableError,\n} from \"../errors.js\";\nimport { ENGINE_CONFIGS } from \"../types.js\";\n\n/**\n * Challenge indicators that require JS execution\n */\nconst JS_REQUIRED_PATTERNS = [\n  // Cloudflare JS challenge\n  \"cf-browser-verification\",\n  \"challenge-platform\",\n  \"_cf_chl_tk\",\n  \"/cdn-cgi/challenge-platform/\",\n\n  // Generic JS requirements\n  \"Enable JavaScript\",\n  \"JavaScript is required\",\n  \"Please enable JavaScript\",\n  \"requires JavaScript\",\n  \"noscript\",\n];\n\n/**\n * Blocked/denied patterns\n */\nconst BLOCKED_PATTERNS = [\n  \"Access denied\",\n  \"Sorry, you have been blocked\",\n  \"bot detected\",\n  \"suspicious activity\",\n  \"too many requests\",\n];\n\n/**\n * Minimum content length threshold\n */\nconst MIN_CONTENT_LENGTH = 100;\n\n/**\n * TLS Client Engine implementation using got-scraping\n */\nexport class TlsClientEngine implements Engine {\n  readonly config: EngineConfig = ENGINE_CONFIGS.tlsclient;\n  private available: boolean = true;\n\n  constructor() {\n    // Check if got-scraping is properly loaded\n    try {\n      if (!gotScraping) {\n        this.available = false;\n      }\n    } catch {\n      this.available = false;\n    }\n  }\n\n  async scrape(meta: EngineMeta): Promise<EngineResult> {\n    if (!this.available) {\n      throw new EngineUnavailableError(\"tlsclient\", \"got-scraping not available\");\n    }\n\n    const startTime = Date.now();\n    const { url, options, logger, abortSignal } = meta;\n\n    try {\n      // Create abort controller for timeout\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), this.config.maxTimeout);\n\n      // Link external abort signal\n      if (abortSignal) {\n        abortSignal.addEventListener(\"abort\", () => controller.abort(), { once: true });\n      }\n\n      logger?.debug(`[tlsclient] Fetching ${url}`);\n\n      const response = await gotScraping({\n        url,\n        timeout: {\n          request: this.config.maxTimeout,\n        },\n        headers: options.headers,\n        followRedirect: true,\n        // got-scraping handles browser fingerprinting automatically\n        // It uses header generators and proper TLS settings\n      });\n\n      clearTimeout(timeoutId);\n\n      const duration = Date.now() - startTime;\n      const html = response.body;\n\n      logger?.debug(`[tlsclient] Got response: ${response.statusCode} (${html.length} chars) in ${duration}ms`);\n\n      // Check for HTTP errors\n      if (response.statusCode >= 400) {\n        throw new HttpError(\"tlsclient\", response.statusCode, response.statusMessage);\n      }\n\n      // Check for JS-required challenges\n      const challengeType = this.detectJsRequired(html);\n      if (challengeType) {\n        logger?.debug(`[tlsclient] JS required: ${challengeType}`);\n        throw new ChallengeDetectedError(\"tlsclient\", challengeType);\n      }\n\n      // Check for blocked patterns\n      const blockedReason = this.detectBlocked(html);\n      if (blockedReason) {\n        logger?.debug(`[tlsclient] Blocked: ${blockedReason}`);\n        throw new ChallengeDetectedError(\"tlsclient\", `blocked: ${blockedReason}`);\n      }\n\n      // Check for sufficient content\n      const textContent = this.extractText(html);\n      if (textContent.length < MIN_CONTENT_LENGTH) {\n        logger?.debug(`[tlsclient] Insufficient content: ${textContent.length} chars`);\n        throw new InsufficientContentError(\"tlsclient\", textContent.length, MIN_CONTENT_LENGTH);\n      }\n\n      return {\n        html,\n        url: response.url,\n        statusCode: response.statusCode,\n        contentType: response.headers[\"content-type\"] as string | undefined,\n        headers: response.headers as Record<string, string>,\n        engine: \"tlsclient\",\n        duration,\n      };\n    } catch (error: unknown) {\n      // Re-throw our own errors\n      if (\n        error instanceof ChallengeDetectedError ||\n        error instanceof InsufficientContentError ||\n        error instanceof HttpError ||\n        error instanceof EngineUnavailableError\n      ) {\n        throw error;\n      }\n\n      // Handle timeout\n      if (error instanceof Error) {\n        if (error.name === \"TimeoutError\" || error.message.includes(\"timeout\")) {\n          throw new EngineTimeoutError(\"tlsclient\", this.config.maxTimeout);\n        }\n\n        if (error.name === \"AbortError\") {\n          throw new EngineTimeoutError(\"tlsclient\", this.config.maxTimeout);\n        }\n\n        // Wrap other errors\n        throw new EngineError(\"tlsclient\", error.message, { cause: error });\n      }\n\n      throw new EngineError(\"tlsclient\", String(error));\n    }\n  }\n\n  /**\n   * Detect patterns that require JS execution\n   */\n  private detectJsRequired(html: string): string | null {\n    const htmlLower = html.toLowerCase();\n\n    for (const pattern of JS_REQUIRED_PATTERNS) {\n      if (htmlLower.includes(pattern.toLowerCase())) {\n        if (pattern.includes(\"cf\") || pattern.includes(\"cloudflare\")) {\n          return \"cloudflare-js\";\n        }\n        return \"js-required\";\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Detect blocked/denied patterns\n   */\n  private detectBlocked(html: string): string | null {\n    const htmlLower = html.toLowerCase();\n\n    for (const pattern of BLOCKED_PATTERNS) {\n      if (htmlLower.includes(pattern.toLowerCase())) {\n        return pattern;\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Extract visible text from HTML\n   */\n  private extractText(html: string): string {\n    return html\n      .replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\")\n      .replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\")\n      .replace(/<[^>]+>/g, \" \")\n      .replace(/\\s+/g, \" \")\n      .trim();\n  }\n\n  isAvailable(): boolean {\n    return this.available;\n  }\n}\n\n/**\n * Singleton instance\n */\nexport const tlsClientEngine = new TlsClientEngine();\n","import type Hero from \"@ulixee/hero\";\nimport type { ChallengeDetection } from \"./types\";\n\n/**\n * CLOUDFLARE-SPECIFIC DOM SELECTORS\n *\n * These are ONLY present during active Cloudflare challenges.\n * We query for actual DOM elements, not string matching.\n */\nconst CLOUDFLARE_CHALLENGE_SELECTORS = [\n  \"#challenge-running\",\n  \"#challenge-stage\",\n  \"#challenge-form\",\n  \".cf-browser-verification\",\n  \"#cf-wrapper\",\n  \"#cf-hcaptcha-container\",\n  \"#turnstile-wrapper\",\n];\n\n/**\n * CLOUDFLARE-SPECIFIC TEXT PATTERNS\n *\n * These phrases only appear during active Cloudflare challenges.\n * Must be combined with other Cloudflare signals to avoid false positives.\n */\nconst CLOUDFLARE_TEXT_PATTERNS = [\n  \"checking if the site connection is secure\",\n  \"this process is automatic. your browser will redirect\",\n  \"ray id:\",\n  \"performance & security by cloudflare\",\n];\n\n/**\n * CLOUDFLARE INFRASTRUCTURE SIGNALS\n *\n * Indicators that the page is served by Cloudflare\n */\nconst CLOUDFLARE_INFRA_PATTERNS = [\n  \"/cdn-cgi/\",\n  \"cloudflare\",\n  \"__cf_bm\",\n  \"cf-ray\",\n];\n\n/**\n * BLOCKED/403 SIGNALS (Cloudflare-specific)\n *\n * Detect when Cloudflare explicitly blocks access\n */\nconst CLOUDFLARE_BLOCKED_PATTERNS = [\n  \"sorry, you have been blocked\",\n  \"ray id:\",\n];\n\n/**\n * Detect if current page is a Cloudflare challenge\n *\n * Uses multi-signal approach requiring BOTH:\n * 1. Cloudflare infrastructure indicators (cdn-cgi, cf-ray, etc.)\n * 2. Challenge-specific elements or text\n *\n * This prevents false positives on login pages or other sites\n * that happen to use similar text.\n *\n * @param hero - Hero instance with loaded page\n * @returns Detection result with confidence score and signals\n */\nexport async function detectChallenge(hero: Hero): Promise<ChallengeDetection> {\n  const signals: string[] = [];\n  let type: ChallengeDetection[\"type\"] = \"none\";\n  let hasCloudflareInfra = false;\n  let hasChallengeIndicator = false;\n\n  try {\n    // Ensure we have access to document\n    if (!hero.document) {\n      return {\n        isChallenge: false,\n        type: \"none\",\n        confidence: 0,\n        signals: [\"No document available\"],\n      };\n    }\n\n    // =========================================================================\n    // CHECK 1: CLOUDFLARE INFRASTRUCTURE (required for any detection)\n    // =========================================================================\n    const html = await hero.document.documentElement.outerHTML;\n    const htmlLower = html.toLowerCase();\n\n    for (const pattern of CLOUDFLARE_INFRA_PATTERNS) {\n      if (htmlLower.includes(pattern)) {\n        hasCloudflareInfra = true;\n        signals.push(`Cloudflare infra: \"${pattern}\"`);\n        break;\n      }\n    }\n\n    // If no Cloudflare infrastructure detected, it's not a Cloudflare challenge\n    if (!hasCloudflareInfra) {\n      return {\n        isChallenge: false,\n        type: \"none\",\n        confidence: 0,\n        signals: [\"No Cloudflare infrastructure detected\"],\n      };\n    }\n\n    // =========================================================================\n    // CHECK 2: CHALLENGE DOM ELEMENTS (using actual DOM queries)\n    // =========================================================================\n    for (const selector of CLOUDFLARE_CHALLENGE_SELECTORS) {\n      try {\n        const element = await hero.document.querySelector(selector);\n        if (element) {\n          hasChallengeIndicator = true;\n          signals.push(`Challenge element: ${selector}`);\n          type = \"js_challenge\";\n        }\n      } catch {\n        // Element not found, continue\n      }\n    }\n\n    // =========================================================================\n    // CHECK 3: CHALLENGE-SPECIFIC TEXT\n    // =========================================================================\n    for (const pattern of CLOUDFLARE_TEXT_PATTERNS) {\n      if (htmlLower.includes(pattern)) {\n        hasChallengeIndicator = true;\n        signals.push(`Challenge text: \"${pattern}\"`);\n        type = type === \"none\" ? \"js_challenge\" : type;\n      }\n    }\n\n    // =========================================================================\n    // CHECK 4: \"WAITING FOR\" + \"TO RESPOND\" (Cloudflare-specific combo)\n    // =========================================================================\n    if (htmlLower.includes(\"waiting for\") && htmlLower.includes(\"to respond\")) {\n      hasChallengeIndicator = true;\n      signals.push('Challenge text: \"waiting for...to respond\"');\n      type = type === \"none\" ? \"js_challenge\" : type;\n    }\n\n    // =========================================================================\n    // CHECK 5: CLOUDFLARE BLOCKED DETECTION\n    // =========================================================================\n    // Check for blocked page with Ray ID (Cloudflare-specific)\n    const hasBlocked = CLOUDFLARE_BLOCKED_PATTERNS.every((p) => htmlLower.includes(p));\n    if (hasBlocked) {\n      hasChallengeIndicator = true;\n      signals.push(\"Cloudflare block page detected\");\n      type = \"blocked\";\n    }\n\n    // Challenge only if we have BOTH Cloudflare infra AND challenge indicators\n    const isChallenge = hasCloudflareInfra && hasChallengeIndicator;\n    const confidence = isChallenge ? 100 : 0;\n\n    return {\n      isChallenge,\n      type: isChallenge ? type : \"none\",\n      confidence,\n      signals,\n    };\n  } catch (error: any) {\n    return {\n      isChallenge: false,\n      type: \"none\",\n      confidence: 0,\n      signals: [`Error during detection: ${error.message}`],\n    };\n  }\n}\n\n/**\n * Quick check - just returns boolean\n *\n * @param hero - Hero instance\n * @returns True if challenge page detected\n */\nexport async function isChallengePage(hero: Hero): Promise<boolean> {\n  const detection = await detectChallenge(hero);\n  return detection.isChallenge;\n}\n","import type Hero from \"@ulixee/hero\";\nimport { detectChallenge } from \"./detector\";\nimport type { ChallengeResolutionResult, ChallengeWaitOptions } from \"./types\";\n\n/**\n * Wait for Cloudflare challenge to resolve\n *\n * Uses multiple detection strategies:\n * 1. URL redirect detection (page redirects after challenge)\n * 2. Signal polling (challenge-specific elements/text disappear)\n *\n * @param hero - Hero instance with challenge page loaded\n * @param options - Waiting options\n * @returns Resolution result with method and time waited\n *\n * @example\n * const result = await waitForChallengeResolution(hero, {\n *   maxWaitMs: 45000,\n *   pollIntervalMs: 500,\n *   verbose: true,\n *   initialUrl: 'https://example.com'\n * });\n *\n * if (result.resolved) {\n *   console.log(`Challenge resolved via ${result.method} in ${result.waitedMs}ms`);\n * }\n */\nexport async function waitForChallengeResolution(\n  hero: Hero,\n  options: ChallengeWaitOptions\n): Promise<ChallengeResolutionResult> {\n  const { maxWaitMs = 45000, pollIntervalMs = 500, verbose = false, initialUrl } = options;\n\n  const startTime = Date.now();\n  const log = (msg: string) => verbose && console.log(`   ${msg}`);\n\n  while (Date.now() - startTime < maxWaitMs) {\n    const elapsed = Date.now() - startTime;\n\n    // =========================================================================\n    // STRATEGY 1: Check for URL change (redirect after challenge)\n    // =========================================================================\n    try {\n      const currentUrl = await hero.url;\n      if (currentUrl !== initialUrl) {\n        log(`âœ“ URL changed: ${initialUrl} â†’ ${currentUrl}`);\n        // Wait for the new page to fully load after redirect\n        log(`  Waiting for new page to load...`);\n        try {\n          await hero.waitForLoad(\"DomContentLoaded\", { timeoutMs: 30000 });\n          log(`  DOMContentLoaded`);\n        } catch {\n          log(`  DOMContentLoaded timeout, continuing...`);\n        }\n        // Additional wait for JS to execute and render\n        await hero.waitForPaintingStable().catch(() => {});\n        log(`  Page stabilized`);\n        return { resolved: true, method: \"url_redirect\", waitedMs: elapsed };\n      }\n    } catch {\n      // URL check failed, continue with other strategies\n    }\n\n    // =========================================================================\n    // STRATEGY 2: Check if challenge signals are gone\n    // =========================================================================\n    const detection = await detectChallenge(hero);\n\n    if (!detection.isChallenge) {\n      log(`âœ“ Challenge signals cleared (confidence dropped to ${detection.confidence})`);\n      // Wait for page to fully load after challenge clears\n      log(`  Waiting for page to load...`);\n      try {\n        await hero.waitForLoad(\"DomContentLoaded\", { timeoutMs: 30000 });\n        log(`  DOMContentLoaded`);\n      } catch {\n        log(`  DOMContentLoaded timeout, continuing...`);\n      }\n      await hero.waitForPaintingStable().catch(() => {});\n      log(`  Page stabilized`);\n      return { resolved: true, method: \"signals_cleared\", waitedMs: elapsed };\n    }\n\n    // Log progress\n    log(\n      `â³ ${(elapsed / 1000).toFixed(1)}s - Still challenge (confidence: ${detection.confidence})`\n    );\n\n    // Wait before next poll\n    await new Promise((resolve) => setTimeout(resolve, pollIntervalMs));\n  }\n\n  // Timeout reached\n  return {\n    resolved: false,\n    method: \"timeout\",\n    waitedMs: Date.now() - startTime,\n  };\n}\n\n/**\n * Wait for a specific CSS selector to appear\n *\n * Useful when you know exactly what element should appear after challenge.\n *\n * @param hero - Hero instance\n * @param selector - CSS selector to wait for\n * @param maxWaitMs - Maximum time to wait\n * @param verbose - Enable logging\n * @returns Whether selector was found and time waited\n *\n * @example\n * const result = await waitForSelector(hero, '.content', 30000, true);\n * if (result.found) {\n *   console.log(`Content appeared after ${result.waitedMs}ms`);\n * }\n */\nexport async function waitForSelector(\n  hero: Hero,\n  selector: string,\n  maxWaitMs: number,\n  verbose: boolean = false\n): Promise<{ found: boolean; waitedMs: number }> {\n  const startTime = Date.now();\n  const log = (msg: string) => verbose && console.log(`   ${msg}`);\n\n  log(`Waiting for selector: \"${selector}\"`);\n\n  while (Date.now() - startTime < maxWaitMs) {\n    try {\n      const element = await hero.document.querySelector(selector);\n      if (element) {\n        const elapsed = Date.now() - startTime;\n        log(`âœ“ Selector found after ${(elapsed / 1000).toFixed(1)}s`);\n        return { found: true, waitedMs: elapsed };\n      }\n    } catch {\n      // Selector not found yet, continue\n    }\n\n    await new Promise((resolve) => setTimeout(resolve, 300));\n  }\n\n  log(`âœ— Selector not found within timeout`);\n  return { found: false, waitedMs: Date.now() - startTime };\n}\n\n/**\n * Handle Cloudflare challenge with automatic detection and waiting\n *\n * High-level function that combines detection and resolution.\n *\n * @param hero - Hero instance\n * @param options - Wait options (without initialUrl)\n * @returns Resolution result\n *\n * @example\n * await hero.goto('https://example.com');\n * const result = await handleChallenge(hero, { verbose: true });\n * if (result.resolved) {\n *   // Challenge passed, continue scraping\n * }\n */\nexport async function handleChallenge(\n  hero: Hero,\n  options: Omit<ChallengeWaitOptions, \"initialUrl\"> = {}\n): Promise<ChallengeResolutionResult> {\n  // Get current URL\n  const initialUrl = await hero.url;\n\n  // Detect challenge\n  const detection = await detectChallenge(hero);\n\n  if (!detection.isChallenge) {\n    // No challenge, return immediately\n    return { resolved: true, method: \"signals_cleared\", waitedMs: 0 };\n  }\n\n  // Challenge detected, wait for resolution\n  return waitForChallengeResolution(hero, {\n    ...options,\n    initialUrl,\n  });\n}\n","/**\n * Hero Engine - Full browser with JavaScript execution\n *\n * Uses Hero browser automation with browser pool.\n * Handles JavaScript-heavy sites and challenge pages.\n * Most capable but slowest engine - used as fallback.\n */\n\nimport Hero from \"@ulixee/hero\";\nimport type { Engine, EngineConfig, EngineMeta, EngineResult } from \"../types.js\";\nimport {\n  EngineError,\n  ChallengeDetectedError,\n  InsufficientContentError,\n  EngineTimeoutError,\n  EngineUnavailableError,\n} from \"../errors.js\";\nimport { ENGINE_CONFIGS } from \"../types.js\";\nimport { detectChallenge } from \"../../cloudflare/detector.js\";\nimport { waitForChallengeResolution } from \"../../cloudflare/handler.js\";\nimport type { IBrowserPool } from \"../../browser/types.js\";\n\n/**\n * Minimum content length threshold\n */\nconst MIN_CONTENT_LENGTH = 100;\n\n/**\n * Hero Engine implementation using browser pool\n */\nexport class HeroEngine implements Engine {\n  readonly config: EngineConfig = ENGINE_CONFIGS.hero;\n\n  async scrape(meta: EngineMeta): Promise<EngineResult> {\n    const startTime = Date.now();\n    const { url, options, logger, abortSignal } = meta;\n\n    // Get browser pool from options\n    const pool = options.pool as IBrowserPool | undefined;\n    if (!pool) {\n      throw new EngineUnavailableError(\"hero\", \"Browser pool not available\");\n    }\n\n    // Check for abort before starting\n    if (abortSignal?.aborted) {\n      throw new EngineTimeoutError(\"hero\", 0);\n    }\n\n    logger?.debug(`[hero] Starting browser scrape of ${url}`);\n\n    try {\n      const result = await pool.withBrowser(async (hero: Hero) => {\n        // Set up abort handling\n        let aborted = false;\n        if (abortSignal) {\n          abortSignal.addEventListener(\"abort\", () => {\n            aborted = true;\n          }, { once: true });\n        }\n\n        // Navigate to URL\n        const timeoutMs = options.timeoutMs || this.config.maxTimeout;\n        await hero.goto(url, { timeoutMs });\n\n        if (aborted) {\n          throw new EngineTimeoutError(\"hero\", Date.now() - startTime);\n        }\n\n        // Wait for initial page load\n        try {\n          await hero.waitForLoad(\"DomContentLoaded\", { timeoutMs });\n        } catch {\n          // Timeout is OK, continue anyway\n        }\n        await hero.waitForPaintingStable();\n\n        if (aborted) {\n          throw new EngineTimeoutError(\"hero\", Date.now() - startTime);\n        }\n\n        // Detect and handle Cloudflare challenge\n        const initialUrl = await hero.url;\n        const detection = await detectChallenge(hero);\n\n        if (detection.isChallenge) {\n          logger?.debug(`[hero] Challenge detected: ${detection.type}`);\n\n          // If it's a blocked challenge, we can't proceed\n          if (detection.type === \"blocked\") {\n            throw new ChallengeDetectedError(\"hero\", \"blocked\");\n          }\n\n          // Wait for resolution\n          const resolution = await waitForChallengeResolution(hero, {\n            maxWaitMs: 45000,\n            pollIntervalMs: 500,\n            verbose: options.verbose,\n            initialUrl,\n          });\n\n          if (!resolution.resolved) {\n            throw new ChallengeDetectedError(\"hero\", `unresolved: ${detection.type}`);\n          }\n\n          logger?.debug(`[hero] Challenge resolved via ${resolution.method} in ${resolution.waitedMs}ms`);\n        }\n\n        if (aborted) {\n          throw new EngineTimeoutError(\"hero\", Date.now() - startTime);\n        }\n\n        // Wait for final page to stabilize (handles Cloudflare silent redirects)\n        await this.waitForFinalPage(hero, url, logger);\n\n        if (aborted) {\n          throw new EngineTimeoutError(\"hero\", Date.now() - startTime);\n        }\n\n        // Wait for selector if specified\n        if (options.waitForSelector) {\n          try {\n            await hero.waitForElement(hero.document.querySelector(options.waitForSelector), {\n              timeoutMs,\n            });\n          } catch {\n            logger?.debug(`[hero] Selector not found: ${options.waitForSelector}`);\n          }\n        }\n\n        // Extract content\n        const html = await hero.document.documentElement.outerHTML;\n        const finalUrl = await hero.url;\n\n        // Validate content length\n        const textContent = this.extractText(html);\n        if (textContent.length < MIN_CONTENT_LENGTH) {\n          logger?.debug(`[hero] Insufficient content: ${textContent.length} chars`);\n          throw new InsufficientContentError(\"hero\", textContent.length, MIN_CONTENT_LENGTH);\n        }\n\n        const duration = Date.now() - startTime;\n        logger?.debug(`[hero] Success: ${html.length} chars in ${duration}ms`);\n\n        return {\n          html,\n          url: finalUrl,\n          statusCode: 200, // Hero doesn't expose status code directly\n          engine: \"hero\" as const,\n          duration,\n        };\n      });\n\n      return result;\n    } catch (error: unknown) {\n      // Re-throw our own errors\n      if (\n        error instanceof ChallengeDetectedError ||\n        error instanceof InsufficientContentError ||\n        error instanceof EngineTimeoutError ||\n        error instanceof EngineUnavailableError\n      ) {\n        throw error;\n      }\n\n      // Handle specific error types\n      if (error instanceof Error) {\n        // Timeout errors\n        if (error.name === \"TimeoutError\" || error.message.includes(\"timeout\")) {\n          throw new EngineTimeoutError(\"hero\", this.config.maxTimeout);\n        }\n\n        // Navigation errors\n        if (error.message.includes(\"Navigation\") || error.message.includes(\"ERR_\")) {\n          throw new EngineError(\"hero\", `Navigation failed: ${error.message}`, { cause: error });\n        }\n\n        // Wrap other errors\n        throw new EngineError(\"hero\", error.message, { cause: error });\n      }\n\n      throw new EngineError(\"hero\", String(error));\n    }\n  }\n\n  /**\n   * Wait for the final page to load after any Cloudflare redirects\n   */\n  private async waitForFinalPage(hero: Hero, originalUrl: string, logger?: EngineMeta[\"logger\"]): Promise<void> {\n    const maxWaitMs = 15000;\n    const startTime = Date.now();\n\n    // Wait for any pending navigation to complete\n    try {\n      await hero.waitForLoad(\"AllContentLoaded\", { timeoutMs: maxWaitMs });\n    } catch {\n      // Timeout is OK\n    }\n\n    // Check if URL changed (Cloudflare redirect)\n    let currentUrl = await hero.url;\n    const normalizeUrl = (url: string) => url.replace(/\\/+$/, \"\");\n    const urlChanged = normalizeUrl(currentUrl) !== normalizeUrl(originalUrl);\n\n    if (urlChanged || currentUrl.includes(\"__cf_chl\")) {\n      logger?.debug(`[hero] Cloudflare redirect detected: ${originalUrl} â†’ ${currentUrl}`);\n\n      // Wait for the redirect to complete and new page to load\n      let lastUrl = currentUrl;\n      let stableCount = 0;\n\n      while (Date.now() - startTime < maxWaitMs) {\n        await new Promise((resolve) => setTimeout(resolve, 500));\n\n        try {\n          currentUrl = await hero.url;\n\n          // URL is stable if it hasn't changed for 2 consecutive checks\n          if (currentUrl === lastUrl) {\n            stableCount++;\n            if (stableCount >= 2) {\n              break;\n            }\n          } else {\n            stableCount = 0;\n            lastUrl = currentUrl;\n            logger?.debug(`[hero] URL changed to: ${currentUrl}`);\n          }\n        } catch {\n          // Error getting URL, continue waiting\n        }\n      }\n\n      // Final wait for page content to render\n      try {\n        await hero.waitForLoad(\"AllContentLoaded\", { timeoutMs: 10000 });\n      } catch {\n        // Timeout OK\n      }\n    }\n\n    // Final stabilization\n    await hero.waitForPaintingStable();\n\n    // Buffer for JS execution and dynamic content loading\n    await new Promise((resolve) => setTimeout(resolve, 2000));\n  }\n\n  /**\n   * Extract visible text from HTML\n   */\n  private extractText(html: string): string {\n    return html\n      .replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\")\n      .replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\")\n      .replace(/<[^>]+>/g, \" \")\n      .replace(/\\s+/g, \" \")\n      .trim();\n  }\n\n  isAvailable(): boolean {\n    // Hero is always available if we can import it\n    // Actual pool availability is checked in scrape()\n    return true;\n  }\n}\n\n/**\n * Singleton instance\n */\nexport const heroEngine = new HeroEngine();\n","/**\n * Engine Orchestrator\n *\n * Manages multi-engine scraping with waterfall fallback pattern.\n * Tries engines in order of speed/efficiency:\n *   1. http - Native fetch, fastest, works for static sites\n *   2. tlsclient - TLS fingerprinting for better compatibility\n *   3. hero - Full browser, handles Cloudflare and JS-heavy sites\n *\n * Features:\n * - Staggered timeouts (each engine gets its configured time before fallback)\n * - Parallel racing option (start next engine while previous still running)\n * - Graceful fallback on challenge detection\n * - Detailed error tracking per engine\n */\n\nimport type { Engine, EngineName, EngineMeta, EngineResult } from \"./types.js\";\nimport { DEFAULT_ENGINE_ORDER } from \"./types.js\";\nimport {\n  EngineError,\n  ChallengeDetectedError,\n  InsufficientContentError,\n  HttpError,\n  EngineTimeoutError,\n  EngineUnavailableError,\n  AllEnginesFailedError,\n} from \"./errors.js\";\nimport { httpEngine } from \"./http/index.js\";\nimport { tlsClientEngine } from \"./tlsclient/index.js\";\nimport { heroEngine } from \"./hero/index.js\";\nimport type { Logger } from \"../utils/logger.js\";\n\n/**\n * Orchestrator options\n */\nexport interface OrchestratorOptions {\n  /** Engines to use (in order). Default: ['http', 'tlsclient', 'hero'] */\n  engines?: EngineName[];\n  /** Skip specific engines */\n  skipEngines?: EngineName[];\n  /** Force a specific engine (skips others) */\n  forceEngine?: EngineName;\n  /** Enable parallel racing (start next engine while previous still running) */\n  parallelRacing?: boolean;\n  /** Logger instance */\n  logger?: Logger;\n  /** Verbose logging */\n  verbose?: boolean;\n}\n\n/**\n * Engine registry\n */\nconst ENGINE_REGISTRY: Record<EngineName, Engine> = {\n  http: httpEngine,\n  tlsclient: tlsClientEngine,\n  hero: heroEngine,\n};\n\n/**\n * Orchestrator result with engine metadata\n */\nexport interface OrchestratorResult extends EngineResult {\n  /** Engines that were attempted */\n  attemptedEngines: EngineName[];\n  /** Errors from failed engines */\n  engineErrors: Map<EngineName, Error>;\n}\n\n/**\n * Engine Orchestrator\n *\n * Coordinates multiple scraping engines with fallback logic.\n *\n * @example\n * const orchestrator = new EngineOrchestrator({ verbose: true });\n * const result = await orchestrator.scrape({\n *   url: 'https://example.com',\n *   options: { timeoutMs: 30000 }\n * });\n * console.log(`Scraped with ${result.engine} engine`);\n */\nexport class EngineOrchestrator {\n  private options: OrchestratorOptions;\n  private engines: Engine[];\n  private engineOrder: EngineName[];\n\n  constructor(options: OrchestratorOptions = {}) {\n    this.options = options;\n    this.engineOrder = this.resolveEngineOrder();\n    this.engines = this.engineOrder\n      .map((name) => ENGINE_REGISTRY[name])\n      .filter((engine) => engine.isAvailable());\n  }\n\n  /**\n   * Resolve the engine order based on options\n   */\n  private resolveEngineOrder(): EngineName[] {\n    // If force engine is set, use only that\n    if (this.options.forceEngine) {\n      return [this.options.forceEngine];\n    }\n\n    // Start with configured order or default\n    let order = this.options.engines || [...DEFAULT_ENGINE_ORDER];\n\n    // Remove skipped engines\n    if (this.options.skipEngines) {\n      order = order.filter((e) => !this.options.skipEngines!.includes(e));\n    }\n\n    return order;\n  }\n\n  /**\n   * Get available engines\n   */\n  getAvailableEngines(): EngineName[] {\n    return this.engines.map((e) => e.config.name);\n  }\n\n  /**\n   * Scrape a URL using the engine cascade\n   *\n   * @param meta - Engine metadata (url, options, logger, abortSignal)\n   * @returns Scrape result with engine metadata\n   * @throws AllEnginesFailedError if all engines fail\n   */\n  async scrape(meta: EngineMeta): Promise<OrchestratorResult> {\n    const attemptedEngines: EngineName[] = [];\n    const engineErrors = new Map<EngineName, Error>();\n    const logger = meta.logger || this.options.logger;\n    const verbose = this.options.verbose || meta.options.verbose;\n\n    if (this.engines.length === 0) {\n      throw new AllEnginesFailedError([], engineErrors);\n    }\n\n    const log = (msg: string) => {\n      if (verbose) {\n        logger?.info(msg);\n      } else {\n        logger?.debug(msg);\n      }\n    };\n\n    log(`[orchestrator] Starting scrape of ${meta.url} with engines: ${this.engineOrder.join(\" â†’ \")}`);\n\n    // Try each engine in order\n    for (const engine of this.engines) {\n      const engineName = engine.config.name;\n      attemptedEngines.push(engineName);\n\n      try {\n        log(`[orchestrator] Trying ${engineName} engine...`);\n\n        // Create abort controller for this engine's timeout\n        const controller = new AbortController();\n        const timeoutId = setTimeout(() => controller.abort(), engine.config.maxTimeout);\n\n        // Link external abort signal\n        if (meta.abortSignal) {\n          meta.abortSignal.addEventListener(\"abort\", () => controller.abort(), { once: true });\n        }\n\n        try {\n          const result = await engine.scrape({\n            ...meta,\n            abortSignal: controller.signal,\n          });\n\n          clearTimeout(timeoutId);\n\n          log(`[orchestrator] âœ“ ${engineName} succeeded in ${result.duration}ms`);\n\n          return {\n            ...result,\n            attemptedEngines,\n            engineErrors,\n          };\n        } finally {\n          clearTimeout(timeoutId);\n        }\n      } catch (error: unknown) {\n        const err = error instanceof Error ? error : new Error(String(error));\n        engineErrors.set(engineName, err);\n\n        // Log the error with appropriate detail\n        if (error instanceof ChallengeDetectedError) {\n          log(`[orchestrator] ${engineName} detected challenge: ${error.challengeType}`);\n        } else if (error instanceof InsufficientContentError) {\n          log(`[orchestrator] ${engineName} insufficient content: ${error.contentLength} chars`);\n        } else if (error instanceof HttpError) {\n          log(`[orchestrator] ${engineName} HTTP error: ${error.statusCode}`);\n        } else if (error instanceof EngineTimeoutError) {\n          log(`[orchestrator] ${engineName} timed out after ${error.timeoutMs}ms`);\n        } else if (error instanceof EngineUnavailableError) {\n          log(`[orchestrator] ${engineName} unavailable: ${err.message}`);\n        } else {\n          log(`[orchestrator] ${engineName} failed: ${err.message}`);\n        }\n\n        // Check if we should continue to next engine\n        if (!this.shouldRetry(error)) {\n          log(`[orchestrator] Non-retryable error, stopping cascade`);\n          break;\n        }\n\n        // Continue to next engine\n        log(`[orchestrator] Falling back to next engine...`);\n      }\n    }\n\n    // All engines failed\n    log(`[orchestrator] All engines failed for ${meta.url}`);\n    throw new AllEnginesFailedError(attemptedEngines, engineErrors);\n  }\n\n  /**\n   * Determine if we should retry with next engine\n   */\n  private shouldRetry(error: unknown): boolean {\n    // Always retry on these errors\n    if (\n      error instanceof ChallengeDetectedError ||\n      error instanceof InsufficientContentError ||\n      error instanceof EngineTimeoutError\n    ) {\n      return true;\n    }\n\n    // Retry on HTTP errors that might be bot detection or server issues\n    // 403 Forbidden - often bot detection, try better fingerprinting\n    // 404 Not Found - might be JS-rendered SPA that needs browser\n    // 429 Too Many Requests - rate limited, try different engine\n    // 5xx Server errors - might be blocking, try again\n    if (error instanceof HttpError) {\n      return error.statusCode === 403 || error.statusCode === 404 || error.statusCode === 429 || error.statusCode >= 500;\n    }\n\n    // Don't retry on unavailable (won't help)\n    if (error instanceof EngineUnavailableError) {\n      return true; // Skip to next engine\n    }\n\n    // Generic engine errors - check retryable flag\n    if (error instanceof EngineError) {\n      return error.retryable;\n    }\n\n    // Unknown errors - retry\n    return true;\n  }\n}\n\n/**\n * Create an orchestrator with default settings\n */\nexport function createOrchestrator(options: OrchestratorOptions = {}): EngineOrchestrator {\n  return new EngineOrchestrator(options);\n}\n\n/**\n * Convenience function to scrape with orchestrator\n *\n * @example\n * const result = await orchestratedScrape({\n *   url: 'https://example.com',\n *   options: { pool }\n * });\n */\nexport async function orchestratedScrape(\n  meta: EngineMeta,\n  options: OrchestratorOptions = {}\n): Promise<OrchestratorResult> {\n  const orchestrator = new EngineOrchestrator(options);\n  return orchestrator.scrape(meta);\n}\n","import Hero from \"@ulixee/hero\";\nimport { parseHTML } from \"linkedom\";\nimport type { IBrowserPool } from \"./browser/types\";\nimport { detectChallenge } from \"./cloudflare/detector\";\nimport { waitForChallengeResolution } from \"./cloudflare/handler\";\nimport { resolveUrl, isValidUrl, isSameDomain, getUrlKey, isContentUrl, shouldIncludeUrl } from \"./utils/url-helpers\";\nimport { fetchRobotsTxt, isUrlAllowed, type RobotsRules } from \"./utils/robots-parser\";\nimport { rateLimit } from \"./utils/rate-limiter\";\nimport { createLogger } from \"./utils/logger\";\nimport { scrape } from \"./scraper\";\nimport type { CrawlOptions, CrawlResult, CrawlUrl, CrawlMetadata } from \"./crawl-types\";\nimport type { ScrapeResult } from \"./types\";\n\n/**\n * Crawler class for discovering and optionally scraping pages\n *\n * Features:\n * - BFS/DFS crawling with depth control\n * - Automatic Cloudflare challenge handling\n * - Link extraction and filtering\n * - Optional full content scraping\n * - URL deduplication\n *\n * @example\n * const crawler = new Crawler({\n *   url: 'https://example.com',\n *   depth: 2,\n *   maxPages: 20,\n *   scrape: true\n * });\n *\n * const result = await crawler.crawl();\n * console.log(`Discovered ${result.urls.length} URLs`);\n */\nexport class Crawler {\n  private options: Omit<\n    Required<CrawlOptions>,\n    \"proxy\" | \"timeoutMs\" | \"userAgent\" | \"includePatterns\" | \"excludePatterns\" | \"pool\" | \"removeAds\" | \"removeBase64Images\"\n  > & {\n    proxy?: CrawlOptions[\"proxy\"];\n    timeoutMs?: CrawlOptions[\"timeoutMs\"];\n    userAgent?: CrawlOptions[\"userAgent\"];\n    includePatterns?: string[];\n    excludePatterns?: string[];\n    removeAds?: boolean;\n    removeBase64Images?: boolean;\n  };\n  private visited: Set<string> = new Set();\n  private queue: Array<{ url: string; depth: number }> = [];\n  private urls: CrawlUrl[] = [];\n  private pool: IBrowserPool;\n  private logger = createLogger(\"crawler\");\n  private robotsRules: RobotsRules | null = null;\n\n  constructor(options: CrawlOptions) {\n    // Pool must be provided by client\n    if (!options.pool) {\n      throw new Error(\"Browser pool must be provided. Use ReaderClient for automatic pool management.\");\n    }\n    this.pool = options.pool;\n\n    this.options = {\n      url: options.url,\n      depth: options.depth || 1,\n      maxPages: options.maxPages || 20,\n      scrape: options.scrape || false,\n      delayMs: options.delayMs || 1000,\n      timeoutMs: options.timeoutMs,\n      includePatterns: options.includePatterns,\n      excludePatterns: options.excludePatterns,\n      formats: options.formats || [\"markdown\", \"html\"],\n      scrapeConcurrency: options.scrapeConcurrency || 2,\n      proxy: options.proxy,\n      userAgent: options.userAgent,\n      verbose: options.verbose || false,\n      showChrome: options.showChrome || false,\n      connectionToCore: options.connectionToCore,\n      // Content cleaning options\n      removeAds: options.removeAds,\n      removeBase64Images: options.removeBase64Images,\n    };\n  }\n\n  /**\n   * Start crawling\n   */\n  async crawl(): Promise<CrawlResult> {\n    const startTime = Date.now();\n\n    // Fetch robots.txt rules before crawling\n    this.robotsRules = await fetchRobotsTxt(this.options.url);\n    if (this.robotsRules) {\n      this.logger.info(\"Loaded robots.txt rules\");\n    }\n\n    // Pool is managed by ReaderClient - just use it\n    // Add seed URL to queue (if allowed by robots.txt)\n    if (isUrlAllowed(this.options.url, this.robotsRules)) {\n      this.queue.push({ url: this.options.url, depth: 0 });\n    } else {\n      this.logger.warn(`Seed URL blocked by robots.txt: ${this.options.url}`);\n    }\n\n    // Crawl URLs\n    while (this.queue.length > 0 && this.urls.length < this.options.maxPages) {\n      // Check timeout\n      if (this.options.timeoutMs && Date.now() - startTime > this.options.timeoutMs) {\n        this.logger.warn(`Crawl timed out after ${this.options.timeoutMs}ms`);\n        break;\n      }\n\n      const item = this.queue.shift()!;\n      const urlKey = getUrlKey(item.url);\n\n      if (this.visited.has(urlKey)) {\n        continue;\n      }\n\n      // Fetch page\n      const result = await this.fetchPage(item.url);\n\n      if (result) {\n        this.urls.push(result.crawlUrl);\n        this.visited.add(urlKey);\n\n        // Extract links from the fetched HTML if not at max depth\n        if (item.depth < this.options.depth) {\n          const links = this.extractLinks(result.html, item.url, item.depth + 1);\n          this.queue.push(...links);\n        }\n      }\n\n      // Rate limit (use robots.txt crawl-delay if specified, otherwise use configured delay)\n      const delay = this.robotsRules?.crawlDelay || this.options.delayMs;\n      await rateLimit(delay);\n    }\n\n    // Build metadata\n    const metadata: CrawlMetadata = {\n      totalUrls: this.urls.length,\n      maxDepth: this.options.depth,\n      totalDuration: Date.now() - startTime,\n      seedUrl: this.options.url,\n    };\n\n    // Optionally scrape all discovered URLs\n    let scraped: ScrapeResult | undefined;\n    if (this.options.scrape) {\n      scraped = await this.scrapeDiscoveredUrls();\n    }\n\n    return {\n      urls: this.urls,\n      scraped,\n      metadata,\n    };\n  }\n\n  /**\n   * Fetch a single page and extract basic info\n   */\n  private async fetchPage(url: string): Promise<{ crawlUrl: CrawlUrl; html: string } | null> {\n    try {\n      return await this.pool.withBrowser(async (hero: Hero) => {\n        // Navigate\n        await hero.goto(url, { timeoutMs: 30000 });\n        await hero.waitForPaintingStable();\n\n        // Handle Cloudflare challenge\n        const initialUrl = await hero.url;\n        const detection = await detectChallenge(hero);\n\n        if (detection.isChallenge) {\n          if (this.options.verbose) {\n            this.logger.info(`Challenge detected on ${url}`);\n          }\n\n          const result = await waitForChallengeResolution(hero, {\n            maxWaitMs: 45000,\n            pollIntervalMs: 500,\n            verbose: this.options.verbose,\n            initialUrl,\n          });\n\n          if (!result.resolved) {\n            throw new Error(`Challenge not resolved`);\n          }\n        }\n\n        // Extract basic info and HTML\n        const title = await hero.document.title;\n        const html = await hero.document.documentElement.outerHTML;\n\n        // Try to extract description from meta tags\n        let description: string | null = null;\n        try {\n          const metaDesc = await hero.document.querySelector('meta[name=\"description\"]');\n          if (metaDesc) {\n            description = await metaDesc.getAttribute(\"content\");\n          }\n        } catch {\n          // No description found\n        }\n\n        return {\n          crawlUrl: {\n            url,\n            title: title || \"Untitled\",\n            description,\n          },\n          html,\n        };\n      });\n    } catch (error: any) {\n      this.logger.error(`Failed to fetch ${url}: ${error.message}`);\n      return null;\n    }\n  }\n\n  /**\n   * Extract links from HTML content using DOM parsing\n   * Handles all href formats (single quotes, double quotes, unquoted)\n   */\n  private extractLinks(\n    html: string,\n    baseUrl: string,\n    depth: number\n  ): Array<{ url: string; depth: number }> {\n    const links: Array<{ url: string; depth: number }> = [];\n    const { document } = parseHTML(html);\n\n    // Use proper DOM API to find all anchor elements with href\n    document.querySelectorAll(\"a[href]\").forEach((anchor: Element) => {\n      const rawHref = anchor.getAttribute(\"href\");\n      if (!rawHref) return;\n\n      // Trim whitespace from href\n      const href = rawHref.trim();\n      if (!href) return;\n\n      // Skip fragment-only links (#, #section, etc.)\n      if (href.startsWith(\"#\")) return;\n\n      // Skip non-HTTP schemes (javascript:, mailto:, tel:, data:, blob:, ftp:)\n      const lowerHref = href.toLowerCase();\n      if (\n        lowerHref.startsWith(\"javascript:\") ||\n        lowerHref.startsWith(\"mailto:\") ||\n        lowerHref.startsWith(\"tel:\") ||\n        lowerHref.startsWith(\"data:\") ||\n        lowerHref.startsWith(\"blob:\") ||\n        lowerHref.startsWith(\"ftp:\")\n      ) {\n        return;\n      }\n\n      // Resolve relative URLs\n      let resolved = resolveUrl(href, baseUrl);\n      if (!resolved || !isValidUrl(resolved)) return;\n\n      // Strip hash fragments from URLs\n      try {\n        const parsed = new URL(resolved);\n        parsed.hash = \"\";\n        resolved = parsed.toString();\n      } catch {\n        return;\n      }\n\n      // Check if same domain\n      if (!isSameDomain(resolved, this.options.url)) return;\n\n      // Check if content page (skip legal, policy, utility pages)\n      if (!isContentUrl(resolved)) return;\n\n      // Check include/exclude patterns\n      if (!shouldIncludeUrl(resolved, this.options.includePatterns, this.options.excludePatterns)) return;\n\n      // Check if allowed by robots.txt\n      if (!isUrlAllowed(resolved, this.robotsRules)) return;\n\n      // Check if already visited or queued\n      const urlKey = getUrlKey(resolved);\n      if (this.visited.has(urlKey) || this.queue.some((q) => getUrlKey(q.url) === urlKey)) {\n        return;\n      }\n\n      links.push({ url: resolved, depth });\n    });\n\n    return links;\n  }\n\n  /**\n   * Scrape all discovered URLs\n   */\n  private async scrapeDiscoveredUrls(): Promise<ScrapeResult> {\n    const urls = this.urls.map((u) => u.url);\n\n    return scrape({\n      urls,\n      formats: this.options.formats,\n      batchConcurrency: this.options.scrapeConcurrency,\n      proxy: this.options.proxy,\n      userAgent: this.options.userAgent,\n      verbose: this.options.verbose,\n      showChrome: this.options.showChrome,\n      pool: this.pool,\n      // Content cleaning options\n      removeAds: this.options.removeAds,\n      removeBase64Images: this.options.removeBase64Images,\n    });\n  }\n}\n\n/**\n * Convenience function to crawl a website\n *\n * @param options - Crawl options\n * @returns Crawl result\n *\n * @example\n * const result = await crawl({\n *   url: 'https://example.com',\n *   depth: 2,\n *   maxPages: 20,\n *   scrape: true\n * });\n */\nexport async function crawl(options: CrawlOptions): Promise<CrawlResult> {\n  const crawler = new Crawler(options);\n  return crawler.crawl();\n}\n","import pLimit from \"p-limit\";\n\n/**\n * Simple rate limit function\n */\nexport async function rateLimit(ms: number): Promise<void> {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n\n/**\n * Rate limiter using p-limit to control concurrent requests\n */\nexport class RateLimiter {\n  private limit: ReturnType<typeof pLimit>;\n\n  constructor(requestsPerSecond: number) {\n    // Convert requests per second to concurrency limit\n    // For rate limiting, we use pLimit with a delay between requests\n    this.limit = pLimit(1);\n    this.requestsPerSecond = requestsPerSecond;\n  }\n\n  private requestsPerSecond: number;\n  private lastRequestTime = 0;\n\n  /**\n   * Execute a function with rate limiting\n   */\n  async execute<T>(fn: () => Promise<T>): Promise<T> {\n    return this.limit(async () => {\n      await this.waitForNextSlot();\n      return fn();\n    });\n  }\n\n  /**\n   * Wait for the next available time slot based on rate limit\n   */\n  private async waitForNextSlot(): Promise<void> {\n    const now = Date.now();\n    const timeSinceLastRequest = now - this.lastRequestTime;\n    const minInterval = 1000 / this.requestsPerSecond;\n\n    if (timeSinceLastRequest < minInterval) {\n      const delay = minInterval - timeSinceLastRequest;\n      await new Promise((resolve) => setTimeout(resolve, delay));\n    }\n\n    this.lastRequestTime = Date.now();\n  }\n\n  /**\n   * Execute multiple functions concurrently with rate limiting\n   */\n  async executeAll<T>(functions: Array<() => Promise<T>>): Promise<T[]> {\n    return Promise.all(functions.map((fn) => this.execute(fn)));\n  }\n}\n","import Hero from \"@ulixee/hero\";\nimport { createHeroConfig } from \"./hero-config\";\nimport type {\n  BrowserInstance,\n  QueueItem,\n  PoolConfig,\n  PoolStats,\n  HealthStatus,\n  IBrowserPool,\n} from \"./types\";\nimport type { ProxyConfig } from \"../types\";\nimport { createLogger } from \"../utils/logger\";\n\n/**\n * Default pool configuration\n */\nconst DEFAULT_POOL_CONFIG: PoolConfig = {\n  size: 2,\n  retireAfterPageCount: 100,\n  retireAfterAgeMs: 30 * 60 * 1000, // 30 minutes\n  recycleCheckInterval: 60 * 1000, // 1 minute\n  healthCheckInterval: 5 * 60 * 1000, // 5 minutes\n  maxConsecutiveFailures: 3,\n  maxQueueSize: 100,\n  queueTimeout: 60 * 1000, // 1 minute\n};\n\n/**\n * Generate unique ID\n */\nfunction generateId(): string {\n  return `browser_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;\n}\n\n/**\n * Browser Pool\n *\n * Manages a pool of Hero browser instances with:\n * - Auto-recycling based on age/request count\n * - Request queuing when pool is full\n * - Health monitoring\n *\n * @example\n * const pool = new BrowserPool({ size: 5 });\n * await pool.initialize();\n *\n * // Use withBrowser for automatic acquire/release\n * await pool.withBrowser(async (hero) => {\n *   await hero.goto('https://example.com');\n *   const title = await hero.document.title;\n *   return title;\n * });\n *\n * await pool.shutdown();\n */\nexport class BrowserPool implements IBrowserPool {\n  private instances: BrowserInstance[] = [];\n  private available: BrowserInstance[] = [];\n  private inUse: Set<BrowserInstance> = new Set();\n  private queue: QueueItem[] = [];\n  private config: PoolConfig;\n  private proxy?: ProxyConfig;\n  private recycleTimer?: NodeJS.Timeout;\n  private healthTimer?: NodeJS.Timeout;\n  private totalRequests = 0;\n  private totalRequestDuration = 0;\n  private showChrome: boolean;\n  private connectionToCore?: any;\n  private userAgent?: string;\n  private verbose: boolean;\n  private logger = createLogger(\"pool\");\n\n  constructor(\n    config: Partial<PoolConfig> = {},\n    proxy?: ProxyConfig,\n    showChrome: boolean = false,\n    connectionToCore?: any,\n    userAgent?: string,\n    verbose: boolean = false\n  ) {\n    this.config = { ...DEFAULT_POOL_CONFIG, ...config };\n    this.proxy = proxy;\n    this.showChrome = showChrome;\n    this.connectionToCore = connectionToCore;\n    this.userAgent = userAgent;\n    this.verbose = verbose;\n  }\n\n  /**\n   * Initialize the pool by pre-launching browsers\n   */\n  async initialize(): Promise<void> {\n    if (this.verbose) {\n      this.logger.info(`Initializing pool with ${this.config.size} browsers...`);\n    }\n\n    // Pre-launch browsers\n    const launchPromises: Promise<BrowserInstance>[] = [];\n    for (let i = 0; i < this.config.size; i++) {\n      launchPromises.push(this.createInstance());\n    }\n\n    this.instances = await Promise.all(launchPromises);\n    this.available = [...this.instances];\n\n    // Start background tasks\n    this.startRecycling();\n    this.startHealthChecks();\n\n    if (this.verbose) {\n      this.logger.info(`Pool ready: ${this.instances.length} browsers available`);\n    }\n  }\n\n  /**\n   * Shutdown the pool and close all browsers\n   */\n  async shutdown(): Promise<void> {\n    if (this.verbose) {\n      const stats = this.getStats();\n      this.logger.info(\n        `Shutting down pool: ${stats.totalRequests} total requests processed, ` +\n          `${Math.round(stats.avgRequestDuration)}ms avg duration`\n      );\n    }\n\n    // Stop background tasks\n    if (this.recycleTimer) clearInterval(this.recycleTimer);\n    if (this.healthTimer) clearInterval(this.healthTimer);\n\n    // Reject all queued requests\n    for (const item of this.queue) {\n      item.reject(new Error(\"Pool shutting down\"));\n    }\n    this.queue = [];\n\n    // Close all browsers\n    const closePromises = this.instances.map((instance) => instance.hero.close().catch(() => {}));\n    await Promise.all(closePromises);\n\n    // Disconnect the connection to core to release event listeners\n    if (this.connectionToCore) {\n      try {\n        await this.connectionToCore.disconnect();\n      } catch {\n        // Ignore disconnect errors\n      }\n      this.connectionToCore = undefined;\n    }\n\n    // Clear instances\n    this.instances = [];\n    this.available = [];\n    this.inUse.clear();\n  }\n\n  /**\n   * Acquire a browser from the pool\n   */\n  async acquire(): Promise<Hero> {\n    // Get available instance\n    const instance = this.available.shift();\n    if (!instance) {\n      // No available instances, queue the request\n      if (this.verbose) {\n        this.logger.info(`No browsers available, queuing request (queue: ${this.queue.length + 1})`);\n      }\n      return this.queueRequest();\n    }\n\n    // Mark as busy\n    instance.status = \"busy\";\n    instance.lastUsed = Date.now();\n    this.inUse.add(instance);\n\n    if (this.verbose) {\n      this.logger.info(\n        `Acquired browser ${instance.id} (available: ${this.available.length}, busy: ${this.inUse.size})`\n      );\n    }\n\n    return instance.hero;\n  }\n\n  /**\n   * Release a browser back to the pool\n   */\n  release(hero: Hero): void {\n    const instance = this.instances.find((i) => i.hero === hero);\n    if (!instance) return;\n\n    // Update stats\n    instance.status = \"idle\";\n    instance.requestCount++;\n    this.inUse.delete(instance);\n\n    if (this.verbose) {\n      this.logger.info(\n        `Released browser ${instance.id} (requests: ${instance.requestCount}, available: ${this.available.length + 1})`\n      );\n    }\n\n    // Check if needs recycling\n    if (this.shouldRecycle(instance)) {\n      if (this.verbose) {\n        this.logger.info(`Recycling browser ${instance.id} (age or request limit reached)`);\n      }\n      this.recycleInstance(instance).catch(() => {});\n    } else {\n      this.available.push(instance);\n      this.processQueue();\n    }\n  }\n\n  /**\n   * Execute callback with auto-managed browser\n   */\n  async withBrowser<T>(callback: (hero: Hero) => Promise<T>): Promise<T> {\n    const startTime = Date.now();\n    const hero = await this.acquire();\n\n    try {\n      const result = await callback(hero);\n\n      // Update request stats\n      this.totalRequests++;\n      this.totalRequestDuration += Date.now() - startTime;\n\n      return result;\n    } finally {\n      this.release(hero);\n    }\n  }\n\n  /**\n   * Get pool statistics\n   */\n  getStats(): PoolStats {\n    const recycling = this.instances.filter((i) => i.status === \"recycling\").length;\n    const unhealthy = this.instances.filter((i) => i.status === \"unhealthy\").length;\n\n    return {\n      total: this.instances.length,\n      available: this.available.length,\n      busy: this.inUse.size,\n      recycling,\n      unhealthy,\n      queueLength: this.queue.length,\n      totalRequests: this.totalRequests,\n      avgRequestDuration:\n        this.totalRequests > 0 ? this.totalRequestDuration / this.totalRequests : 0,\n    };\n  }\n\n  /**\n   * Run health check\n   */\n  async healthCheck(): Promise<HealthStatus> {\n    const issues: string[] = [];\n    const stats = this.getStats();\n\n    // Check for unhealthy instances\n    if (stats.unhealthy > 0) {\n      issues.push(`${stats.unhealthy} unhealthy instances`);\n    }\n\n    // Check queue size\n    if (stats.queueLength > this.config.maxQueueSize * 0.8) {\n      issues.push(`Queue near capacity: ${stats.queueLength}/${this.config.maxQueueSize}`);\n    }\n\n    // Check if pool is saturated\n    if (stats.available === 0 && stats.queueLength > 0) {\n      issues.push(\"Pool saturated - all browsers busy with pending requests\");\n    }\n\n    return {\n      healthy: issues.length === 0,\n      issues,\n      stats,\n    };\n  }\n\n  // =========================================================================\n  // Private methods\n  // =========================================================================\n\n  /**\n   * Create a new browser instance\n   */\n  private async createInstance(): Promise<BrowserInstance> {\n    const heroConfig = createHeroConfig({\n      proxy: this.proxy,\n      showChrome: this.showChrome,\n      connectionToCore: this.connectionToCore,\n      userAgent: this.userAgent,\n    });\n\n    const hero = new Hero(heroConfig);\n\n    return {\n      hero,\n      id: generateId(),\n      createdAt: Date.now(),\n      lastUsed: Date.now(),\n      requestCount: 0,\n      status: \"idle\",\n    };\n  }\n\n  /**\n   * Check if instance should be recycled\n   */\n  private shouldRecycle(instance: BrowserInstance): boolean {\n    const age = Date.now() - instance.createdAt;\n    return (\n      instance.requestCount >= this.config.retireAfterPageCount ||\n      age >= this.config.retireAfterAgeMs\n    );\n  }\n\n  /**\n   * Recycle an instance (close old, create new)\n   */\n  private async recycleInstance(instance: BrowserInstance): Promise<void> {\n    instance.status = \"recycling\";\n\n    try {\n      // Close old instance\n      await instance.hero.close().catch(() => {});\n\n      // Create new instance\n      const newInstance = await this.createInstance();\n\n      // Replace in instances array\n      const index = this.instances.indexOf(instance);\n      if (index !== -1) {\n        this.instances[index] = newInstance;\n      }\n\n      // Add to available pool\n      this.available.push(newInstance);\n\n      if (this.verbose) {\n        this.logger.info(`Recycled browser: ${instance.id} â†’ ${newInstance.id}`);\n      }\n\n      // Process queue\n      this.processQueue();\n    } catch (error) {\n      // Failed to recycle, mark as unhealthy\n      instance.status = \"unhealthy\";\n      if (this.verbose) {\n        this.logger.warn(`Failed to recycle browser ${instance.id}`);\n      }\n    }\n  }\n\n  /**\n   * Queue a request when no browsers available\n   */\n  private queueRequest(): Promise<Hero> {\n    return new Promise<Hero>((resolve, reject) => {\n      // Check queue size\n      if (this.queue.length >= this.config.maxQueueSize) {\n        reject(new Error(\"Queue full\"));\n        return;\n      }\n\n      // Add to queue\n      const item: QueueItem = {\n        resolve,\n        reject,\n        queuedAt: Date.now(),\n      };\n      this.queue.push(item);\n\n      // Set timeout\n      setTimeout(() => {\n        const index = this.queue.indexOf(item);\n        if (index !== -1) {\n          this.queue.splice(index, 1);\n          reject(new Error(\"Queue timeout\"));\n        }\n      }, this.config.queueTimeout);\n    });\n  }\n\n  /**\n   * Process queued requests\n   */\n  private processQueue(): void {\n    while (this.queue.length > 0 && this.available.length > 0) {\n      const item = this.queue.shift()!;\n\n      // Check if still valid (not timed out)\n      const age = Date.now() - item.queuedAt;\n      if (age > this.config.queueTimeout) {\n        item.reject(new Error(\"Queue timeout\"));\n        continue;\n      }\n\n      // Acquire and resolve\n      this.acquire().then(item.resolve).catch(item.reject);\n    }\n  }\n\n  /**\n   * Start background recycling task\n   */\n  private startRecycling(): void {\n    this.recycleTimer = setInterval(() => {\n      for (const instance of this.instances) {\n        if (instance.status === \"idle\" && this.shouldRecycle(instance)) {\n          this.recycleInstance(instance).catch(() => {});\n        }\n      }\n    }, this.config.recycleCheckInterval);\n    // Allow process to exit even if timer is still running\n    this.recycleTimer.unref();\n  }\n\n  /**\n   * Start background health checks\n   */\n  private startHealthChecks(): void {\n    this.healthTimer = setInterval(async () => {\n      const health = await this.healthCheck();\n      if (!health.healthy && health.issues.length > 0) {\n        console.warn(\"[BrowserPool] Health issues:\", health.issues);\n      }\n    }, this.config.healthCheckInterval);\n    // Allow process to exit even if timer is still running\n    this.healthTimer.unref();\n  }\n}\n\n// Backward compatibility alias\nexport { BrowserPool as HeroBrowserPool };\n","import type { ProxyConfig } from \"../types\";\n\n/**\n * Create proxy URL from configuration\n *\n * Supports both datacenter and residential proxies.\n * For residential proxies (e.g., IPRoyal), generates a sticky session ID.\n *\n * @param config - Proxy configuration\n * @returns Formatted proxy URL\n *\n * @example\n * // Datacenter proxy\n * createProxyUrl({\n *   type: 'datacenter',\n *   username: 'user',\n *   password: 'pass',\n *   host: 'proxy.example.com',\n *   port: 8080\n * })\n * // Returns: \"http://user:pass@proxy.example.com:8080\"\n *\n * @example\n * // Residential proxy with sticky session\n * createProxyUrl({\n *   type: 'residential',\n *   username: 'customer-abc',\n *   password: 'secret',\n *   host: 'geo.iproyal.com',\n *   port: 12321,\n *   country: 'us'\n * })\n * // Returns: \"http://customer-abc_session-hero_123_abc456_country-us:secret@geo.iproyal.com:12321\"\n */\nexport function createProxyUrl(config: ProxyConfig): string {\n  // If full URL provided, use it directly\n  if (config.url) {\n    return config.url;\n  }\n\n  // Residential proxy with sticky session\n  if (config.type === \"residential\") {\n    // Generate unique session ID for sticky sessions\n    const sessionId = `hero_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;\n\n    // Format: customer-{username}_session-{sessionId}_country-{country}:{password}@{host}:{port}\n    return `http://customer-${config.username}_session-${sessionId}_country-${\n      config.country || \"us\"\n    }:${config.password}@${config.host}:${config.port}`;\n  }\n\n  // Datacenter proxy (simple authentication)\n  return `http://${config.username}:${config.password}@${config.host}:${config.port}`;\n}\n\n/**\n * Parse proxy URL into ProxyConfig\n *\n * @param url - Proxy URL string\n * @returns Parsed proxy configuration\n *\n * @example\n * parseProxyUrl(\"http://user:pass@proxy.example.com:8080\")\n * // Returns: { username: 'user', password: 'pass', host: 'proxy.example.com', port: 8080 }\n */\nexport function parseProxyUrl(url: string): ProxyConfig {\n  try {\n    const parsed = new URL(url);\n\n    return {\n      url,\n      username: parsed.username,\n      password: parsed.password,\n      host: parsed.hostname,\n      port: parsed.port ? parseInt(parsed.port, 10) : undefined,\n    };\n  } catch (error) {\n    throw new Error(`Invalid proxy URL: ${url}`);\n  }\n}\n","import type { ProxyConfig } from \"../types\";\nimport { createProxyUrl } from \"../proxy/config\";\n\n/**\n * Hero configuration options\n */\nexport interface HeroConfigOptions {\n  /** Proxy configuration */\n  proxy?: ProxyConfig;\n  /** Show Chrome window (default: false) */\n  showChrome?: boolean;\n  /** Custom user agent */\n  userAgent?: string;\n  /** Connection to Core (for in-process Core) */\n  connectionToCore?: any;\n}\n\n/**\n * Create Hero configuration with optimal anti-bot bypass settings\n *\n * Extracted from proven hero-test implementation.\n * Includes:\n * - TLS fingerprint emulation (disableMitm: false)\n * - DNS over TLS (mimics Chrome)\n * - WebRTC IP masking\n * - Proper locale and timezone\n *\n * @param options - Configuration options\n * @returns Hero configuration object\n */\nexport function createHeroConfig(options: HeroConfigOptions = {}): any {\n  const config: any = {\n    // Show or hide Chrome window\n    showChrome: options.showChrome ?? false,\n\n    // ============================================================================\n    // CRITICAL: TLS fingerprint emulation\n    // ============================================================================\n    // Setting disableMitm to false enables TLS/TCP fingerprint emulation\n    // This is ESSENTIAL for bypassing Cloudflare and other anti-bot systems\n    disableMitm: false,\n\n    // ============================================================================\n    // Session management\n    // ============================================================================\n    // Use incognito for clean session state\n    disableIncognito: false,\n\n    // ============================================================================\n    // Docker compatibility\n    // ============================================================================\n    // Required when running in containerized environments\n    noChromeSandbox: true,\n\n    // ============================================================================\n    // DNS over TLS (mimics Chrome behavior)\n    // ============================================================================\n    // Using Cloudflare's DNS (1.1.1.1) over TLS makes the connection\n    // look more like a real Chrome browser\n    dnsOverTlsProvider: {\n      host: \"1.1.1.1\",\n      servername: \"cloudflare-dns.com\",\n    },\n\n    // ============================================================================\n    // WebRTC IP leak prevention\n    // ============================================================================\n    // Masks the real IP address in WebRTC connections\n    // Uses ipify.org to detect the public IP\n    upstreamProxyIpMask: {\n      ipLookupService: \"https://api.ipify.org?format=json\",\n    },\n\n    // ============================================================================\n    // Locale and timezone\n    // ============================================================================\n    locale: \"en-US\",\n    timezoneId: \"America/New_York\",\n\n    // ============================================================================\n    // Viewport (standard desktop size)\n    // ============================================================================\n    viewport: {\n      width: 1920,\n      height: 1080,\n    },\n\n    // ============================================================================\n    // User agent (if provided)\n    // ============================================================================\n    ...(options.userAgent && { userAgent: options.userAgent }),\n\n    // ============================================================================\n    // Connection to Core (if provided)\n    // ============================================================================\n    ...(options.connectionToCore && { connectionToCore: options.connectionToCore }),\n  };\n\n  // ============================================================================\n  // Proxy configuration\n  // ============================================================================\n  if (options.proxy) {\n    config.upstreamProxyUrl = createProxyUrl(options.proxy);\n    // Don't use system DNS when using proxy\n    config.upstreamProxyUseSystemDns = false;\n  }\n\n  return config;\n}\n\n/**\n * Default Hero configuration (no proxy)\n */\nexport function getDefaultHeroConfig(): any {\n  return createHeroConfig();\n}\n","/**\n * Daemon Server\n *\n * An HTTP server that wraps ReaderClient, allowing multiple CLI\n * commands to share a single browser pool for efficient scraping.\n *\n * @example\n * // Start daemon\n * const daemon = new DaemonServer({ port: 3847, poolSize: 5 });\n * await daemon.start();\n *\n * // Stop daemon\n * await daemon.stop();\n */\n\nimport http from \"http\";\nimport { ReaderClient, type ReaderClientOptions } from \"../client\";\nimport type { ScrapeOptions, ScrapeResult } from \"../types\";\nimport type { CrawlOptions, CrawlResult } from \"../crawl-types\";\nimport { createLogger } from \"../utils/logger\";\n\nconst logger = createLogger(\"daemon\");\n\nexport const DEFAULT_DAEMON_PORT = 3847;\nconst PID_FILE_NAME = \".reader-daemon.pid\";\n\n/**\n * Daemon server configuration\n */\nexport interface DaemonServerOptions {\n  /** Port to listen on (default: 3847) */\n  port?: number;\n  /** Browser pool size (default: 5) */\n  poolSize?: number;\n  /** Enable verbose logging (default: false) */\n  verbose?: boolean;\n  /** Show Chrome browser windows (default: false) */\n  showChrome?: boolean;\n}\n\n/**\n * Request body types\n */\ninterface ScrapeRequest {\n  action: \"scrape\";\n  options: Omit<ScrapeOptions, \"connectionToCore\">;\n}\n\ninterface CrawlRequest {\n  action: \"crawl\";\n  options: Omit<CrawlOptions, \"connectionToCore\">;\n}\n\ninterface StatusRequest {\n  action: \"status\";\n}\n\ninterface ShutdownRequest {\n  action: \"shutdown\";\n}\n\ntype DaemonRequest = ScrapeRequest | CrawlRequest | StatusRequest | ShutdownRequest;\n\n/**\n * Response types\n */\ninterface SuccessResponse<T> {\n  success: true;\n  data: T;\n}\n\ninterface ErrorResponse {\n  success: false;\n  error: string;\n}\n\ntype DaemonResponse<T> = SuccessResponse<T> | ErrorResponse;\n\n/**\n * Status response data\n */\nexport interface DaemonStatus {\n  running: true;\n  port: number;\n  poolSize: number;\n  uptime: number;\n  pid: number;\n}\n\n/**\n * Daemon Server\n */\nexport class DaemonServer {\n  private server: http.Server | null = null;\n  private client: ReaderClient | null = null;\n  private options: Required<DaemonServerOptions>;\n  private startTime: number = 0;\n\n  constructor(options: DaemonServerOptions = {}) {\n    this.options = {\n      port: options.port ?? DEFAULT_DAEMON_PORT,\n      poolSize: options.poolSize ?? 5,\n      verbose: options.verbose ?? false,\n      showChrome: options.showChrome ?? false,\n    };\n  }\n\n  /**\n   * Start the daemon server\n   */\n  async start(): Promise<void> {\n    if (this.server) {\n      throw new Error(\"Daemon is already running\");\n    }\n\n    // Initialize ReaderClient\n    const clientOptions: ReaderClientOptions = {\n      verbose: this.options.verbose,\n      showChrome: this.options.showChrome,\n      browserPool: {\n        size: this.options.poolSize,\n      },\n    };\n\n    this.client = new ReaderClient(clientOptions);\n    await this.client.start();\n\n    // Create HTTP server\n    this.server = http.createServer(this.handleRequest.bind(this));\n\n    // Start listening\n    await new Promise<void>((resolve, reject) => {\n      this.server!.listen(this.options.port, () => {\n        this.startTime = Date.now();\n        if (this.options.verbose) {\n          logger.info(`Daemon started on port ${this.options.port} with pool size ${this.options.poolSize}`);\n        }\n        resolve();\n      });\n\n      this.server!.on(\"error\", (error: NodeJS.ErrnoException) => {\n        if (error.code === \"EADDRINUSE\") {\n          reject(new Error(`Port ${this.options.port} is already in use. Is another daemon running?`));\n        } else {\n          reject(error);\n        }\n      });\n    });\n\n    // Write PID file\n    await this.writePidFile();\n  }\n\n  /**\n   * Stop the daemon server\n   */\n  async stop(): Promise<void> {\n    if (this.server) {\n      await new Promise<void>((resolve) => {\n        this.server!.close(() => resolve());\n      });\n      this.server = null;\n    }\n\n    if (this.client) {\n      await this.client.close();\n      this.client = null;\n    }\n\n    // Remove PID file\n    await this.removePidFile();\n\n    if (this.options.verbose) {\n      logger.info(\"Daemon stopped\");\n    }\n  }\n\n  /**\n   * Get the port the daemon is running on\n   */\n  getPort(): number {\n    return this.options.port;\n  }\n\n  /**\n   * Handle incoming HTTP requests\n   */\n  private async handleRequest(req: http.IncomingMessage, res: http.ServerResponse): Promise<void> {\n    // Only accept POST requests to /\n    if (req.method !== \"POST\" || req.url !== \"/\") {\n      res.writeHead(404, { \"Content-Type\": \"application/json\" });\n      res.end(JSON.stringify({ success: false, error: \"Not found\" }));\n      return;\n    }\n\n    // Parse request body\n    let body = \"\";\n    for await (const chunk of req) {\n      body += chunk;\n    }\n\n    let request: DaemonRequest;\n    try {\n      request = JSON.parse(body);\n    } catch {\n      this.sendResponse(res, 400, { success: false, error: \"Invalid JSON\" });\n      return;\n    }\n\n    // Handle request\n    try {\n      switch (request.action) {\n        case \"scrape\":\n          await this.handleScrape(res, request.options);\n          break;\n        case \"crawl\":\n          await this.handleCrawl(res, request.options);\n          break;\n        case \"status\":\n          this.handleStatus(res);\n          break;\n        case \"shutdown\":\n          await this.handleShutdown(res);\n          break;\n        default:\n          this.sendResponse(res, 400, { success: false, error: \"Unknown action\" });\n      }\n    } catch (error: any) {\n      this.sendResponse(res, 500, { success: false, error: error.message });\n    }\n  }\n\n  /**\n   * Handle scrape request\n   */\n  private async handleScrape(\n    res: http.ServerResponse,\n    options: Omit<ScrapeOptions, \"connectionToCore\">\n  ): Promise<void> {\n    if (!this.client) {\n      this.sendResponse(res, 500, { success: false, error: \"Client not initialized\" });\n      return;\n    }\n\n    const result = await this.client.scrape(options);\n    this.sendResponse<ScrapeResult>(res, 200, { success: true, data: result });\n  }\n\n  /**\n   * Handle crawl request\n   */\n  private async handleCrawl(\n    res: http.ServerResponse,\n    options: Omit<CrawlOptions, \"connectionToCore\">\n  ): Promise<void> {\n    if (!this.client) {\n      this.sendResponse(res, 500, { success: false, error: \"Client not initialized\" });\n      return;\n    }\n\n    const result = await this.client.crawl(options);\n    this.sendResponse<CrawlResult>(res, 200, { success: true, data: result });\n  }\n\n  /**\n   * Handle status request\n   */\n  private handleStatus(res: http.ServerResponse): void {\n    const status: DaemonStatus = {\n      running: true,\n      port: this.options.port,\n      poolSize: this.options.poolSize,\n      uptime: Date.now() - this.startTime,\n      pid: process.pid,\n    };\n    this.sendResponse<DaemonStatus>(res, 200, { success: true, data: status });\n  }\n\n  /**\n   * Handle shutdown request\n   */\n  private async handleShutdown(res: http.ServerResponse): Promise<void> {\n    this.sendResponse(res, 200, { success: true, data: { message: \"Shutting down\" } });\n\n    // Delay shutdown to allow response to be sent\n    setTimeout(() => {\n      this.stop().then(() => process.exit(0));\n    }, 100);\n  }\n\n  /**\n   * Send JSON response\n   */\n  private sendResponse<T>(res: http.ServerResponse, statusCode: number, data: DaemonResponse<T>): void {\n    res.writeHead(statusCode, { \"Content-Type\": \"application/json\" });\n    res.end(JSON.stringify(data));\n  }\n\n  /**\n   * Write PID file\n   */\n  private async writePidFile(): Promise<void> {\n    const fs = await import(\"fs/promises\");\n    const path = await import(\"path\");\n    const os = await import(\"os\");\n\n    const pidFile = path.join(os.tmpdir(), PID_FILE_NAME);\n    const data = JSON.stringify({\n      pid: process.pid,\n      port: this.options.port,\n      startedAt: new Date().toISOString(),\n    });\n\n    await fs.writeFile(pidFile, data);\n  }\n\n  /**\n   * Remove PID file\n   */\n  private async removePidFile(): Promise<void> {\n    const fs = await import(\"fs/promises\");\n    const path = await import(\"path\");\n    const os = await import(\"os\");\n\n    const pidFile = path.join(os.tmpdir(), PID_FILE_NAME);\n    try {\n      await fs.unlink(pidFile);\n    } catch {\n      // Ignore errors\n    }\n  }\n}\n\n/**\n * Get path to PID file\n */\nexport async function getPidFilePath(): Promise<string> {\n  const path = await import(\"path\");\n  const os = await import(\"os\");\n  return path.join(os.tmpdir(), PID_FILE_NAME);\n}\n\n/**\n * Check if daemon is running by reading PID file\n */\nexport async function getDaemonInfo(): Promise<{ pid: number; port: number; startedAt: string } | null> {\n  const fs = await import(\"fs/promises\");\n  const pidFile = await getPidFilePath();\n\n  try {\n    const data = await fs.readFile(pidFile, \"utf-8\");\n    const info = JSON.parse(data);\n\n    // Check if process is still running\n    try {\n      process.kill(info.pid, 0); // Signal 0 tests if process exists\n      return info;\n    } catch {\n      // Process not running, clean up stale PID file\n      await fs.unlink(pidFile).catch(() => {});\n      return null;\n    }\n  } catch {\n    return null;\n  }\n}\n","/**\n * Daemon Client\n *\n * A client that connects to the daemon server via HTTP.\n * Used by CLI commands when a daemon is running.\n *\n * @example\n * const client = new DaemonClient({ port: 3847 });\n *\n * const result = await client.scrape({\n *   urls: ['https://example.com'],\n *   formats: ['markdown'],\n * });\n */\n\nimport http from \"http\";\nimport type { ScrapeOptions, ScrapeResult } from \"../types\";\nimport type { CrawlOptions, CrawlResult } from \"../crawl-types\";\nimport type { DaemonStatus } from \"./server\";\nimport { DEFAULT_DAEMON_PORT } from \"./server\";\n\n/**\n * Daemon client configuration\n */\nexport interface DaemonClientOptions {\n  /** Port the daemon is running on (default: 3847) */\n  port?: number;\n  /** Request timeout in milliseconds (default: 600000 = 10 minutes) */\n  timeoutMs?: number;\n}\n\n/**\n * Daemon Client\n */\nexport class DaemonClient {\n  private options: Required<DaemonClientOptions>;\n\n  constructor(options: DaemonClientOptions = {}) {\n    this.options = {\n      port: options.port ?? DEFAULT_DAEMON_PORT,\n      timeoutMs: options.timeoutMs ?? 600000, // 10 minutes default\n    };\n  }\n\n  /**\n   * Scrape URLs via daemon\n   */\n  async scrape(options: Omit<ScrapeOptions, \"connectionToCore\">): Promise<ScrapeResult> {\n    return this.request<ScrapeResult>({\n      action: \"scrape\",\n      options,\n    });\n  }\n\n  /**\n   * Crawl URL via daemon\n   */\n  async crawl(options: Omit<CrawlOptions, \"connectionToCore\">): Promise<CrawlResult> {\n    return this.request<CrawlResult>({\n      action: \"crawl\",\n      options,\n    });\n  }\n\n  /**\n   * Get daemon status\n   */\n  async status(): Promise<DaemonStatus> {\n    return this.request<DaemonStatus>({\n      action: \"status\",\n    });\n  }\n\n  /**\n   * Request daemon shutdown\n   */\n  async shutdown(): Promise<void> {\n    await this.request<{ message: string }>({\n      action: \"shutdown\",\n    });\n  }\n\n  /**\n   * Check if daemon is reachable\n   */\n  async isRunning(): Promise<boolean> {\n    try {\n      await this.status();\n      return true;\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Make HTTP request to daemon\n   */\n  private request<T>(body: object): Promise<T> {\n    return new Promise((resolve, reject) => {\n      const data = JSON.stringify(body);\n\n      const req = http.request(\n        {\n          hostname: \"127.0.0.1\",\n          port: this.options.port,\n          path: \"/\",\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            \"Content-Length\": Buffer.byteLength(data),\n          },\n          timeout: this.options.timeoutMs,\n        },\n        (res) => {\n          let responseBody = \"\";\n\n          res.on(\"data\", (chunk) => {\n            responseBody += chunk;\n          });\n\n          res.on(\"end\", () => {\n            try {\n              const response = JSON.parse(responseBody);\n\n              if (response.success) {\n                resolve(response.data);\n              } else {\n                reject(new Error(response.error || \"Unknown daemon error\"));\n              }\n            } catch (error) {\n              reject(new Error(`Failed to parse daemon response: ${responseBody}`));\n            }\n          });\n        }\n      );\n\n      req.on(\"error\", (error: NodeJS.ErrnoException) => {\n        if (error.code === \"ECONNREFUSED\") {\n          reject(new Error(`Cannot connect to daemon on port ${this.options.port}. Is it running?`));\n        } else {\n          reject(error);\n        }\n      });\n\n      req.on(\"timeout\", () => {\n        req.destroy();\n        reject(new Error(`Request to daemon timed out after ${this.options.timeoutMs}ms`));\n      });\n\n      req.write(data);\n      req.end();\n    });\n  }\n}\n\n/**\n * Check if daemon is running on the specified port\n */\nexport async function isDaemonRunning(port: number = DEFAULT_DAEMON_PORT): Promise<boolean> {\n  const client = new DaemonClient({ port, timeoutMs: 5000 });\n  return client.isRunning();\n}\n"],"mappings":";;;;;;;;;AA6BA,SAAS,eAAe;;;ACTxB,OAAO,cAAc;AACrB,SAAS,uBAAuB;AAChC,SAAS,4BAA4B;;;ACtBrC,OAAO,YAAY;;;ACAnB,SAAS,eAAe;AAUjB,SAAS,eAAe,MAAsB;AACnD,MAAI;AACF,WAAO,QAAQ,MAAM;AAAA,MACnB,cAAc;AAAA,MACd,cAAc;AAAA,MACd,WAAW;AAAA,MACX,WAAW;AAAA,IACb,CAAC;AAAA,EACH,SAAS,OAAO;AACd,YAAQ,KAAK,sCAAsC,KAAK;AAExD,WAAO,KAAK,QAAQ,YAAY,EAAE,EAAE,KAAK;AAAA,EAC3C;AACF;;;ACvBA,SAAS,iBAAiB;AAgC1B,IAAM,0BAA0B;AAAA;AAAA,EAE9B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAM,oBAAoB;AAAA,EACxB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAMA,IAAM,uBAAuB;AAAA;AAAA,EAE3B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AACF;AAKA,IAAM,0BAA0B;AAAA;AAAA,EAE9B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAM,eAAe;AAAA;AAAA,EAEnB;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAUA,SAAS,eAAe,SAA0B;AAChD,QAAM,OAAO,QAAQ,eAAe;AACpC,QAAM,aAAa,KAAK,KAAK,EAAE;AAC/B,MAAI,eAAe,EAAG,QAAO;AAE7B,MAAI,aAAa;AACjB,UAAQ,iBAAiB,GAAG,EAAE,QAAQ,CAAC,SAAkB;AACvD,mBAAe,KAAK,eAAe,IAAI,KAAK,EAAE;AAAA,EAChD,CAAC;AAED,SAAO,aAAa;AACtB;AAMA,SAAS,gBAAgB,SAA0B;AACjD,MAAI,QAAQ;AACZ,QAAM,OAAO,QAAQ,eAAe;AACpC,QAAM,aAAa,KAAK,KAAK,EAAE;AAG/B,WAAS,KAAK,IAAI,aAAa,KAAK,EAAE;AACtC,WAAS,QAAQ,iBAAiB,GAAG,EAAE,SAAS;AAChD,WAAS,QAAQ,iBAAiB,wBAAwB,EAAE,SAAS;AACrE,WAAS,QAAQ,iBAAiB,KAAK,EAAE,SAAS;AAGlD,WAAS,QAAQ,iBAAiB,GAAG,EAAE,SAAS;AAChD,WAAS,QAAQ,iBAAiB,IAAI,EAAE,SAAS;AAGjD,QAAM,cAAc,eAAe,OAAO;AAC1C,MAAI,cAAc,IAAK,UAAS;AAAA,WACvB,cAAc,IAAK,UAAS;AAGrC,QAAM,cAAc,QAAQ,aAAa,MAAM,OAAO,QAAQ,MAAM;AACpE,MAAI,wCAAwC,KAAK,UAAU,EAAG,UAAS;AACvE,MAAI,oDAAoD,KAAK,UAAU,EAAG,UAAS;AAEnF,SAAO;AACT;AAKA,SAAS,oBAAoB,SAA2B;AACtD,QAAM,cAAc,eAAe,OAAO;AAC1C,MAAI,cAAc,IAAK,QAAO;AAG9B,QAAM,YAAY,QAAQ,iBAAiB,IAAI;AAC/C,QAAM,QAAQ,QAAQ,iBAAiB,GAAG;AAC1C,MAAI,UAAU,SAAS,KAAK,MAAM,SAAS,UAAU,SAAS,IAAK,QAAO;AAE1E,SAAO;AACT;AASA,SAAS,eAAe,UAAoB,WAA2B;AACrE,aAAW,YAAY,WAAW;AAChC,QAAI;AACF,eAAS,iBAAiB,QAAQ,EAAE,QAAQ,CAAC,OAAgB,GAAG,OAAO,CAAC;AAAA,IAC1E,QAAQ;AAAA,IAER;AAAA,EACF;AACF;AAMA,SAAS,qBACP,UACA,mBACA,oBACM;AACN,aAAW,YAAY,mBAAmB;AACxC,QAAI;AACF,eAAS,iBAAiB,QAAQ,EAAE,QAAQ,CAAC,YAAqB;AAEhE,cAAM,cAAc,mBAAmB,KAAK,CAAC,OAAO;AAClD,cAAI;AACF,mBAAO,QAAQ,QAAQ,EAAE;AAAA,UAC3B,QAAQ;AACN,mBAAO;AAAA,UACT;AAAA,QACF,CAAC;AACD,YAAI,YAAa;AAGjB,cAAM,oBAAoB,mBAAmB,KAAK,CAAC,OAAO;AACxD,cAAI;AACF,mBAAO,QAAQ,cAAc,EAAE,MAAM;AAAA,UACvC,QAAQ;AACN,mBAAO;AAAA,UACT;AAAA,QACF,CAAC;AACD,YAAI,kBAAmB;AAGvB,gBAAQ,OAAO;AAAA,MACjB,CAAC;AAAA,IACH,QAAQ;AAAA,IAER;AAAA,EACF;AACF;AASA,SAAS,gBAAgB,UAAoC;AAE3D,QAAM,iBAAiB,CAAC,OAAsC;AAC5D,QAAI,CAAC,GAAI,QAAO;AAChB,UAAM,OAAO,GAAG,eAAe;AAC/B,QAAI,KAAK,KAAK,EAAE,SAAS,IAAK,QAAO;AAErC,QAAI,oBAAoB,EAAE,EAAG,QAAO;AACpC,WAAO;AAAA,EACT;AAGA,QAAM,OAAO,SAAS,cAAc,MAAM;AAC1C,MAAI,eAAe,IAAI,KAAK,eAAe,IAAI,IAAI,KAAK;AACtD,WAAO;AAAA,EACT;AAGA,QAAM,WAAW,SAAS,cAAc,eAAe;AACvD,MAAI,eAAe,QAAQ,KAAK,eAAe,QAAQ,IAAI,KAAK;AAC9D,WAAO;AAAA,EACT;AAGA,QAAM,WAAW,SAAS,iBAAiB,SAAS;AACpD,MAAI,SAAS,WAAW,KAAK,eAAe,SAAS,CAAC,CAAC,GAAG;AACxD,WAAO,SAAS,CAAC;AAAA,EACnB;AAGA,QAAM,mBAAmB;AAAA,IACvB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,aAAW,YAAY,kBAAkB;AACvC,QAAI;AACF,YAAM,KAAK,SAAS,cAAc,QAAQ;AAC1C,UAAI,eAAe,EAAE,KAAK,eAAe,EAAE,IAAI,KAAK;AAClD,eAAO;AAAA,MACT;AAAA,IACF,QAAQ;AAAA,IAER;AAAA,EACF;AAGA,QAAM,aAAoD,CAAC;AAC3D,QAAM,aAAa,SAAS,iBAAiB,uBAAuB;AAEpE,aAAW,QAAQ,CAAC,OAAgB;AAClC,UAAM,OAAO,GAAG,eAAe;AAC/B,QAAI,KAAK,KAAK,EAAE,SAAS,IAAK;AAE9B,UAAM,QAAQ,gBAAgB,EAAE;AAChC,QAAI,QAAQ,GAAG;AACb,iBAAW,KAAK,EAAE,IAAI,MAAM,CAAC;AAAA,IAC/B;AAAA,EACF,CAAC;AAGD,aAAW,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAE3C,MAAI,WAAW,SAAS,KAAK,WAAW,CAAC,EAAE,QAAQ,IAAI;AACrD,WAAO,WAAW,CAAC,EAAE;AAAA,EACvB;AAGA,SAAO;AACT;AAKO,SAAS,UAAU,MAAc,SAAiB,UAA2B,CAAC,GAAW;AAC9F,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,qBAAqB;AAAA,IACrB,kBAAkB;AAAA,IAClB;AAAA,IACA;AAAA,EACF,IAAI;AAEJ,QAAM,EAAE,SAAS,IAAI,UAAU,IAAI;AAKnC,iBAAe,UAAU,uBAAuB;AAChD,iBAAe,UAAU,iBAAiB;AAK1C,MAAI,WAAW;AACb,mBAAe,UAAU,YAAY;AAAA,EACvC;AAKA,MAAI,eAAe,YAAY,SAAS,GAAG;AACzC,mBAAe,UAAU,WAAW;AAAA,EACtC;AAMA,MAAI,iBAAiB;AAGnB,yBAAqB,UAAU,sBAAsB,uBAAuB;AAG5E,UAAM,cAAc,gBAAgB,QAAQ;AAE5C,QAAI,aAAa;AAEf,YAAM,OAAO,SAAS;AACtB,UAAI,MAAM;AACR,cAAM,QAAQ,YAAY,UAAU,IAAI;AACxC,aAAK,YAAY;AACjB,aAAK,YAAY,KAAK;AAAA,MACxB;AAAA,IACF;AAAA,EAEF;AAKA,MAAI,eAAe,YAAY,SAAS,GAAG;AACzC,UAAM,kBAA6B,CAAC;AAEpC,eAAW,YAAY,aAAa;AAClC,UAAI;AACF,iBAAS,iBAAiB,QAAQ,EAAE,QAAQ,CAAC,OAAgB;AAC3D,0BAAgB,KAAK,GAAG,UAAU,IAAI,CAAY;AAAA,QACpD,CAAC;AAAA,MACH,QAAQ;AAAA,MAER;AAAA,IACF;AAEA,QAAI,gBAAgB,SAAS,GAAG;AAC9B,YAAM,OAAO,SAAS;AACtB,UAAI,MAAM;AACR,aAAK,YAAY;AACjB,wBAAgB,QAAQ,CAAC,OAAO,KAAK,YAAY,EAAE,CAAC;AAAA,MACtD;AAAA,IACF;AAAA,EACF;AAOA,MAAI,oBAAoB;AACtB,mCAA+B,QAAQ;AAAA,EACzC;AAGA,QAAM,SAAS,SAAS;AAAA,IAAiB;AAAA,IAAU;AAAA;AAAA,EAAiC;AACpF,QAAM,WAAmB,CAAC;AAC1B,SAAO,OAAO,SAAS,GAAG;AACxB,aAAS,KAAK,OAAO,WAAW;AAAA,EAClC;AACA,WAAS,QAAQ,CAAC,YAAY,QAAQ,YAAY,YAAY,OAAO,CAAC;AAGtE,sBAAoB,UAAU,OAAO;AAErC,SAAO,SAAS,iBAAiB,aAAa;AAChD;AAKA,SAAS,+BAA+B,UAA0B;AAEhE,WAAS,iBAAiB,mBAAmB,EAAE,QAAQ,CAAC,OAAgB;AACtE,OAAG,OAAO;AAAA,EACZ,CAAC;AAGD,WAAS,iBAAiB,uBAAuB,EAAE,QAAQ,CAAC,OAAgB;AAC1E,UAAM,QAAQ,GAAG,aAAa,OAAO;AACrC,QAAI,OAAO;AACT,YAAM,eAAe,MAAM;AAAA,QACzB;AAAA,QACA;AAAA,MACF;AACA,UAAI,aAAa,KAAK,GAAG;AACvB,WAAG,aAAa,SAAS,YAAY;AAAA,MACvC,OAAO;AACL,WAAG,gBAAgB,OAAO;AAAA,MAC5B;AAAA,IACF;AAAA,EACF,CAAC;AAGD,WAAS,iBAAiB,+CAA+C,EAAE,QAAQ,CAAC,OAAgB;AAClG,OAAG,OAAO;AAAA,EACZ,CAAC;AACH;AAKA,SAAS,oBAAoB,UAAoB,SAAuB;AAEtE,WAAS,iBAAiB,OAAO,EAAE,QAAQ,CAAC,OAAgB;AAC1D,UAAM,MAAM,GAAG,aAAa,KAAK;AACjC,QAAI,OAAO,CAAC,IAAI,WAAW,MAAM,KAAK,CAAC,IAAI,WAAW,IAAI,KAAK,CAAC,IAAI,WAAW,OAAO,GAAG;AACvF,UAAI;AACF,WAAG,aAAa,OAAO,IAAI,IAAI,KAAK,OAAO,EAAE,SAAS,CAAC;AAAA,MACzD,QAAQ;AAAA,MAER;AAAA,IACF;AAAA,EACF,CAAC;AAGD,WAAS,iBAAiB,QAAQ,EAAE,QAAQ,CAAC,OAAgB;AAC3D,UAAM,OAAO,GAAG,aAAa,MAAM;AACnC,QACE,QACA,CAAC,KAAK,WAAW,MAAM,KACvB,CAAC,KAAK,WAAW,IAAI,KACrB,CAAC,KAAK,WAAW,GAAG,KACpB,CAAC,KAAK,WAAW,SAAS,KAC1B,CAAC,KAAK,WAAW,MAAM,KACvB,CAAC,KAAK,WAAW,aAAa,GAC9B;AACA,UAAI;AACF,WAAG,aAAa,QAAQ,IAAI,IAAI,MAAM,OAAO,EAAE,SAAS,CAAC;AAAA,MAC3D,QAAQ;AAAA,MAER;AAAA,IACF;AAAA,EACF,CAAC;AACH;AAKO,SAAS,aAAa,MAAc,SAAiB,UAA2B,CAAC,GAAW;AACjG,SAAO,UAAU,MAAM,SAAS,OAAO;AACzC;;;AC5mBA,SAAS,aAAAA,kBAAiB;;;ACA1B,SAAS,OAAAC,YAAW;AACpB,OAAO,SAAS;AAST,SAAS,WAAW,UAAkB,MAAsB;AACjE,MAAI;AACF,WAAO,IAAIA,KAAI,UAAU,IAAI,EAAE,SAAS;AAAA,EAC1C,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAKO,SAAS,WAAW,QAAyB;AAClD,MAAI;AACF,QAAIA,KAAI,MAAM;AACd,WAAO;AAAA,EACT,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAKO,SAAS,aAAa,KAAa,SAA0B;AAClE,MAAI;AACF,QAAI;AAEJ,QAAI,IAAI,WAAW,SAAS,KAAK,IAAI,WAAW,UAAU,GAAG;AAC3D,kBAAY,IAAIA,KAAI,GAAG;AAAA,IACzB,WAAW,SAAS;AAClB,kBAAY,IAAIA,KAAI,KAAK,OAAO;AAAA,IAClC,OAAO;AACL,YAAM,IAAI,MAAM,gCAAgC;AAAA,IAClD;AAGA,cAAU,OAAO;AAEjB,WAAO,UAAU,SAAS;AAAA,EAC5B,QAAQ;AACN,UAAM,IAAI,MAAM,gBAAgB,GAAG,EAAE;AAAA,EACvC;AACF;AAKO,SAAS,kBAAkB,KAAqB;AACrD,MAAI;AACF,UAAM,YAAY,IAAIA,KAAI,GAAG;AAC7B,WAAO,UAAU;AAAA,EACnB,QAAQ;AACN,UAAM,IAAI,MAAM,sCAAsC,GAAG,EAAE;AAAA,EAC7D;AACF;AAKA,SAAS,cAAc,UAA0B;AAC/C,QAAM,QAAQ,SAAS,MAAM,GAAG;AAGhC,MAAI,MAAM,UAAU,GAAG;AACrB,WAAO;AAAA,EACT;AAGA,QAAM,cAAc,CAAC,SAAS,UAAU,SAAS,UAAU,SAAS,SAAS,UAAU,QAAQ;AAC/F,QAAM,UAAU,MAAM,MAAM,EAAE,EAAE,KAAK,GAAG;AAExC,MAAI,YAAY,SAAS,OAAO,GAAG;AAEjC,WAAO,MAAM,MAAM,EAAE,EAAE,KAAK,GAAG;AAAA,EACjC;AAGA,SAAO,MAAM,MAAM,EAAE,EAAE,KAAK,GAAG;AACjC;AAMO,SAAS,aAAa,KAAa,SAA0B;AAClE,MAAI;AACF,UAAM,YAAY,kBAAkB,GAAG;AACvC,UAAM,aAAa,kBAAkB,OAAO;AAG5C,QAAI,cAAc,YAAY;AAC5B,aAAO;AAAA,IACT;AAIA,UAAM,UAAU,cAAc,SAAS;AACvC,UAAM,WAAW,cAAc,UAAU;AAEzC,WAAO,YAAY;AAAA,EACrB,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAaO,SAAS,UAAU,KAAqB;AAC7C,MAAI;AACF,UAAM,YAAY,IAAIA,KAAI,GAAG;AAG7B,cAAU,OAAO;AAGjB,cAAU,SAAS;AAGnB,QAAI,UAAU,SAAS,WAAW,MAAM,GAAG;AACzC,gBAAU,WAAW,UAAU,SAAS,MAAM,CAAC;AAAA,IACjD;AAGA,QACG,UAAU,aAAa,WAAW,UAAU,SAAS,QACrD,UAAU,aAAa,YAAY,UAAU,SAAS,OACvD;AACA,gBAAU,OAAO;AAAA,IACnB;AAGA,UAAM,aAAa,CAAC,cAAc,aAAa,gBAAgB,eAAe,WAAW;AACzF,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,SAAS,SAAS,IAAI,SAAS,EAAE,GAAG;AAChD,kBAAU,WAAW,UAAU,SAAS,MAAM,GAAG,CAAC,UAAU,MAAM;AAClE;AAAA,MACF;AAAA,IACF;AAGA,QAAI,aAAa,UAAU,SAAS,EAAE,YAAY;AAClD,QAAI,WAAW,SAAS,GAAG,KAAK,UAAU,aAAa,KAAK;AAC1D,mBAAa,WAAW,MAAM,GAAG,EAAE;AAAA,IACrC;AAEA,WAAO;AAAA,EACT,QAAQ;AACN,WAAO,IAAI,YAAY;AAAA,EACzB;AACF;AAoEO,SAAS,gBAAgB,KAAa,UAA6B;AACxE,MAAI,CAAC,YAAY,SAAS,WAAW,GAAG;AACtC,WAAO;AAAA,EACT;AAEA,SAAO,SAAS,KAAK,CAAC,YAAY;AAChC,QAAI;AACF,YAAM,QAAQ,IAAI,IAAI,SAAS,GAAG;AAClC,aAAO,MAAM,KAAK,GAAG;AAAA,IACvB,QAAQ;AAEN,aAAO;AAAA,IACT;AAAA,EACF,CAAC;AACH;AAOO,SAAS,iBACd,KACA,iBACA,iBACS;AAET,MAAI,mBAAmB,gBAAgB,SAAS,GAAG;AACjD,QAAI,CAAC,gBAAgB,KAAK,eAAe,GAAG;AAC1C,aAAO;AAAA,IACT;AAAA,EACF;AAGA,MAAI,mBAAmB,gBAAgB,SAAS,GAAG;AACjD,QAAI,gBAAgB,KAAK,eAAe,GAAG;AACzC,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAMO,SAAS,aAAa,KAAsB;AACjD,QAAM,WAAW,IAAI,YAAY;AAGjC,QAAM,qBAAqB;AAAA;AAAA,IAEzB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA,EACF;AAEA,MAAI,mBAAmB,KAAK,CAAC,YAAY,QAAQ,KAAK,QAAQ,CAAC,GAAG;AAChE,WAAO;AAAA,EACT;AAGA,QAAM,iBAAiB,CAAC,QAAQ,QAAQ,SAAS,QAAQ,SAAS,QAAQ,MAAM;AAChF,MAAI,eAAe,KAAK,CAAC,QAAQ,SAAS,SAAS,GAAG,CAAC,GAAG;AACxD,WAAO;AAAA,EACT;AAEA,SAAO;AACT;;;ADtTO,SAAS,gBAAgB,MAAc,SAAkC;AAC9E,SAAO,uBAAuB,MAAM,OAAO;AAC7C;AAKO,SAAS,uBAAuB,MAAc,SAAkC;AACrF,QAAM,EAAE,SAAS,IAAIC,WAAU,IAAI;AAEnC,QAAM,WAA4B;AAAA,IAChC,OAAO;AAAA,IACP,aAAa;AAAA,IACb,QAAQ;AAAA,IACR,UAAU;AAAA,IACV,SAAS;AAAA,IACT,SAAS;AAAA,IACT,WAAW;AAAA,IACX,OAAO;AAAA,IACP,UAAU;AAAA,IACV,QAAQ;AAAA,IACR,YAAY;AAAA,IACZ,WAAW;AAAA,IACX,SAAS;AAAA,EACX;AAGA,WAAS,QAAQ,aAAa,QAAQ;AACtC,WAAS,cAAc,mBAAmB,UAAU,aAAa;AACjE,WAAS,SAAS,mBAAmB,UAAU,QAAQ;AACvD,WAAS,WAAW,gBAAgB,QAAQ;AAC5C,WAAS,UAAU,eAAe,QAAQ;AAG1C,WAAS,UAAU,eAAe,UAAU,OAAO;AACnD,WAAS,YAAY,iBAAiB,UAAU,OAAO;AACvD,WAAS,QACP,mBAAmB,UAAU,UAAU,KAAK,mBAAmB,UAAU,eAAe;AAG1F,WAAS,WAAW,gBAAgB,QAAQ;AAC5C,WAAS,SAAS,mBAAmB,UAAU,QAAQ;AACvD,WAAS,aAAa,mBAAmB,UAAU,aAAa;AAGhE,WAAS,YAAY,iBAAiB,QAAQ;AAG9C,WAAS,UAAU,mBAAmB,QAAQ;AAE9C,SAAO;AACT;AAKA,SAAS,aAAa,UAAmC;AAEvD,QAAM,eAAe,SAAS,cAAc,OAAO;AACnD,MAAI,cAAc,aAAa;AAC7B,WAAO,aAAa,YAAY,KAAK;AAAA,EACvC;AAGA,SAAO,mBAAmB,UAAU,UAAU;AAChD;AAMA,SAAS,mBAAmB,UAAoB,MAA6B;AAE3E,QAAM,SAAS,SAAS,cAAc,cAAc,IAAI,IAAI;AAC5D,MAAI,QAAQ;AACV,UAAM,UAAU,OAAO,aAAa,SAAS;AAC7C,QAAI,QAAS,QAAO,QAAQ,KAAK;AAAA,EACnC;AAGA,QAAM,aAAa,SAAS,cAAc,kBAAkB,IAAI,IAAI;AACpE,MAAI,YAAY;AACd,UAAM,UAAU,WAAW,aAAa,SAAS;AACjD,QAAI,QAAS,QAAO,QAAQ,KAAK;AAAA,EACnC;AAEA,SAAO;AACT;AAKA,SAAS,gBAAgB,UAAmC;AAC1D,QAAM,OAAO,SAAS,iBAAiB,aAAa,MAAM;AAC1D,SAAO,MAAM,KAAK,KAAK;AACzB;AAKA,SAAS,eAAe,UAAmC;AAEzD,QAAM,cAAc,SAAS,cAAc,eAAe;AAC1D,MAAI,aAAa;AACf,UAAM,UAAU,YAAY,aAAa,SAAS;AAClD,QAAI,QAAS,QAAO,QAAQ,KAAK;AAAA,EACnC;AAGA,QAAM,gBAAgB,SAAS,cAAc,iCAAiC;AAC9E,MAAI,eAAe;AACjB,UAAM,UAAU,cAAc,aAAa,SAAS;AACpD,QAAI,SAAS;AACX,YAAM,eAAe,QAAQ,MAAM,oBAAoB;AACvD,UAAI,aAAc,QAAO,aAAa,CAAC,EAAE,KAAK;AAAA,IAChD;AAAA,EACF;AAEA,SAAO;AACT;AAKA,SAAS,eAAe,UAAoB,SAAgC;AAE1E,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,aAAW,YAAY,eAAe;AACpC,UAAM,WAAW,SAAS,cAAc,QAAQ;AAChD,QAAI,UAAU;AACZ,YAAM,OAAO,SAAS,aAAa,MAAM;AACzC,UAAI,MAAM;AACR,eAAO,aAAa,MAAM,OAAO;AAAA,MACnC;AAAA,IACF;AAAA,EACF;AAGA,MAAI;AACF,WAAO,aAAa,gBAAgB,OAAO;AAAA,EAC7C,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAKA,SAAS,iBAAiB,UAAoB,SAAgC;AAC5E,QAAM,gBAAgB,SAAS,cAAc,uBAAuB;AACpE,MAAI,eAAe;AACjB,UAAM,OAAO,cAAc,aAAa,MAAM;AAC9C,QAAI,MAAM;AACR,aAAO,aAAa,MAAM,OAAO;AAAA,IACnC;AAAA,EACF;AAEA,SAAO;AACT;AAKA,SAAS,gBAAgB,UAAqC;AAC5D,QAAM,kBAAkB,mBAAmB,UAAU,UAAU;AAC/D,MAAI,CAAC,iBAAiB;AACpB,WAAO;AAAA,EACT;AAEA,SAAO,gBACJ,MAAM,GAAG,EACT,IAAI,CAAC,YAAY,QAAQ,KAAK,CAAC,EAC/B,OAAO,CAAC,YAAY,QAAQ,SAAS,CAAC;AAC3C;AAKA,SAAS,iBAAiB,UAAkD;AAC1E,QAAM,YAA0C;AAAA,IAC9C,OAAO;AAAA,IACP,aAAa;AAAA,IACb,MAAM;AAAA,IACN,KAAK;AAAA,IACL,OAAO;AAAA,IACP,UAAU;AAAA,IACV,QAAQ;AAAA,EACV;AAEA,YAAU,QAAQ,mBAAmB,UAAU,UAAU;AACzD,YAAU,cAAc,mBAAmB,UAAU,gBAAgB;AACrE,YAAU,OAAO,mBAAmB,UAAU,SAAS;AACvD,YAAU,MAAM,mBAAmB,UAAU,QAAQ;AACrD,YAAU,QAAQ,mBAAmB,UAAU,UAAU;AACzD,YAAU,WAAW,mBAAmB,UAAU,cAAc;AAChE,YAAU,SAAS,mBAAmB,UAAU,WAAW;AAG3D,MAAI,OAAO,OAAO,SAAS,EAAE,MAAM,CAAC,UAAU,CAAC,KAAK,GAAG;AACrD,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAKA,SAAS,mBAAmB,UAAgD;AAC1E,QAAM,UAAsC;AAAA,IAC1C,MAAM;AAAA,IACN,MAAM;AAAA,IACN,SAAS;AAAA,IACT,OAAO;AAAA,IACP,aAAa;AAAA,IACb,OAAO;AAAA,EACT;AAEA,UAAQ,OAAO,mBAAmB,UAAU,cAAc;AAC1D,UAAQ,OAAO,mBAAmB,UAAU,cAAc;AAC1D,UAAQ,UAAU,mBAAmB,UAAU,iBAAiB;AAChE,UAAQ,QAAQ,mBAAmB,UAAU,eAAe;AAC5D,UAAQ,cAAc,mBAAmB,UAAU,qBAAqB;AACxE,UAAQ,QAAQ,mBAAmB,UAAU,eAAe;AAG5D,MAAI,OAAO,OAAO,OAAO,EAAE,MAAM,CAAC,UAAU,CAAC,KAAK,GAAG;AACnD,WAAO;AAAA,EACT;AAEA,SAAO;AACT;;;AErPA,OAAO,UAAU;AAUjB,SAAS,gBAAyB;AAChC,MAAI;AACF,cAAQ,QAAQ,aAAa;AAC7B,WAAO;AAAA,EACT,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AASO,SAAS,aACd,OAAe,UACf,QAAgB,QAAQ,IAAI,aAAa,QACzC;AACA,QAAM,YACJ,QAAQ,IAAI,aAAa,gBAAgB,cAAc;AAEzD,SAAO,KAAK;AAAA,IACV;AAAA,IACA;AAAA,IACA,WAAW,YACP;AAAA,MACE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,UAAU;AAAA,QACV,eAAe;AAAA,QACf,QAAQ;AAAA,MACV;AAAA,IACF,IACA;AAAA,EACN,CAAC;AACH;AAKO,IAAM,SAAS,aAAa;;;ACvC5B,SAAS,eAAe,SAAiB,YAAoB,KAAkB;AACpF,QAAM,QAAqB;AAAA,IACzB,iBAAiB,CAAC;AAAA,IAClB,cAAc,CAAC;AAAA,IACf,YAAY;AAAA,EACd;AAEA,QAAM,QAAQ,QAAQ,MAAM,IAAI,EAAE,IAAI,CAAC,SAAS,KAAK,KAAK,CAAC;AAC3D,MAAI,mBAAmB;AACvB,MAAI,mBAAmB;AAEvB,aAAW,QAAQ,OAAO;AAExB,QAAI,CAAC,QAAQ,KAAK,WAAW,GAAG,GAAG;AACjC;AAAA,IACF;AAEA,UAAM,aAAa,KAAK,QAAQ,GAAG;AACnC,QAAI,eAAe,IAAI;AACrB;AAAA,IACF;AAEA,UAAM,YAAY,KAAK,UAAU,GAAG,UAAU,EAAE,KAAK,EAAE,YAAY;AACnE,UAAM,QAAQ,KAAK,UAAU,aAAa,CAAC,EAAE,KAAK;AAElD,QAAI,cAAc,cAAc;AAC9B,yBAAmB,MAAM,YAAY;AAErC,yBAAmB,qBAAqB,OAAO,qBAAqB,UAAU,YAAY;AAAA,IAC5F,WAAW,kBAAkB;AAC3B,UAAI,cAAc,cAAc,OAAO;AACrC,cAAM,gBAAgB,KAAK,KAAK;AAAA,MAClC,WAAW,cAAc,WAAW,OAAO;AACzC,cAAM,aAAa,KAAK,KAAK;AAAA,MAC/B,WAAW,cAAc,eAAe;AACtC,cAAM,QAAQ,WAAW,KAAK;AAC9B,YAAI,CAAC,MAAM,KAAK,GAAG;AACjB,gBAAM,aAAa,QAAQ;AAAA,QAC7B;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,cAAc,MAAc,OAA6B;AAEvE,QAAM,iBAAiB,KAAK,WAAW,GAAG,IAAI,OAAO,MAAM;AAG3D,aAAW,eAAe,MAAM,cAAc;AAC5C,QAAI,YAAY,gBAAgB,WAAW,GAAG;AAC5C,aAAO;AAAA,IACT;AAAA,EACF;AAGA,aAAW,kBAAkB,MAAM,iBAAiB;AAClD,QAAI,YAAY,gBAAgB,cAAc,GAAG;AAC/C,aAAO;AAAA,IACT;AAAA,EACF;AAGA,SAAO;AACT;AAMA,SAAS,YAAY,MAAc,SAA0B;AAE3D,MAAI,CAAC,SAAS;AACZ,WAAO;AAAA,EACT;AAGA,MAAI,eAAe,QAChB,QAAQ,sBAAsB,MAAM,EACpC,QAAQ,OAAO,IAAI;AAGtB,MAAI,aAAa,SAAS,KAAK,GAAG;AAChC,mBAAe,aAAa,MAAM,GAAG,EAAE,IAAI;AAAA,EAC7C,OAAO;AACL,mBAAe,MAAM;AAAA,EACvB;AAEA,MAAI;AACF,UAAM,QAAQ,IAAI,OAAO,YAAY;AACrC,WAAO,MAAM,KAAK,IAAI;AAAA,EACxB,QAAQ;AAEN,WAAO,KAAK,WAAW,OAAO;AAAA,EAChC;AACF;AAKA,eAAsB,eAAe,SAA8C;AACjF,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,eAAe,OAAO;AAC1C,UAAM,WAAW,MAAM,MAAM,IAAI,SAAS,GAAG;AAAA,MAC3C,SAAS;AAAA,QACP,cAAc;AAAA,MAChB;AAAA,IACF,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAEhB,aAAO;AAAA,IACT;AAEA,UAAM,UAAU,MAAM,SAAS,KAAK;AACpC,WAAO,eAAe,SAAS,cAAc;AAAA,EAC/C,QAAQ;AAEN,WAAO;AAAA,EACT;AACF;AAKO,SAAS,aAAa,KAAa,OAAoC;AAC5E,MAAI,CAAC,OAAO;AACV,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,YAAY,IAAI,IAAI,GAAG;AAC7B,WAAO,cAAc,UAAU,WAAW,UAAU,QAAQ,KAAK;AAAA,EACnE,QAAQ;AACN,WAAO;AAAA,EACT;AACF;;;AC+KO,IAAM,kBAcT;AAAA,EACF,MAAM,CAAC;AAAA,EACP,SAAS,CAAC,UAAU;AAAA,EACpB,WAAW;AAAA,EACX,iBAAiB,CAAC;AAAA,EAClB,iBAAiB,CAAC;AAAA;AAAA,EAElB,WAAW;AAAA,EACX,oBAAoB;AAAA,EACpB,iBAAiB;AAAA,EACjB,aAAa,CAAC;AAAA,EACd,aAAa,CAAC;AAAA,EACd,qBAAqB;AAAA;AAAA,EAErB,kBAAkB;AAAA,EAClB,gBAAgB;AAAA,EAChB,YAAY;AAAA,EACZ,YAAY,MAAM;AAAA,EAAC;AAAA;AAAA;AAAA,EAEnB,SAAS;AAAA,EACT,YAAY;AACd;;;AC/PO,IAAM,iBAAmD;AAAA,EAC9D,MAAM;AAAA,IACJ,MAAM;AAAA,IACN,SAAS;AAAA,IACT,YAAY;AAAA,IACZ,SAAS;AAAA,IACT,UAAU;AAAA,MACR,YAAY;AAAA,MACZ,YAAY;AAAA,MACZ,gBAAgB;AAAA,MAChB,SAAS;AAAA,MACT,aAAa;AAAA,IACf;AAAA,EACF;AAAA,EACA,WAAW;AAAA,IACT,MAAM;AAAA,IACN,SAAS;AAAA,IACT,YAAY;AAAA,IACZ,SAAS;AAAA,IACT,UAAU;AAAA,MACR,YAAY;AAAA,MACZ,YAAY;AAAA,MACZ,gBAAgB;AAAA,MAChB,SAAS;AAAA,MACT,aAAa;AAAA,IACf;AAAA,EACF;AAAA,EACA,MAAM;AAAA,IACJ,MAAM;AAAA,IACN,SAAS;AAAA,IACT,YAAY;AAAA,IACZ,SAAS;AAAA,IACT,UAAU;AAAA,MACR,YAAY;AAAA,MACZ,YAAY;AAAA,MACZ,gBAAgB;AAAA,MAChB,SAAS;AAAA,MACT,aAAa;AAAA,IACf;AAAA,EACF;AACF;AAKO,IAAM,uBAAqC,CAAC,QAAQ,aAAa,MAAM;;;AC9IvE,IAAM,cAAN,cAA0B,MAAM;AAAA,EAC5B;AAAA,EACA;AAAA,EAET,YAAY,QAAoB,SAAiB,SAAkD;AACjG,UAAM,IAAI,MAAM,KAAK,OAAO,EAAE;AAC9B,SAAK,OAAO;AACZ,SAAK,SAAS;AACd,SAAK,YAAY,SAAS,aAAa;AACvC,SAAK,QAAQ,SAAS;AAEtB,QAAI,MAAM,mBAAmB;AAC3B,YAAM,kBAAkB,MAAM,KAAK,WAAW;AAAA,IAChD;AAAA,EACF;AACF;AAMO,IAAM,yBAAN,cAAqC,YAAY;AAAA,EAC7C;AAAA,EAET,YAAY,QAAoB,eAAwB;AACtD,UAAM,QAAQ,uBAAuB,iBAAiB,SAAS,IAAI,EAAE,WAAW,KAAK,CAAC;AACtF,SAAK,OAAO;AACZ,SAAK,gBAAgB,iBAAiB;AAAA,EACxC;AACF;AAMO,IAAM,2BAAN,cAAuC,YAAY;AAAA,EAC/C;AAAA,EACA;AAAA,EAET,YAAY,QAAoB,eAAuB,YAAoB,KAAK;AAC9E,UAAM,QAAQ,yBAAyB,aAAa,sBAAsB,SAAS,KAAK,EAAE,WAAW,KAAK,CAAC;AAC3G,SAAK,OAAO;AACZ,SAAK,gBAAgB;AACrB,SAAK,YAAY;AAAA,EACnB;AACF;AAKO,IAAM,YAAN,cAAwB,YAAY;AAAA,EAChC;AAAA,EAET,YAAY,QAAoB,YAAoB,YAAqB;AACvE,UAAM,YAAY,cAAc,OAAO,eAAe;AACtD,UAAM,QAAQ,QAAQ,UAAU,GAAG,aAAa,KAAK,UAAU,KAAK,EAAE,IAAI,EAAE,UAAU,CAAC;AACvF,SAAK,OAAO;AACZ,SAAK,aAAa;AAAA,EACpB;AACF;AAKO,IAAM,qBAAN,cAAiC,YAAY;AAAA,EACzC;AAAA,EAET,YAAY,QAAoB,WAAmB;AACjD,UAAM,QAAQ,iBAAiB,SAAS,MAAM,EAAE,WAAW,KAAK,CAAC;AACjE,SAAK,OAAO;AACZ,SAAK,YAAY;AAAA,EACnB;AACF;AAKO,IAAM,yBAAN,cAAqC,YAAY;AAAA,EACtD,YAAY,QAAoB,QAAiB;AAC/C,UAAM,QAAQ,UAAU,wBAAwB,EAAE,WAAW,MAAM,CAAC;AACpE,SAAK,OAAO;AAAA,EACd;AACF;AAqBO,IAAM,wBAAN,cAAoC,MAAM;AAAA,EACtC;AAAA,EACA;AAAA,EAET,YAAY,kBAAgC,QAAgC;AAC1E,UAAM,UAAU,iBACb,IAAI,CAAC,MAAM,GAAG,CAAC,KAAK,OAAO,IAAI,CAAC,GAAG,WAAW,SAAS,EAAE,EACzD,KAAK,IAAI;AACZ,UAAM,uBAAuB,OAAO,EAAE;AACtC,SAAK,OAAO;AACZ,SAAK,mBAAmB;AACxB,SAAK,SAAS;AAAA,EAChB;AACF;;;AC3GA,IAAM,kBAA0C;AAAA,EAC9C,cACE;AAAA,EACF,QAAQ;AAAA,EACR,mBAAmB;AAAA,EACnB,mBAAmB;AAAA,EACnB,iBAAiB;AAAA,EACjB,QAAQ;AAAA,EACR,kBAAkB;AAAA,EAClB,kBAAkB;AAAA,EAClB,kBAAkB;AAAA,EAClB,kBAAkB;AAAA,EAClB,6BAA6B;AAC/B;AAMA,IAAM,qBAAqB;AAAA;AAAA,EAEzB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAM,4BAA4B,CAAC,aAAa,cAAc,WAAW,QAAQ;AAKjF,IAAM,qBAAqB;AAKpB,IAAM,aAAN,MAAmC;AAAA,EAC/B,SAAuB,eAAe;AAAA,EAE/C,MAAM,OAAO,MAAyC;AACpD,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,EAAE,KAAK,SAAS,QAAAC,SAAQ,YAAY,IAAI;AAE9C,QAAI;AAEF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,KAAK,OAAO,UAAU;AAG7E,UAAI,aAAa;AACf,oBAAY,iBAAiB,SAAS,MAAM,WAAW,MAAM,GAAG,EAAE,MAAM,KAAK,CAAC;AAAA,MAChF;AAEA,MAAAA,SAAQ,MAAM,mBAAmB,GAAG,EAAE;AAEtC,YAAM,WAAW,MAAM,MAAM,KAAK;AAAA,QAChC,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,GAAG;AAAA,UACH,GAAI,QAAQ,WAAW,CAAC;AAAA,QAC1B;AAAA,QACA,UAAU;AAAA,QACV,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,mBAAa,SAAS;AAEtB,YAAM,WAAW,KAAK,IAAI,IAAI;AAC9B,YAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,MAAAA,SAAQ,MAAM,wBAAwB,SAAS,MAAM,KAAK,KAAK,MAAM,cAAc,QAAQ,IAAI;AAG/F,UAAI,SAAS,UAAU,KAAK;AAC1B,cAAM,IAAI,UAAU,QAAQ,SAAS,QAAQ,SAAS,UAAU;AAAA,MAClE;AAGA,YAAM,gBAAgB,KAAK,gBAAgB,IAAI;AAC/C,UAAI,eAAe;AACjB,QAAAA,SAAQ,MAAM,8BAA8B,aAAa,EAAE;AAC3D,cAAM,IAAI,uBAAuB,QAAQ,aAAa;AAAA,MACxD;AAGA,YAAM,cAAc,KAAK,YAAY,IAAI;AACzC,UAAI,YAAY,SAAS,oBAAoB;AAC3C,QAAAA,SAAQ,MAAM,gCAAgC,YAAY,MAAM,QAAQ;AACxE,cAAM,IAAI,yBAAyB,QAAQ,YAAY,QAAQ,kBAAkB;AAAA,MACnF;AAEA,aAAO;AAAA,QACL;AAAA,QACA,KAAK,SAAS;AAAA,QACd,YAAY,SAAS;AAAA,QACrB,aAAa,SAAS,QAAQ,IAAI,cAAc,KAAK;AAAA,QACrD,SAAS,KAAK,gBAAgB,SAAS,OAAO;AAAA,QAC9C,QAAQ;AAAA,QACR;AAAA,MACF;AAAA,IACF,SAAS,OAAgB;AAEvB,UACE,iBAAiB,0BACjB,iBAAiB,4BACjB,iBAAiB,WACjB;AACA,cAAM;AAAA,MACR;AAGA,UAAI,iBAAiB,OAAO;AAC1B,YAAI,MAAM,SAAS,cAAc;AAC/B,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,OAAO,UAAU;AAAA,QAC7D;AAGA,cAAM,IAAI,YAAY,QAAQ,MAAM,SAAS,EAAE,OAAO,MAAM,CAAC;AAAA,MAC/D;AAEA,YAAM,IAAI,YAAY,QAAQ,OAAO,KAAK,CAAC;AAAA,IAC7C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,gBAAgB,MAA6B;AACnD,UAAM,YAAY,KAAK,YAAY;AAGnC,UAAM,gBAAgB,0BAA0B,KAAK,CAAC,MAAM,UAAU,SAAS,EAAE,YAAY,CAAC,CAAC;AAE/F,eAAW,WAAW,oBAAoB;AACxC,UAAI,UAAU,SAAS,QAAQ,YAAY,CAAC,GAAG;AAC7C,YAAI,iBAAiB,QAAQ,SAAS,IAAI,GAAG;AAC3C,iBAAO;AAAA,QACT;AACA,eAAO;AAAA,MACT;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,gBAAgB,SAA0C;AAChE,UAAM,SAAiC,CAAC;AACxC,YAAQ,QAAQ,CAAC,OAAO,QAAQ;AAC9B,aAAO,GAAG,IAAI;AAAA,IAChB,CAAC;AACD,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,YAAY,MAAsB;AACxC,WAAO,KACJ,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,mCAAmC,EAAE,EAC7C,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;AAAA,EACV;AAAA,EAEA,cAAuB;AACrB,WAAO;AAAA,EACT;AACF;AAKO,IAAM,aAAa,IAAI,WAAW;;;ACnNzC,SAAS,mBAAmB;AAe5B,IAAM,uBAAuB;AAAA;AAAA,EAE3B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAM,mBAAmB;AAAA,EACvB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAMC,sBAAqB;AAKpB,IAAM,kBAAN,MAAwC;AAAA,EACpC,SAAuB,eAAe;AAAA,EACvC,YAAqB;AAAA,EAE7B,cAAc;AAEZ,QAAI;AACF,UAAI,CAAC,aAAa;AAChB,aAAK,YAAY;AAAA,MACnB;AAAA,IACF,QAAQ;AACN,WAAK,YAAY;AAAA,IACnB;AAAA,EACF;AAAA,EAEA,MAAM,OAAO,MAAyC;AACpD,QAAI,CAAC,KAAK,WAAW;AACnB,YAAM,IAAI,uBAAuB,aAAa,4BAA4B;AAAA,IAC5E;AAEA,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,EAAE,KAAK,SAAS,QAAAC,SAAQ,YAAY,IAAI;AAE9C,QAAI;AAEF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,KAAK,OAAO,UAAU;AAG7E,UAAI,aAAa;AACf,oBAAY,iBAAiB,SAAS,MAAM,WAAW,MAAM,GAAG,EAAE,MAAM,KAAK,CAAC;AAAA,MAChF;AAEA,MAAAA,SAAQ,MAAM,wBAAwB,GAAG,EAAE;AAE3C,YAAM,WAAW,MAAM,YAAY;AAAA,QACjC;AAAA,QACA,SAAS;AAAA,UACP,SAAS,KAAK,OAAO;AAAA,QACvB;AAAA,QACA,SAAS,QAAQ;AAAA,QACjB,gBAAgB;AAAA;AAAA;AAAA,MAGlB,CAAC;AAED,mBAAa,SAAS;AAEtB,YAAM,WAAW,KAAK,IAAI,IAAI;AAC9B,YAAM,OAAO,SAAS;AAEtB,MAAAA,SAAQ,MAAM,6BAA6B,SAAS,UAAU,KAAK,KAAK,MAAM,cAAc,QAAQ,IAAI;AAGxG,UAAI,SAAS,cAAc,KAAK;AAC9B,cAAM,IAAI,UAAU,aAAa,SAAS,YAAY,SAAS,aAAa;AAAA,MAC9E;AAGA,YAAM,gBAAgB,KAAK,iBAAiB,IAAI;AAChD,UAAI,eAAe;AACjB,QAAAA,SAAQ,MAAM,4BAA4B,aAAa,EAAE;AACzD,cAAM,IAAI,uBAAuB,aAAa,aAAa;AAAA,MAC7D;AAGA,YAAM,gBAAgB,KAAK,cAAc,IAAI;AAC7C,UAAI,eAAe;AACjB,QAAAA,SAAQ,MAAM,wBAAwB,aAAa,EAAE;AACrD,cAAM,IAAI,uBAAuB,aAAa,YAAY,aAAa,EAAE;AAAA,MAC3E;AAGA,YAAM,cAAc,KAAK,YAAY,IAAI;AACzC,UAAI,YAAY,SAASD,qBAAoB;AAC3C,QAAAC,SAAQ,MAAM,qCAAqC,YAAY,MAAM,QAAQ;AAC7E,cAAM,IAAI,yBAAyB,aAAa,YAAY,QAAQD,mBAAkB;AAAA,MACxF;AAEA,aAAO;AAAA,QACL;AAAA,QACA,KAAK,SAAS;AAAA,QACd,YAAY,SAAS;AAAA,QACrB,aAAa,SAAS,QAAQ,cAAc;AAAA,QAC5C,SAAS,SAAS;AAAA,QAClB,QAAQ;AAAA,QACR;AAAA,MACF;AAAA,IACF,SAAS,OAAgB;AAEvB,UACE,iBAAiB,0BACjB,iBAAiB,4BACjB,iBAAiB,aACjB,iBAAiB,wBACjB;AACA,cAAM;AAAA,MACR;AAGA,UAAI,iBAAiB,OAAO;AAC1B,YAAI,MAAM,SAAS,kBAAkB,MAAM,QAAQ,SAAS,SAAS,GAAG;AACtE,gBAAM,IAAI,mBAAmB,aAAa,KAAK,OAAO,UAAU;AAAA,QAClE;AAEA,YAAI,MAAM,SAAS,cAAc;AAC/B,gBAAM,IAAI,mBAAmB,aAAa,KAAK,OAAO,UAAU;AAAA,QAClE;AAGA,cAAM,IAAI,YAAY,aAAa,MAAM,SAAS,EAAE,OAAO,MAAM,CAAC;AAAA,MACpE;AAEA,YAAM,IAAI,YAAY,aAAa,OAAO,KAAK,CAAC;AAAA,IAClD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,iBAAiB,MAA6B;AACpD,UAAM,YAAY,KAAK,YAAY;AAEnC,eAAW,WAAW,sBAAsB;AAC1C,UAAI,UAAU,SAAS,QAAQ,YAAY,CAAC,GAAG;AAC7C,YAAI,QAAQ,SAAS,IAAI,KAAK,QAAQ,SAAS,YAAY,GAAG;AAC5D,iBAAO;AAAA,QACT;AACA,eAAO;AAAA,MACT;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,cAAc,MAA6B;AACjD,UAAM,YAAY,KAAK,YAAY;AAEnC,eAAW,WAAW,kBAAkB;AACtC,UAAI,UAAU,SAAS,QAAQ,YAAY,CAAC,GAAG;AAC7C,eAAO;AAAA,MACT;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,YAAY,MAAsB;AACxC,WAAO,KACJ,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,mCAAmC,EAAE,EAC7C,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;AAAA,EACV;AAAA,EAEA,cAAuB;AACrB,WAAO,KAAK;AAAA,EACd;AACF;AAKO,IAAM,kBAAkB,IAAI,gBAAgB;;;AC1NnD,IAAM,iCAAiC;AAAA,EACrC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAQA,IAAM,2BAA2B;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAOA,IAAME,6BAA4B;AAAA,EAChC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAOA,IAAM,8BAA8B;AAAA,EAClC;AAAA,EACA;AACF;AAeA,eAAsB,gBAAgB,MAAyC;AAC7E,QAAM,UAAoB,CAAC;AAC3B,MAAI,OAAmC;AACvC,MAAI,qBAAqB;AACzB,MAAI,wBAAwB;AAE5B,MAAI;AAEF,QAAI,CAAC,KAAK,UAAU;AAClB,aAAO;AAAA,QACL,aAAa;AAAA,QACb,MAAM;AAAA,QACN,YAAY;AAAA,QACZ,SAAS,CAAC,uBAAuB;AAAA,MACnC;AAAA,IACF;AAKA,UAAM,OAAO,MAAM,KAAK,SAAS,gBAAgB;AACjD,UAAM,YAAY,KAAK,YAAY;AAEnC,eAAW,WAAWA,4BAA2B;AAC/C,UAAI,UAAU,SAAS,OAAO,GAAG;AAC/B,6BAAqB;AACrB,gBAAQ,KAAK,sBAAsB,OAAO,GAAG;AAC7C;AAAA,MACF;AAAA,IACF;AAGA,QAAI,CAAC,oBAAoB;AACvB,aAAO;AAAA,QACL,aAAa;AAAA,QACb,MAAM;AAAA,QACN,YAAY;AAAA,QACZ,SAAS,CAAC,uCAAuC;AAAA,MACnD;AAAA,IACF;AAKA,eAAW,YAAY,gCAAgC;AACrD,UAAI;AACF,cAAM,UAAU,MAAM,KAAK,SAAS,cAAc,QAAQ;AAC1D,YAAI,SAAS;AACX,kCAAwB;AACxB,kBAAQ,KAAK,sBAAsB,QAAQ,EAAE;AAC7C,iBAAO;AAAA,QACT;AAAA,MACF,QAAQ;AAAA,MAER;AAAA,IACF;AAKA,eAAW,WAAW,0BAA0B;AAC9C,UAAI,UAAU,SAAS,OAAO,GAAG;AAC/B,gCAAwB;AACxB,gBAAQ,KAAK,oBAAoB,OAAO,GAAG;AAC3C,eAAO,SAAS,SAAS,iBAAiB;AAAA,MAC5C;AAAA,IACF;AAKA,QAAI,UAAU,SAAS,aAAa,KAAK,UAAU,SAAS,YAAY,GAAG;AACzE,8BAAwB;AACxB,cAAQ,KAAK,4CAA4C;AACzD,aAAO,SAAS,SAAS,iBAAiB;AAAA,IAC5C;AAMA,UAAM,aAAa,4BAA4B,MAAM,CAAC,MAAM,UAAU,SAAS,CAAC,CAAC;AACjF,QAAI,YAAY;AACd,8BAAwB;AACxB,cAAQ,KAAK,gCAAgC;AAC7C,aAAO;AAAA,IACT;AAGA,UAAM,cAAc,sBAAsB;AAC1C,UAAM,aAAa,cAAc,MAAM;AAEvC,WAAO;AAAA,MACL;AAAA,MACA,MAAM,cAAc,OAAO;AAAA,MAC3B;AAAA,MACA;AAAA,IACF;AAAA,EACF,SAAS,OAAY;AACnB,WAAO;AAAA,MACL,aAAa;AAAA,MACb,MAAM;AAAA,MACN,YAAY;AAAA,MACZ,SAAS,CAAC,2BAA2B,MAAM,OAAO,EAAE;AAAA,IACtD;AAAA,EACF;AACF;;;AClJA,eAAsB,2BACpB,MACA,SACoC;AACpC,QAAM,EAAE,YAAY,MAAO,iBAAiB,KAAK,UAAU,OAAO,WAAW,IAAI;AAEjF,QAAM,YAAY,KAAK,IAAI;AAC3B,QAAM,MAAM,CAAC,QAAgB,WAAW,QAAQ,IAAI,MAAM,GAAG,EAAE;AAE/D,SAAO,KAAK,IAAI,IAAI,YAAY,WAAW;AACzC,UAAM,UAAU,KAAK,IAAI,IAAI;AAK7B,QAAI;AACF,YAAM,aAAa,MAAM,KAAK;AAC9B,UAAI,eAAe,YAAY;AAC7B,YAAI,uBAAkB,UAAU,WAAM,UAAU,EAAE;AAElD,YAAI,mCAAmC;AACvC,YAAI;AACF,gBAAM,KAAK,YAAY,oBAAoB,EAAE,WAAW,IAAM,CAAC;AAC/D,cAAI,oBAAoB;AAAA,QAC1B,QAAQ;AACN,cAAI,2CAA2C;AAAA,QACjD;AAEA,cAAM,KAAK,sBAAsB,EAAE,MAAM,MAAM;AAAA,QAAC,CAAC;AACjD,YAAI,mBAAmB;AACvB,eAAO,EAAE,UAAU,MAAM,QAAQ,gBAAgB,UAAU,QAAQ;AAAA,MACrE;AAAA,IACF,QAAQ;AAAA,IAER;AAKA,UAAM,YAAY,MAAM,gBAAgB,IAAI;AAE5C,QAAI,CAAC,UAAU,aAAa;AAC1B,UAAI,2DAAsD,UAAU,UAAU,GAAG;AAEjF,UAAI,+BAA+B;AACnC,UAAI;AACF,cAAM,KAAK,YAAY,oBAAoB,EAAE,WAAW,IAAM,CAAC;AAC/D,YAAI,oBAAoB;AAAA,MAC1B,QAAQ;AACN,YAAI,2CAA2C;AAAA,MACjD;AACA,YAAM,KAAK,sBAAsB,EAAE,MAAM,MAAM;AAAA,MAAC,CAAC;AACjD,UAAI,mBAAmB;AACvB,aAAO,EAAE,UAAU,MAAM,QAAQ,mBAAmB,UAAU,QAAQ;AAAA,IACxE;AAGA;AAAA,MACE,WAAM,UAAU,KAAM,QAAQ,CAAC,CAAC,oCAAoC,UAAU,UAAU;AAAA,IAC1F;AAGA,UAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,cAAc,CAAC;AAAA,EACpE;AAGA,SAAO;AAAA,IACL,UAAU;AAAA,IACV,QAAQ;AAAA,IACR,UAAU,KAAK,IAAI,IAAI;AAAA,EACzB;AACF;;;ACzEA,IAAMC,sBAAqB;AAKpB,IAAM,aAAN,MAAmC;AAAA,EAC/B,SAAuB,eAAe;AAAA,EAE/C,MAAM,OAAO,MAAyC;AACpD,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,EAAE,KAAK,SAAS,QAAAC,SAAQ,YAAY,IAAI;AAG9C,UAAM,OAAO,QAAQ;AACrB,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,uBAAuB,QAAQ,4BAA4B;AAAA,IACvE;AAGA,QAAI,aAAa,SAAS;AACxB,YAAM,IAAI,mBAAmB,QAAQ,CAAC;AAAA,IACxC;AAEA,IAAAA,SAAQ,MAAM,qCAAqC,GAAG,EAAE;AAExD,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,YAAY,OAAO,SAAe;AAE1D,YAAI,UAAU;AACd,YAAI,aAAa;AACf,sBAAY,iBAAiB,SAAS,MAAM;AAC1C,sBAAU;AAAA,UACZ,GAAG,EAAE,MAAM,KAAK,CAAC;AAAA,QACnB;AAGA,cAAM,YAAY,QAAQ,aAAa,KAAK,OAAO;AACnD,cAAM,KAAK,KAAK,KAAK,EAAE,UAAU,CAAC;AAElC,YAAI,SAAS;AACX,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,IAAI,IAAI,SAAS;AAAA,QAC7D;AAGA,YAAI;AACF,gBAAM,KAAK,YAAY,oBAAoB,EAAE,UAAU,CAAC;AAAA,QAC1D,QAAQ;AAAA,QAER;AACA,cAAM,KAAK,sBAAsB;AAEjC,YAAI,SAAS;AACX,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,IAAI,IAAI,SAAS;AAAA,QAC7D;AAGA,cAAM,aAAa,MAAM,KAAK;AAC9B,cAAM,YAAY,MAAM,gBAAgB,IAAI;AAE5C,YAAI,UAAU,aAAa;AACzB,UAAAA,SAAQ,MAAM,8BAA8B,UAAU,IAAI,EAAE;AAG5D,cAAI,UAAU,SAAS,WAAW;AAChC,kBAAM,IAAI,uBAAuB,QAAQ,SAAS;AAAA,UACpD;AAGA,gBAAM,aAAa,MAAM,2BAA2B,MAAM;AAAA,YACxD,WAAW;AAAA,YACX,gBAAgB;AAAA,YAChB,SAAS,QAAQ;AAAA,YACjB;AAAA,UACF,CAAC;AAED,cAAI,CAAC,WAAW,UAAU;AACxB,kBAAM,IAAI,uBAAuB,QAAQ,eAAe,UAAU,IAAI,EAAE;AAAA,UAC1E;AAEA,UAAAA,SAAQ,MAAM,iCAAiC,WAAW,MAAM,OAAO,WAAW,QAAQ,IAAI;AAAA,QAChG;AAEA,YAAI,SAAS;AACX,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,IAAI,IAAI,SAAS;AAAA,QAC7D;AAGA,cAAM,KAAK,iBAAiB,MAAM,KAAKA,OAAM;AAE7C,YAAI,SAAS;AACX,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,IAAI,IAAI,SAAS;AAAA,QAC7D;AAGA,YAAI,QAAQ,iBAAiB;AAC3B,cAAI;AACF,kBAAM,KAAK,eAAe,KAAK,SAAS,cAAc,QAAQ,eAAe,GAAG;AAAA,cAC9E;AAAA,YACF,CAAC;AAAA,UACH,QAAQ;AACN,YAAAA,SAAQ,MAAM,8BAA8B,QAAQ,eAAe,EAAE;AAAA,UACvE;AAAA,QACF;AAGA,cAAM,OAAO,MAAM,KAAK,SAAS,gBAAgB;AACjD,cAAM,WAAW,MAAM,KAAK;AAG5B,cAAM,cAAc,KAAK,YAAY,IAAI;AACzC,YAAI,YAAY,SAASD,qBAAoB;AAC3C,UAAAC,SAAQ,MAAM,gCAAgC,YAAY,MAAM,QAAQ;AACxE,gBAAM,IAAI,yBAAyB,QAAQ,YAAY,QAAQD,mBAAkB;AAAA,QACnF;AAEA,cAAM,WAAW,KAAK,IAAI,IAAI;AAC9B,QAAAC,SAAQ,MAAM,mBAAmB,KAAK,MAAM,aAAa,QAAQ,IAAI;AAErE,eAAO;AAAA,UACL;AAAA,UACA,KAAK;AAAA,UACL,YAAY;AAAA;AAAA,UACZ,QAAQ;AAAA,UACR;AAAA,QACF;AAAA,MACF,CAAC;AAED,aAAO;AAAA,IACT,SAAS,OAAgB;AAEvB,UACE,iBAAiB,0BACjB,iBAAiB,4BACjB,iBAAiB,sBACjB,iBAAiB,wBACjB;AACA,cAAM;AAAA,MACR;AAGA,UAAI,iBAAiB,OAAO;AAE1B,YAAI,MAAM,SAAS,kBAAkB,MAAM,QAAQ,SAAS,SAAS,GAAG;AACtE,gBAAM,IAAI,mBAAmB,QAAQ,KAAK,OAAO,UAAU;AAAA,QAC7D;AAGA,YAAI,MAAM,QAAQ,SAAS,YAAY,KAAK,MAAM,QAAQ,SAAS,MAAM,GAAG;AAC1E,gBAAM,IAAI,YAAY,QAAQ,sBAAsB,MAAM,OAAO,IAAI,EAAE,OAAO,MAAM,CAAC;AAAA,QACvF;AAGA,cAAM,IAAI,YAAY,QAAQ,MAAM,SAAS,EAAE,OAAO,MAAM,CAAC;AAAA,MAC/D;AAEA,YAAM,IAAI,YAAY,QAAQ,OAAO,KAAK,CAAC;AAAA,IAC7C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,iBAAiB,MAAY,aAAqBA,SAA8C;AAC5G,UAAM,YAAY;AAClB,UAAM,YAAY,KAAK,IAAI;AAG3B,QAAI;AACF,YAAM,KAAK,YAAY,oBAAoB,EAAE,WAAW,UAAU,CAAC;AAAA,IACrE,QAAQ;AAAA,IAER;AAGA,QAAI,aAAa,MAAM,KAAK;AAC5B,UAAMC,gBAAe,CAAC,QAAgB,IAAI,QAAQ,QAAQ,EAAE;AAC5D,UAAM,aAAaA,cAAa,UAAU,MAAMA,cAAa,WAAW;AAExE,QAAI,cAAc,WAAW,SAAS,UAAU,GAAG;AACjD,MAAAD,SAAQ,MAAM,wCAAwC,WAAW,WAAM,UAAU,EAAE;AAGnF,UAAI,UAAU;AACd,UAAI,cAAc;AAElB,aAAO,KAAK,IAAI,IAAI,YAAY,WAAW;AACzC,cAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,GAAG,CAAC;AAEvD,YAAI;AACF,uBAAa,MAAM,KAAK;AAGxB,cAAI,eAAe,SAAS;AAC1B;AACA,gBAAI,eAAe,GAAG;AACpB;AAAA,YACF;AAAA,UACF,OAAO;AACL,0BAAc;AACd,sBAAU;AACV,YAAAA,SAAQ,MAAM,0BAA0B,UAAU,EAAE;AAAA,UACtD;AAAA,QACF,QAAQ;AAAA,QAER;AAAA,MACF;AAGA,UAAI;AACF,cAAM,KAAK,YAAY,oBAAoB,EAAE,WAAW,IAAM,CAAC;AAAA,MACjE,QAAQ;AAAA,MAER;AAAA,IACF;AAGA,UAAM,KAAK,sBAAsB;AAGjC,UAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,GAAI,CAAC;AAAA,EAC1D;AAAA;AAAA;AAAA;AAAA,EAKQ,YAAY,MAAsB;AACxC,WAAO,KACJ,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,mCAAmC,EAAE,EAC7C,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;AAAA,EACV;AAAA,EAEA,cAAuB;AAGrB,WAAO;AAAA,EACT;AACF;AAKO,IAAM,aAAa,IAAI,WAAW;;;ACxNzC,IAAM,kBAA8C;AAAA,EAClD,MAAM;AAAA,EACN,WAAW;AAAA,EACX,MAAM;AACR;AAyBO,IAAM,qBAAN,MAAyB;AAAA,EACtB;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,UAA+B,CAAC,GAAG;AAC7C,SAAK,UAAU;AACf,SAAK,cAAc,KAAK,mBAAmB;AAC3C,SAAK,UAAU,KAAK,YACjB,IAAI,CAAC,SAAS,gBAAgB,IAAI,CAAC,EACnC,OAAO,CAAC,WAAW,OAAO,YAAY,CAAC;AAAA,EAC5C;AAAA;AAAA;AAAA;AAAA,EAKQ,qBAAmC;AAEzC,QAAI,KAAK,QAAQ,aAAa;AAC5B,aAAO,CAAC,KAAK,QAAQ,WAAW;AAAA,IAClC;AAGA,QAAI,QAAQ,KAAK,QAAQ,WAAW,CAAC,GAAG,oBAAoB;AAG5D,QAAI,KAAK,QAAQ,aAAa;AAC5B,cAAQ,MAAM,OAAO,CAAC,MAAM,CAAC,KAAK,QAAQ,YAAa,SAAS,CAAC,CAAC;AAAA,IACpE;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,sBAAoC;AAClC,WAAO,KAAK,QAAQ,IAAI,CAAC,MAAM,EAAE,OAAO,IAAI;AAAA,EAC9C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,OAAO,MAA+C;AAC1D,UAAM,mBAAiC,CAAC;AACxC,UAAM,eAAe,oBAAI,IAAuB;AAChD,UAAME,UAAS,KAAK,UAAU,KAAK,QAAQ;AAC3C,UAAM,UAAU,KAAK,QAAQ,WAAW,KAAK,QAAQ;AAErD,QAAI,KAAK,QAAQ,WAAW,GAAG;AAC7B,YAAM,IAAI,sBAAsB,CAAC,GAAG,YAAY;AAAA,IAClD;AAEA,UAAM,MAAM,CAAC,QAAgB;AAC3B,UAAI,SAAS;AACX,QAAAA,SAAQ,KAAK,GAAG;AAAA,MAClB,OAAO;AACL,QAAAA,SAAQ,MAAM,GAAG;AAAA,MACnB;AAAA,IACF;AAEA,QAAI,qCAAqC,KAAK,GAAG,kBAAkB,KAAK,YAAY,KAAK,UAAK,CAAC,EAAE;AAGjG,eAAW,UAAU,KAAK,SAAS;AACjC,YAAM,aAAa,OAAO,OAAO;AACjC,uBAAiB,KAAK,UAAU;AAEhC,UAAI;AACF,YAAI,yBAAyB,UAAU,YAAY;AAGnD,cAAM,aAAa,IAAI,gBAAgB;AACvC,cAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,OAAO,OAAO,UAAU;AAG/E,YAAI,KAAK,aAAa;AACpB,eAAK,YAAY,iBAAiB,SAAS,MAAM,WAAW,MAAM,GAAG,EAAE,MAAM,KAAK,CAAC;AAAA,QACrF;AAEA,YAAI;AACF,gBAAM,SAAS,MAAM,OAAO,OAAO;AAAA,YACjC,GAAG;AAAA,YACH,aAAa,WAAW;AAAA,UAC1B,CAAC;AAED,uBAAa,SAAS;AAEtB,cAAI,yBAAoB,UAAU,iBAAiB,OAAO,QAAQ,IAAI;AAEtE,iBAAO;AAAA,YACL,GAAG;AAAA,YACH;AAAA,YACA;AAAA,UACF;AAAA,QACF,UAAE;AACA,uBAAa,SAAS;AAAA,QACxB;AAAA,MACF,SAAS,OAAgB;AACvB,cAAM,MAAM,iBAAiB,QAAQ,QAAQ,IAAI,MAAM,OAAO,KAAK,CAAC;AACpE,qBAAa,IAAI,YAAY,GAAG;AAGhC,YAAI,iBAAiB,wBAAwB;AAC3C,cAAI,kBAAkB,UAAU,wBAAwB,MAAM,aAAa,EAAE;AAAA,QAC/E,WAAW,iBAAiB,0BAA0B;AACpD,cAAI,kBAAkB,UAAU,0BAA0B,MAAM,aAAa,QAAQ;AAAA,QACvF,WAAW,iBAAiB,WAAW;AACrC,cAAI,kBAAkB,UAAU,gBAAgB,MAAM,UAAU,EAAE;AAAA,QACpE,WAAW,iBAAiB,oBAAoB;AAC9C,cAAI,kBAAkB,UAAU,oBAAoB,MAAM,SAAS,IAAI;AAAA,QACzE,WAAW,iBAAiB,wBAAwB;AAClD,cAAI,kBAAkB,UAAU,iBAAiB,IAAI,OAAO,EAAE;AAAA,QAChE,OAAO;AACL,cAAI,kBAAkB,UAAU,YAAY,IAAI,OAAO,EAAE;AAAA,QAC3D;AAGA,YAAI,CAAC,KAAK,YAAY,KAAK,GAAG;AAC5B,cAAI,sDAAsD;AAC1D;AAAA,QACF;AAGA,YAAI,+CAA+C;AAAA,MACrD;AAAA,IACF;AAGA,QAAI,yCAAyC,KAAK,GAAG,EAAE;AACvD,UAAM,IAAI,sBAAsB,kBAAkB,YAAY;AAAA,EAChE;AAAA;AAAA;AAAA;AAAA,EAKQ,YAAY,OAAyB;AAE3C,QACE,iBAAiB,0BACjB,iBAAiB,4BACjB,iBAAiB,oBACjB;AACA,aAAO;AAAA,IACT;AAOA,QAAI,iBAAiB,WAAW;AAC9B,aAAO,MAAM,eAAe,OAAO,MAAM,eAAe,OAAO,MAAM,eAAe,OAAO,MAAM,cAAc;AAAA,IACjH;AAGA,QAAI,iBAAiB,wBAAwB;AAC3C,aAAO;AAAA,IACT;AAGA,QAAI,iBAAiB,aAAa;AAChC,aAAO,MAAM;AAAA,IACf;AAGA,WAAO;AAAA,EACT;AACF;;;AfzNO,IAAM,UAAN,MAAc;AAAA,EACX;AAAA,EACA,SAAS,aAAa,SAAS;AAAA,EAC/B,cAA+C,oBAAI,IAAI;AAAA,EAE/D,YAAY,SAAwB;AAElC,SAAK,UAAU;AAAA,MACb,GAAG;AAAA,MACH,GAAG;AAAA,IACL;AAAA,EAIF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,eAAe,KAA0C;AACrE,UAAM,SAAS,IAAI,IAAI,GAAG,EAAE;AAC5B,QAAI,CAAC,KAAK,YAAY,IAAI,MAAM,GAAG;AACjC,YAAM,QAAQ,MAAM,eAAe,MAAM;AACzC,WAAK,YAAY,IAAI,QAAQ,KAAK;AAAA,IACpC;AACA,WAAO,KAAK,YAAY,IAAI,MAAM,KAAK;AAAA,EACzC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,SAAgC;AACpC,UAAM,YAAY,KAAK,IAAI;AAI3B,UAAM,UAAU,MAAM,KAAK,sBAAsB;AAGjD,WAAO,KAAK,kBAAkB,SAAS,SAAS;AAAA,EAClD;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,wBAEZ;AACA,UAAM,QAAQ,OAAO,KAAK,QAAQ,oBAAoB,CAAC;AACvD,UAAM,QAAQ,KAAK,QAAQ,KAAK;AAAA,MAAI,CAAC,KAAK,UACxC,MAAM,MAAM,KAAK,yBAAyB,KAAK,KAAK,CAAC;AAAA,IACvD;AAEA,UAAM,eAAe,QAAQ,IAAI,KAAK;AAGtC,QAAI,KAAK,QAAQ,kBAAkB,KAAK,QAAQ,iBAAiB,GAAG;AAClE,YAAM,iBAAiB,IAAI,QAAe,CAAC,GAAG,WAAW;AACvD,mBAAW,MAAM;AACf,iBAAO,IAAI,MAAM,mCAAmC,KAAK,QAAQ,cAAc,IAAI,CAAC;AAAA,QACtF,GAAG,KAAK,QAAQ,cAAc;AAAA,MAChC,CAAC;AAED,aAAO,QAAQ,KAAK,CAAC,cAAc,cAAc,CAAC;AAAA,IACpD;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,yBACZ,KACA,OACiE;AACjE,UAAM,aAAa,KAAK,QAAQ,cAAc;AAC9C,QAAI;AAEJ,aAAS,UAAU,GAAG,WAAW,YAAY,WAAW;AACtD,UAAI;AACF,cAAM,SAAS,MAAM,KAAK,gBAAgB,KAAK,KAAK;AACpD,YAAI,QAAQ;AACV,iBAAO,EAAE,OAAO;AAAA,QAClB;AAEA,oBAAY,oBAAoB,GAAG;AAAA,MACrC,SAAS,OAAY;AACnB,oBAAY,MAAM;AAClB,YAAI,UAAU,YAAY;AAExB,gBAAM,QAAQ,KAAK,IAAI,GAAG,OAAO,IAAI;AACrC,eAAK,OAAO,KAAK,SAAS,UAAU,CAAC,IAAI,UAAU,QAAQ,GAAG,OAAO,KAAK,IAAI;AAC9E,gBAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,KAAK,CAAC;AAAA,QAC3D;AAAA,MACF;AAAA,IACF;AAEA,SAAK,OAAO,MAAM,oBAAoB,GAAG,UAAU,aAAa,CAAC,cAAc,SAAS,EAAE;AAC1F,WAAO,EAAE,QAAQ,MAAM,OAAO,UAAU;AAAA,EAC1C;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBAAgB,KAAa,OAAoD;AAC7F,UAAM,YAAY,KAAK,IAAI;AAG3B,UAAM,cAAc,MAAM,KAAK,eAAe,GAAG;AACjD,QAAI,CAAC,aAAa,KAAK,WAAW,GAAG;AACnC,YAAM,IAAI,MAAM,8BAA8B,GAAG,EAAE;AAAA,IACrD;AAEA,QAAI;AAEF,YAAM,eAAe,IAAI,mBAAmB;AAAA,QAC1C,SAAS,KAAK,QAAQ;AAAA,QACtB,aAAa,KAAK,QAAQ;AAAA,QAC1B,aAAa,KAAK,QAAQ;AAAA,QAC1B,QAAQ,KAAK;AAAA,QACb,SAAS,KAAK,QAAQ;AAAA,MACxB,CAAC;AAGD,YAAM,eAAe,MAAM,aAAa,OAAO;AAAA,QAC7C;AAAA,QACA,SAAS,KAAK;AAAA,QACd,QAAQ,KAAK;AAAA,MACf,CAAC;AAED,UAAI,KAAK,QAAQ,SAAS;AACxB,aAAK,OAAO;AAAA,UACV,aAAa,GAAG,iBAAiB,aAAa,MAAM,cAAc,aAAa,QAAQ,kBACtE,aAAa,iBAAiB,KAAK,UAAK,CAAC;AAAA,QAC5D;AAAA,MACF;AAGA,YAAM,cAAc,aAAa,aAAa,MAAM,aAAa,KAAK;AAAA,QACpE,WAAW,KAAK,QAAQ;AAAA,QACxB,oBAAoB,KAAK,QAAQ;AAAA,QACjC,iBAAiB,KAAK,QAAQ;AAAA,QAC9B,aAAa,KAAK,QAAQ;AAAA,QAC1B,aAAa,KAAK,QAAQ;AAAA,MAC5B,CAAC;AAGD,YAAM,kBAAkB,gBAAgB,aAAa,aAAa,GAAG;AAErE,YAAM,WAAW,KAAK,IAAI,IAAI;AAG9B,YAAM,WAAW,KAAK,QAAQ,QAAQ,SAAS,UAAU,IACrD,eAAe,WAAW,IAC1B;AAEJ,YAAM,aAAa,KAAK,QAAQ,QAAQ,SAAS,MAAM,IAAI,cAAc;AAGzE,UAAI,KAAK,QAAQ,YAAY;AAC3B,aAAK,QAAQ,WAAW;AAAA,UACtB,WAAW,QAAQ;AAAA,UACnB,OAAO,KAAK,QAAQ,KAAK;AAAA,UACzB,YAAY;AAAA,QACd,CAAC;AAAA,MACH;AAGA,UAAI;AACJ,UAAI,KAAK,QAAQ,OAAO;AACtB,cAAM,QAAQ,KAAK,QAAQ;AAE3B,YAAI,MAAM,KAAK;AACb,cAAI;AACF,kBAAM,WAAW,IAAI,IAAI,MAAM,GAAG;AAClC,4BAAgB;AAAA,cACd,MAAM,SAAS;AAAA,cACf,MAAM,SAAS,SAAS,MAAM,EAAE,KAAK;AAAA,cACrC,SAAS,MAAM;AAAA,YACjB;AAAA,UACF,QAAQ;AAAA,UAER;AAAA,QACF,WAAW,MAAM,QAAQ,MAAM,MAAM;AACnC,0BAAgB;AAAA,YACd,MAAM,MAAM;AAAA,YACZ,MAAM,MAAM;AAAA,YACZ,SAAS,MAAM;AAAA,UACjB;AAAA,QACF;AAAA,MACF;AAGA,YAAM,SAA8B;AAAA,QAClC;AAAA,QACA,MAAM;AAAA,QACN,UAAU;AAAA,UACR,SAAS;AAAA,UACT,YAAY;AAAA,UACZ,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,UAClC;AAAA,UACA,SAAS;AAAA,UACT,OAAO;AAAA,QACT;AAAA,MACF;AAEA,aAAO;AAAA,IACT,SAAS,OAAgB;AAEvB,UAAI,iBAAiB,uBAAuB;AAC1C,cAAM,gBAAgB,MAAM,iBACzB,IAAI,CAAC,MAAM,GAAG,CAAC,KAAK,MAAM,OAAO,IAAI,CAAC,GAAG,WAAW,SAAS,EAAE,EAC/D,KAAK,IAAI;AACZ,aAAK,OAAO,MAAM,oBAAoB,GAAG,0BAA0B,aAAa,EAAE;AAAA,MACpF,WAAW,iBAAiB,OAAO;AACjC,aAAK,OAAO,MAAM,oBAAoB,GAAG,KAAK,MAAM,OAAO,EAAE;AAAA,MAC/D,OAAO;AACL,aAAK,OAAO,MAAM,oBAAoB,GAAG,KAAK,OAAO,KAAK,CAAC,EAAE;AAAA,MAC/D;AAGA,UAAI,KAAK,QAAQ,YAAY;AAC3B,aAAK,QAAQ,WAAW;AAAA,UACtB,WAAW,QAAQ;AAAA,UACnB,OAAO,KAAK,QAAQ,KAAK;AAAA,UACzB,YAAY;AAAA,QACd,CAAC;AAAA,MACH;AAEA,aAAO;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,kBACN,SACA,WACc;AACd,UAAM,aAAa,QAChB,OAAO,CAAC,MAAM,EAAE,WAAW,IAAI,EAC/B,IAAI,CAAC,MAAM,EAAE,MAA6B;AAE7C,UAAM,SAAgD,CAAC;AACvD,YAAQ,QAAQ,CAAC,GAAG,UAAU;AAC5B,UAAI,EAAE,WAAW,QAAQ,EAAE,OAAO;AAChC,eAAO,KAAK,EAAE,KAAK,KAAK,QAAQ,KAAK,KAAK,GAAG,OAAO,EAAE,MAAM,CAAC;AAAA,MAC/D;AAAA,IACF,CAAC;AAED,UAAM,gBAA+B;AAAA,MACnC,WAAW,KAAK,QAAQ,KAAK;AAAA,MAC7B,gBAAgB,WAAW;AAAA,MAC3B,YAAY,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,IAAI,EAAE;AAAA,MACrD,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MAClC,eAAe,KAAK,IAAI,IAAI;AAAA,MAC5B;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAcA,eAAsB,OAAO,SAA+C;AAC1E,QAAM,UAAU,IAAI,QAAQ,OAAO;AACnC,SAAO,QAAQ,OAAO;AACxB;;;AgBjUA,SAAS,aAAAC,kBAAiB;;;ACD1B,OAAOC,aAAY;AAKnB,eAAsB,UAAU,IAA2B;AACzD,SAAO,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC;AACzD;;;AD2BO,IAAM,UAAN,MAAc;AAAA,EACX;AAAA,EAYA,UAAuB,oBAAI,IAAI;AAAA,EAC/B,QAA+C,CAAC;AAAA,EAChD,OAAmB,CAAC;AAAA,EACpB;AAAA,EACA,SAAS,aAAa,SAAS;AAAA,EAC/B,cAAkC;AAAA,EAE1C,YAAY,SAAuB;AAEjC,QAAI,CAAC,QAAQ,MAAM;AACjB,YAAM,IAAI,MAAM,gFAAgF;AAAA,IAClG;AACA,SAAK,OAAO,QAAQ;AAEpB,SAAK,UAAU;AAAA,MACb,KAAK,QAAQ;AAAA,MACb,OAAO,QAAQ,SAAS;AAAA,MACxB,UAAU,QAAQ,YAAY;AAAA,MAC9B,QAAQ,QAAQ,UAAU;AAAA,MAC1B,SAAS,QAAQ,WAAW;AAAA,MAC5B,WAAW,QAAQ;AAAA,MACnB,iBAAiB,QAAQ;AAAA,MACzB,iBAAiB,QAAQ;AAAA,MACzB,SAAS,QAAQ,WAAW,CAAC,YAAY,MAAM;AAAA,MAC/C,mBAAmB,QAAQ,qBAAqB;AAAA,MAChD,OAAO,QAAQ;AAAA,MACf,WAAW,QAAQ;AAAA,MACnB,SAAS,QAAQ,WAAW;AAAA,MAC5B,YAAY,QAAQ,cAAc;AAAA,MAClC,kBAAkB,QAAQ;AAAA;AAAA,MAE1B,WAAW,QAAQ;AAAA,MACnB,oBAAoB,QAAQ;AAAA,IAC9B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAA8B;AAClC,UAAM,YAAY,KAAK,IAAI;AAG3B,SAAK,cAAc,MAAM,eAAe,KAAK,QAAQ,GAAG;AACxD,QAAI,KAAK,aAAa;AACpB,WAAK,OAAO,KAAK,yBAAyB;AAAA,IAC5C;AAIA,QAAI,aAAa,KAAK,QAAQ,KAAK,KAAK,WAAW,GAAG;AACpD,WAAK,MAAM,KAAK,EAAE,KAAK,KAAK,QAAQ,KAAK,OAAO,EAAE,CAAC;AAAA,IACrD,OAAO;AACL,WAAK,OAAO,KAAK,mCAAmC,KAAK,QAAQ,GAAG,EAAE;AAAA,IACxE;AAGA,WAAO,KAAK,MAAM,SAAS,KAAK,KAAK,KAAK,SAAS,KAAK,QAAQ,UAAU;AAExE,UAAI,KAAK,QAAQ,aAAa,KAAK,IAAI,IAAI,YAAY,KAAK,QAAQ,WAAW;AAC7E,aAAK,OAAO,KAAK,yBAAyB,KAAK,QAAQ,SAAS,IAAI;AACpE;AAAA,MACF;AAEA,YAAM,OAAO,KAAK,MAAM,MAAM;AAC9B,YAAM,SAAS,UAAU,KAAK,GAAG;AAEjC,UAAI,KAAK,QAAQ,IAAI,MAAM,GAAG;AAC5B;AAAA,MACF;AAGA,YAAM,SAAS,MAAM,KAAK,UAAU,KAAK,GAAG;AAE5C,UAAI,QAAQ;AACV,aAAK,KAAK,KAAK,OAAO,QAAQ;AAC9B,aAAK,QAAQ,IAAI,MAAM;AAGvB,YAAI,KAAK,QAAQ,KAAK,QAAQ,OAAO;AACnC,gBAAM,QAAQ,KAAK,aAAa,OAAO,MAAM,KAAK,KAAK,KAAK,QAAQ,CAAC;AACrE,eAAK,MAAM,KAAK,GAAG,KAAK;AAAA,QAC1B;AAAA,MACF;AAGA,YAAM,QAAQ,KAAK,aAAa,cAAc,KAAK,QAAQ;AAC3D,YAAM,UAAU,KAAK;AAAA,IACvB;AAGA,UAAM,WAA0B;AAAA,MAC9B,WAAW,KAAK,KAAK;AAAA,MACrB,UAAU,KAAK,QAAQ;AAAA,MACvB,eAAe,KAAK,IAAI,IAAI;AAAA,MAC5B,SAAS,KAAK,QAAQ;AAAA,IACxB;AAGA,QAAI;AACJ,QAAI,KAAK,QAAQ,QAAQ;AACvB,gBAAU,MAAM,KAAK,qBAAqB;AAAA,IAC5C;AAEA,WAAO;AAAA,MACL,MAAM,KAAK;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,UAAU,KAAmE;AACzF,QAAI;AACF,aAAO,MAAM,KAAK,KAAK,YAAY,OAAO,SAAe;AAEvD,cAAM,KAAK,KAAK,KAAK,EAAE,WAAW,IAAM,CAAC;AACzC,cAAM,KAAK,sBAAsB;AAGjC,cAAM,aAAa,MAAM,KAAK;AAC9B,cAAM,YAAY,MAAM,gBAAgB,IAAI;AAE5C,YAAI,UAAU,aAAa;AACzB,cAAI,KAAK,QAAQ,SAAS;AACxB,iBAAK,OAAO,KAAK,yBAAyB,GAAG,EAAE;AAAA,UACjD;AAEA,gBAAM,SAAS,MAAM,2BAA2B,MAAM;AAAA,YACpD,WAAW;AAAA,YACX,gBAAgB;AAAA,YAChB,SAAS,KAAK,QAAQ;AAAA,YACtB;AAAA,UACF,CAAC;AAED,cAAI,CAAC,OAAO,UAAU;AACpB,kBAAM,IAAI,MAAM,wBAAwB;AAAA,UAC1C;AAAA,QACF;AAGA,cAAM,QAAQ,MAAM,KAAK,SAAS;AAClC,cAAM,OAAO,MAAM,KAAK,SAAS,gBAAgB;AAGjD,YAAI,cAA6B;AACjC,YAAI;AACF,gBAAM,WAAW,MAAM,KAAK,SAAS,cAAc,0BAA0B;AAC7E,cAAI,UAAU;AACZ,0BAAc,MAAM,SAAS,aAAa,SAAS;AAAA,UACrD;AAAA,QACF,QAAQ;AAAA,QAER;AAEA,eAAO;AAAA,UACL,UAAU;AAAA,YACR;AAAA,YACA,OAAO,SAAS;AAAA,YAChB;AAAA,UACF;AAAA,UACA;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,SAAS,OAAY;AACnB,WAAK,OAAO,MAAM,mBAAmB,GAAG,KAAK,MAAM,OAAO,EAAE;AAC5D,aAAO;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,aACN,MACA,SACA,OACuC;AACvC,UAAM,QAA+C,CAAC;AACtD,UAAM,EAAE,SAAS,IAAIC,WAAU,IAAI;AAGnC,aAAS,iBAAiB,SAAS,EAAE,QAAQ,CAAC,WAAoB;AAChE,YAAM,UAAU,OAAO,aAAa,MAAM;AAC1C,UAAI,CAAC,QAAS;AAGd,YAAM,OAAO,QAAQ,KAAK;AAC1B,UAAI,CAAC,KAAM;AAGX,UAAI,KAAK,WAAW,GAAG,EAAG;AAG1B,YAAM,YAAY,KAAK,YAAY;AACnC,UACE,UAAU,WAAW,aAAa,KAClC,UAAU,WAAW,SAAS,KAC9B,UAAU,WAAW,MAAM,KAC3B,UAAU,WAAW,OAAO,KAC5B,UAAU,WAAW,OAAO,KAC5B,UAAU,WAAW,MAAM,GAC3B;AACA;AAAA,MACF;AAGA,UAAI,WAAW,WAAW,MAAM,OAAO;AACvC,UAAI,CAAC,YAAY,CAAC,WAAW,QAAQ,EAAG;AAGxC,UAAI;AACF,cAAM,SAAS,IAAI,IAAI,QAAQ;AAC/B,eAAO,OAAO;AACd,mBAAW,OAAO,SAAS;AAAA,MAC7B,QAAQ;AACN;AAAA,MACF;AAGA,UAAI,CAAC,aAAa,UAAU,KAAK,QAAQ,GAAG,EAAG;AAG/C,UAAI,CAAC,aAAa,QAAQ,EAAG;AAG7B,UAAI,CAAC,iBAAiB,UAAU,KAAK,QAAQ,iBAAiB,KAAK,QAAQ,eAAe,EAAG;AAG7F,UAAI,CAAC,aAAa,UAAU,KAAK,WAAW,EAAG;AAG/C,YAAM,SAAS,UAAU,QAAQ;AACjC,UAAI,KAAK,QAAQ,IAAI,MAAM,KAAK,KAAK,MAAM,KAAK,CAAC,MAAM,UAAU,EAAE,GAAG,MAAM,MAAM,GAAG;AACnF;AAAA,MACF;AAEA,YAAM,KAAK,EAAE,KAAK,UAAU,MAAM,CAAC;AAAA,IACrC,CAAC;AAED,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,uBAA8C;AAC1D,UAAM,OAAO,KAAK,KAAK,IAAI,CAAC,MAAM,EAAE,GAAG;AAEvC,WAAO,OAAO;AAAA,MACZ;AAAA,MACA,SAAS,KAAK,QAAQ;AAAA,MACtB,kBAAkB,KAAK,QAAQ;AAAA,MAC/B,OAAO,KAAK,QAAQ;AAAA,MACpB,WAAW,KAAK,QAAQ;AAAA,MACxB,SAAS,KAAK,QAAQ;AAAA,MACtB,YAAY,KAAK,QAAQ;AAAA,MACzB,MAAM,KAAK;AAAA;AAAA,MAEX,WAAW,KAAK,QAAQ;AAAA,MACxB,oBAAoB,KAAK,QAAQ;AAAA,IACnC,CAAC;AAAA,EACH;AACF;AAgBA,eAAsB,MAAM,SAA6C;AACvE,QAAM,UAAU,IAAI,QAAQ,OAAO;AACnC,SAAO,QAAQ,MAAM;AACvB;;;AE5UA,OAAO,UAAU;;;ACkCV,SAAS,eAAe,QAA6B;AAE1D,MAAI,OAAO,KAAK;AACd,WAAO,OAAO;AAAA,EAChB;AAGA,MAAI,OAAO,SAAS,eAAe;AAEjC,UAAM,YAAY,QAAQ,KAAK,IAAI,CAAC,IAAI,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,MAAM,GAAG,CAAC,CAAC;AAG9E,WAAO,mBAAmB,OAAO,QAAQ,YAAY,SAAS,YAC5D,OAAO,WAAW,IACpB,IAAI,OAAO,QAAQ,IAAI,OAAO,IAAI,IAAI,OAAO,IAAI;AAAA,EACnD;AAGA,SAAO,UAAU,OAAO,QAAQ,IAAI,OAAO,QAAQ,IAAI,OAAO,IAAI,IAAI,OAAO,IAAI;AACnF;;;ACvBO,SAAS,iBAAiB,UAA6B,CAAC,GAAQ;AACrE,QAAM,SAAc;AAAA;AAAA,IAElB,YAAY,QAAQ,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAOlC,aAAa;AAAA;AAAA;AAAA;AAAA;AAAA,IAMb,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,IAMlB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAOjB,oBAAoB;AAAA,MAClB,MAAM;AAAA,MACN,YAAY;AAAA,IACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAOA,qBAAqB;AAAA,MACnB,iBAAiB;AAAA,IACnB;AAAA;AAAA;AAAA;AAAA,IAKA,QAAQ;AAAA,IACR,YAAY;AAAA;AAAA;AAAA;AAAA,IAKZ,UAAU;AAAA,MACR,OAAO;AAAA,MACP,QAAQ;AAAA,IACV;AAAA;AAAA;AAAA;AAAA,IAKA,GAAI,QAAQ,aAAa,EAAE,WAAW,QAAQ,UAAU;AAAA;AAAA;AAAA;AAAA,IAKxD,GAAI,QAAQ,oBAAoB,EAAE,kBAAkB,QAAQ,iBAAiB;AAAA,EAC/E;AAKA,MAAI,QAAQ,OAAO;AACjB,WAAO,mBAAmB,eAAe,QAAQ,KAAK;AAEtD,WAAO,4BAA4B;AAAA,EACrC;AAEA,SAAO;AACT;;;AF5FA,IAAM,sBAAkC;AAAA,EACtC,MAAM;AAAA,EACN,sBAAsB;AAAA,EACtB,kBAAkB,KAAK,KAAK;AAAA;AAAA,EAC5B,sBAAsB,KAAK;AAAA;AAAA,EAC3B,qBAAqB,IAAI,KAAK;AAAA;AAAA,EAC9B,wBAAwB;AAAA,EACxB,cAAc;AAAA,EACd,cAAc,KAAK;AAAA;AACrB;AAKA,SAAS,aAAqB;AAC5B,SAAO,WAAW,KAAK,IAAI,CAAC,IAAI,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,MAAM,GAAG,CAAC,CAAC;AACxE;AAuBO,IAAM,cAAN,MAA0C;AAAA,EACvC,YAA+B,CAAC;AAAA,EAChC,YAA+B,CAAC;AAAA,EAChC,QAA8B,oBAAI,IAAI;AAAA,EACtC,QAAqB,CAAC;AAAA,EACtB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,gBAAgB;AAAA,EAChB,uBAAuB;AAAA,EACvB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,SAAS,aAAa,MAAM;AAAA,EAEpC,YACE,SAA8B,CAAC,GAC/B,OACA,aAAsB,OACtB,kBACA,WACA,UAAmB,OACnB;AACA,SAAK,SAAS,EAAE,GAAG,qBAAqB,GAAG,OAAO;AAClD,SAAK,QAAQ;AACb,SAAK,aAAa;AAClB,SAAK,mBAAmB;AACxB,SAAK,YAAY;AACjB,SAAK,UAAU;AAAA,EACjB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAA4B;AAChC,QAAI,KAAK,SAAS;AAChB,WAAK,OAAO,KAAK,0BAA0B,KAAK,OAAO,IAAI,cAAc;AAAA,IAC3E;AAGA,UAAM,iBAA6C,CAAC;AACpD,aAAS,IAAI,GAAG,IAAI,KAAK,OAAO,MAAM,KAAK;AACzC,qBAAe,KAAK,KAAK,eAAe,CAAC;AAAA,IAC3C;AAEA,SAAK,YAAY,MAAM,QAAQ,IAAI,cAAc;AACjD,SAAK,YAAY,CAAC,GAAG,KAAK,SAAS;AAGnC,SAAK,eAAe;AACpB,SAAK,kBAAkB;AAEvB,QAAI,KAAK,SAAS;AAChB,WAAK,OAAO,KAAK,eAAe,KAAK,UAAU,MAAM,qBAAqB;AAAA,IAC5E;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAA0B;AAC9B,QAAI,KAAK,SAAS;AAChB,YAAM,QAAQ,KAAK,SAAS;AAC5B,WAAK,OAAO;AAAA,QACV,uBAAuB,MAAM,aAAa,8BACrC,KAAK,MAAM,MAAM,kBAAkB,CAAC;AAAA,MAC3C;AAAA,IACF;AAGA,QAAI,KAAK,aAAc,eAAc,KAAK,YAAY;AACtD,QAAI,KAAK,YAAa,eAAc,KAAK,WAAW;AAGpD,eAAW,QAAQ,KAAK,OAAO;AAC7B,WAAK,OAAO,IAAI,MAAM,oBAAoB,CAAC;AAAA,IAC7C;AACA,SAAK,QAAQ,CAAC;AAGd,UAAM,gBAAgB,KAAK,UAAU,IAAI,CAAC,aAAa,SAAS,KAAK,MAAM,EAAE,MAAM,MAAM;AAAA,IAAC,CAAC,CAAC;AAC5F,UAAM,QAAQ,IAAI,aAAa;AAG/B,QAAI,KAAK,kBAAkB;AACzB,UAAI;AACF,cAAM,KAAK,iBAAiB,WAAW;AAAA,MACzC,QAAQ;AAAA,MAER;AACA,WAAK,mBAAmB;AAAA,IAC1B;AAGA,SAAK,YAAY,CAAC;AAClB,SAAK,YAAY,CAAC;AAClB,SAAK,MAAM,MAAM;AAAA,EACnB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAyB;AAE7B,UAAM,WAAW,KAAK,UAAU,MAAM;AACtC,QAAI,CAAC,UAAU;AAEb,UAAI,KAAK,SAAS;AAChB,aAAK,OAAO,KAAK,kDAAkD,KAAK,MAAM,SAAS,CAAC,GAAG;AAAA,MAC7F;AACA,aAAO,KAAK,aAAa;AAAA,IAC3B;AAGA,aAAS,SAAS;AAClB,aAAS,WAAW,KAAK,IAAI;AAC7B,SAAK,MAAM,IAAI,QAAQ;AAEvB,QAAI,KAAK,SAAS;AAChB,WAAK,OAAO;AAAA,QACV,oBAAoB,SAAS,EAAE,gBAAgB,KAAK,UAAU,MAAM,WAAW,KAAK,MAAM,IAAI;AAAA,MAChG;AAAA,IACF;AAEA,WAAO,SAAS;AAAA,EAClB;AAAA;AAAA;AAAA;AAAA,EAKA,QAAQ,MAAkB;AACxB,UAAM,WAAW,KAAK,UAAU,KAAK,CAAC,MAAM,EAAE,SAAS,IAAI;AAC3D,QAAI,CAAC,SAAU;AAGf,aAAS,SAAS;AAClB,aAAS;AACT,SAAK,MAAM,OAAO,QAAQ;AAE1B,QAAI,KAAK,SAAS;AAChB,WAAK,OAAO;AAAA,QACV,oBAAoB,SAAS,EAAE,eAAe,SAAS,YAAY,gBAAgB,KAAK,UAAU,SAAS,CAAC;AAAA,MAC9G;AAAA,IACF;AAGA,QAAI,KAAK,cAAc,QAAQ,GAAG;AAChC,UAAI,KAAK,SAAS;AAChB,aAAK,OAAO,KAAK,qBAAqB,SAAS,EAAE,iCAAiC;AAAA,MACpF;AACA,WAAK,gBAAgB,QAAQ,EAAE,MAAM,MAAM;AAAA,MAAC,CAAC;AAAA,IAC/C,OAAO;AACL,WAAK,UAAU,KAAK,QAAQ;AAC5B,WAAK,aAAa;AAAA,IACpB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,YAAe,UAAkD;AACrE,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,OAAO,MAAM,KAAK,QAAQ;AAEhC,QAAI;AACF,YAAM,SAAS,MAAM,SAAS,IAAI;AAGlC,WAAK;AACL,WAAK,wBAAwB,KAAK,IAAI,IAAI;AAE1C,aAAO;AAAA,IACT,UAAE;AACA,WAAK,QAAQ,IAAI;AAAA,IACnB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,WAAsB;AACpB,UAAM,YAAY,KAAK,UAAU,OAAO,CAAC,MAAM,EAAE,WAAW,WAAW,EAAE;AACzE,UAAM,YAAY,KAAK,UAAU,OAAO,CAAC,MAAM,EAAE,WAAW,WAAW,EAAE;AAEzE,WAAO;AAAA,MACL,OAAO,KAAK,UAAU;AAAA,MACtB,WAAW,KAAK,UAAU;AAAA,MAC1B,MAAM,KAAK,MAAM;AAAA,MACjB;AAAA,MACA;AAAA,MACA,aAAa,KAAK,MAAM;AAAA,MACxB,eAAe,KAAK;AAAA,MACpB,oBACE,KAAK,gBAAgB,IAAI,KAAK,uBAAuB,KAAK,gBAAgB;AAAA,IAC9E;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAqC;AACzC,UAAM,SAAmB,CAAC;AAC1B,UAAM,QAAQ,KAAK,SAAS;AAG5B,QAAI,MAAM,YAAY,GAAG;AACvB,aAAO,KAAK,GAAG,MAAM,SAAS,sBAAsB;AAAA,IACtD;AAGA,QAAI,MAAM,cAAc,KAAK,OAAO,eAAe,KAAK;AACtD,aAAO,KAAK,wBAAwB,MAAM,WAAW,IAAI,KAAK,OAAO,YAAY,EAAE;AAAA,IACrF;AAGA,QAAI,MAAM,cAAc,KAAK,MAAM,cAAc,GAAG;AAClD,aAAO,KAAK,0DAA0D;AAAA,IACxE;AAEA,WAAO;AAAA,MACL,SAAS,OAAO,WAAW;AAAA,MAC3B;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAc,iBAA2C;AACvD,UAAM,aAAa,iBAAiB;AAAA,MAClC,OAAO,KAAK;AAAA,MACZ,YAAY,KAAK;AAAA,MACjB,kBAAkB,KAAK;AAAA,MACvB,WAAW,KAAK;AAAA,IAClB,CAAC;AAED,UAAM,OAAO,IAAI,KAAK,UAAU;AAEhC,WAAO;AAAA,MACL;AAAA,MACA,IAAI,WAAW;AAAA,MACf,WAAW,KAAK,IAAI;AAAA,MACpB,UAAU,KAAK,IAAI;AAAA,MACnB,cAAc;AAAA,MACd,QAAQ;AAAA,IACV;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,cAAc,UAAoC;AACxD,UAAM,MAAM,KAAK,IAAI,IAAI,SAAS;AAClC,WACE,SAAS,gBAAgB,KAAK,OAAO,wBACrC,OAAO,KAAK,OAAO;AAAA,EAEvB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBAAgB,UAA0C;AACtE,aAAS,SAAS;AAElB,QAAI;AAEF,YAAM,SAAS,KAAK,MAAM,EAAE,MAAM,MAAM;AAAA,MAAC,CAAC;AAG1C,YAAM,cAAc,MAAM,KAAK,eAAe;AAG9C,YAAM,QAAQ,KAAK,UAAU,QAAQ,QAAQ;AAC7C,UAAI,UAAU,IAAI;AAChB,aAAK,UAAU,KAAK,IAAI;AAAA,MAC1B;AAGA,WAAK,UAAU,KAAK,WAAW;AAE/B,UAAI,KAAK,SAAS;AAChB,aAAK,OAAO,KAAK,qBAAqB,SAAS,EAAE,WAAM,YAAY,EAAE,EAAE;AAAA,MACzE;AAGA,WAAK,aAAa;AAAA,IACpB,SAAS,OAAO;AAEd,eAAS,SAAS;AAClB,UAAI,KAAK,SAAS;AAChB,aAAK,OAAO,KAAK,6BAA6B,SAAS,EAAE,EAAE;AAAA,MAC7D;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,eAA8B;AACpC,WAAO,IAAI,QAAc,CAAC,SAAS,WAAW;AAE5C,UAAI,KAAK,MAAM,UAAU,KAAK,OAAO,cAAc;AACjD,eAAO,IAAI,MAAM,YAAY,CAAC;AAC9B;AAAA,MACF;AAGA,YAAM,OAAkB;AAAA,QACtB;AAAA,QACA;AAAA,QACA,UAAU,KAAK,IAAI;AAAA,MACrB;AACA,WAAK,MAAM,KAAK,IAAI;AAGpB,iBAAW,MAAM;AACf,cAAM,QAAQ,KAAK,MAAM,QAAQ,IAAI;AACrC,YAAI,UAAU,IAAI;AAChB,eAAK,MAAM,OAAO,OAAO,CAAC;AAC1B,iBAAO,IAAI,MAAM,eAAe,CAAC;AAAA,QACnC;AAAA,MACF,GAAG,KAAK,OAAO,YAAY;AAAA,IAC7B,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKQ,eAAqB;AAC3B,WAAO,KAAK,MAAM,SAAS,KAAK,KAAK,UAAU,SAAS,GAAG;AACzD,YAAM,OAAO,KAAK,MAAM,MAAM;AAG9B,YAAM,MAAM,KAAK,IAAI,IAAI,KAAK;AAC9B,UAAI,MAAM,KAAK,OAAO,cAAc;AAClC,aAAK,OAAO,IAAI,MAAM,eAAe,CAAC;AACtC;AAAA,MACF;AAGA,WAAK,QAAQ,EAAE,KAAK,KAAK,OAAO,EAAE,MAAM,KAAK,MAAM;AAAA,IACrD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,iBAAuB;AAC7B,SAAK,eAAe,YAAY,MAAM;AACpC,iBAAW,YAAY,KAAK,WAAW;AACrC,YAAI,SAAS,WAAW,UAAU,KAAK,cAAc,QAAQ,GAAG;AAC9D,eAAK,gBAAgB,QAAQ,EAAE,MAAM,MAAM;AAAA,UAAC,CAAC;AAAA,QAC/C;AAAA,MACF;AAAA,IACF,GAAG,KAAK,OAAO,oBAAoB;AAEnC,SAAK,aAAa,MAAM;AAAA,EAC1B;AAAA;AAAA;AAAA;AAAA,EAKQ,oBAA0B;AAChC,SAAK,cAAc,YAAY,YAAY;AACzC,YAAM,SAAS,MAAM,KAAK,YAAY;AACtC,UAAI,CAAC,OAAO,WAAW,OAAO,OAAO,SAAS,GAAG;AAC/C,gBAAQ,KAAK,gCAAgC,OAAO,MAAM;AAAA,MAC5D;AAAA,IACF,GAAG,KAAK,OAAO,mBAAmB;AAElC,SAAK,YAAY,MAAM;AAAA,EACzB;AACF;;;AnBrZA,IAAMC,UAAS,aAAa,QAAQ;AAiC7B,IAAM,eAAN,MAAmB;AAAA,EAChB,WAA4B;AAAA,EAC5B,OAA+B;AAAA,EAC/B,cAAc;AAAA,EACd,eAAqC;AAAA,EACrC,SAAS;AAAA,EACT;AAAA,EACA,aAAa;AAAA,EACb,iBAA+C;AAAA,EAEvD,YAAY,UAA+B,CAAC,GAAG;AAC7C,SAAK,UAAU;AAKf,UAAM,UAAU,QAAQ,uBAAuB;AAC/C,QAAI,SAAS;AACX,cAAQ,IAAI,sBAAsB;AAAA,IACpC;AAGA,SAAK,gBAAgB;AAAA,EACvB;AAAA;AAAA;AAAA;AAAA,EAKQ,eAAwC;AAC9C,UAAM,EAAE,SAAS,gBAAgB,cAAc,IAAI,KAAK;AAExD,QAAI,CAAC,WAAW,QAAQ,WAAW,GAAG;AACpC,aAAO;AAAA,IACT;AAEA,QAAI,kBAAkB,UAAU;AAC9B,aAAO,QAAQ,KAAK,MAAM,KAAK,OAAO,IAAI,QAAQ,MAAM,CAAC;AAAA,IAC3D;AAGA,UAAM,QAAQ,QAAQ,KAAK,aAAa,QAAQ,MAAM;AACtD,SAAK;AACL,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,QAAuB;AAC3B,QAAI,KAAK,QAAQ;AACf,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAGA,QAAI,KAAK,cAAc;AACrB,YAAM,KAAK;AACX;AAAA,IACF;AAEA,SAAK,eAAe,KAAK,eAAe;AACxC,UAAM,KAAK;AACX,SAAK,eAAe;AAAA,EACtB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,iBAAgC;AAC5C,QAAI;AACF,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,sBAAsB;AAAA,MACpC;AAEA,WAAK,WAAW,IAAI,SAAS;AAC7B,YAAM,KAAK,SAAS,MAAM;AAE1B,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,+BAA+B;AAAA,MAC7C;AAGA,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,8BAA8B;AAAA,MAC5C;AAEA,YAAM,oBAAoB,KAAK,QAAQ;AACvC,YAAM,aAAa;AAAA,QACjB,MAAM,mBAAmB,QAAQ;AAAA,QACjC,sBAAsB,mBAAmB,oBAAoB;AAAA,QAC7D,mBAAmB,mBAAmB,sBAAsB,MAAM,KAAK;AAAA,QACvE,cAAc,mBAAmB,gBAAgB;AAAA,MACnD;AAEA,WAAK,OAAO,IAAI;AAAA,QACd;AAAA,QACA;AAAA;AAAA,QACA,KAAK,QAAQ;AAAA,QACb,KAAK,iBAAiB;AAAA,QACtB;AAAA;AAAA,QACA,KAAK,QAAQ;AAAA,MACf;AACA,YAAM,KAAK,KAAK,WAAW;AAE3B,WAAK,cAAc;AAEnB,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,uCAAuC;AAAA,MACrD;AAAA,IACF,SAAS,OAAY;AAEnB,UAAI,KAAK,MAAM;AACb,cAAM,KAAK,KAAK,SAAS,EAAE,MAAM,MAAM;AAAA,QAAC,CAAC;AACzC,aAAK,OAAO;AAAA,MACd;AACA,UAAI,KAAK,UAAU;AACjB,cAAM,KAAK,SAAS,MAAM,EAAE,MAAM,MAAM;AAAA,QAAC,CAAC;AAC1C,aAAK,WAAW;AAAA,MAClB;AACA,WAAK,cAAc;AAGnB,YAAM,UAAU,MAAM,WAAW,OAAO,KAAK;AAE7C,UAAI,QAAQ,SAAS,YAAY,GAAG;AAClC,cAAM,IAAI;AAAA,UACR;AAAA,QAGF;AAAA,MACF;AAEA,UAAI,QAAQ,SAAS,QAAQ,KAAK,QAAQ,SAAS,QAAQ,GAAG;AAC5D,cAAM,IAAI;AAAA,UACR;AAAA,QAEF;AAAA,MACF;AAEA,YAAM,IAAI,MAAM,6BAA6B,OAAO,EAAE;AAAA,IACxD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,mBAAyC;AAC/C,QAAI,CAAC,KAAK,UAAU;AAClB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,UAAM,SAAS,IAAI,gBAAgB;AACnC,SAAK,SAAS,cAAc,OAAO,iBAAiB;AACpD,WAAO,IAAI,qBAAqB,OAAO,eAAe;AAAA,EACxD;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,oBAAmC;AAC/C,QAAI,KAAK,QAAQ;AACf,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,QAAI,CAAC,KAAK,aAAa;AACrB,YAAM,KAAK,MAAM;AAAA,IACnB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAcA,MAAM,OAAO,SAAkF;AAC7F,UAAM,KAAK,kBAAkB;AAE7B,QAAI,CAAC,KAAK,MAAM;AACd,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAGA,UAAM,QAAQ,QAAQ,SAAS,KAAK,aAAa;AAEjD,WAAO,MAAM,OAAO;AAAA,MAClB,GAAG;AAAA,MACH;AAAA,MACA,YAAY,QAAQ,cAAc,KAAK,QAAQ;AAAA,MAC/C,SAAS,QAAQ,WAAW,KAAK,QAAQ;AAAA,MACzC,MAAM,KAAK;AAAA,IACb,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAgBA,MAAM,MAAM,SAAgF;AAC1F,UAAM,KAAK,kBAAkB;AAE7B,QAAI,CAAC,KAAK,MAAM;AACd,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAGA,UAAM,QAAQ,QAAQ,SAAS,KAAK,aAAa;AAEjD,WAAO,MAAM,MAAM;AAAA,MACjB,GAAG;AAAA,MACH;AAAA,MACA,MAAM,KAAK;AAAA,IACb,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,UAAmB;AACjB,WAAO,KAAK,eAAe,CAAC,KAAK;AAAA,EACnC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAuB;AAC3B,QAAI,KAAK,QAAQ;AACf;AAAA,IACF;AAEA,SAAK,SAAS;AAGd,SAAK,sBAAsB;AAG3B,QAAI,KAAK,MAAM;AACb,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,+BAA+B;AAAA,MAC7C;AAEA,UAAI;AACF,cAAM,KAAK,KAAK,SAAS;AAAA,MAC3B,SAAS,OAAY;AACnB,YAAI,KAAK,QAAQ,SAAS;AACxB,UAAAA,QAAO,KAAK,6BAA6B,MAAM,OAAO,EAAE;AAAA,QAC1D;AAAA,MACF;AAEA,WAAK,OAAO;AAAA,IACd;AAGA,QAAI,KAAK,UAAU;AACjB,UAAI,KAAK,QAAQ,SAAS;AACxB,QAAAA,QAAO,KAAK,qBAAqB;AAAA,MACnC;AAEA,UAAI;AACF,cAAM,KAAK,SAAS,MAAM;AAE1B,cAAM,SAAS,SAAS;AAAA,MAC1B,SAAS,OAAY;AAEnB,YAAI,KAAK,QAAQ,SAAS;AACxB,UAAAA,QAAO,KAAK,2BAA2B,MAAM,OAAO,EAAE;AAAA,QACxD;AAAA,MACF;AAEA,WAAK,WAAW;AAAA,IAClB;AAEA,SAAK,cAAc;AAEnB,QAAI,KAAK,QAAQ,SAAS;AACxB,MAAAA,QAAO,KAAK,qBAAqB;AAAA,IACnC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,kBAAwB;AAC9B,SAAK,iBAAiB,YAAY;AAChC,YAAM,KAAK,MAAM;AAAA,IACnB;AAGA,YAAQ,KAAK,cAAc,KAAK,cAAc;AAC9C,YAAQ,KAAK,UAAU,YAAY;AACjC,YAAM,KAAK,iBAAiB;AAC5B,cAAQ,KAAK,CAAC;AAAA,IAChB,CAAC;AACD,YAAQ,KAAK,WAAW,YAAY;AAClC,YAAM,KAAK,iBAAiB;AAC5B,cAAQ,KAAK,CAAC;AAAA,IAChB,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKQ,wBAA8B;AACpC,QAAI,KAAK,gBAAgB;AACvB,cAAQ,eAAe,cAAc,KAAK,cAAc;AACxD,WAAK,iBAAiB;AAAA,IACxB;AAAA,EACF;AACF;;;AsB1XA,OAAO,UAAU;AAMjB,IAAMC,UAAS,aAAa,QAAQ;AAE7B,IAAM,sBAAsB;AACnC,IAAM,gBAAgB;AAoEf,IAAM,eAAN,MAAmB;AAAA,EAChB,SAA6B;AAAA,EAC7B,SAA8B;AAAA,EAC9B;AAAA,EACA,YAAoB;AAAA,EAE5B,YAAY,UAA+B,CAAC,GAAG;AAC7C,SAAK,UAAU;AAAA,MACb,MAAM,QAAQ,QAAQ;AAAA,MACtB,UAAU,QAAQ,YAAY;AAAA,MAC9B,SAAS,QAAQ,WAAW;AAAA,MAC5B,YAAY,QAAQ,cAAc;AAAA,IACpC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAuB;AAC3B,QAAI,KAAK,QAAQ;AACf,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC7C;AAGA,UAAM,gBAAqC;AAAA,MACzC,SAAS,KAAK,QAAQ;AAAA,MACtB,YAAY,KAAK,QAAQ;AAAA,MACzB,aAAa;AAAA,QACX,MAAM,KAAK,QAAQ;AAAA,MACrB;AAAA,IACF;AAEA,SAAK,SAAS,IAAI,aAAa,aAAa;AAC5C,UAAM,KAAK,OAAO,MAAM;AAGxB,SAAK,SAAS,KAAK,aAAa,KAAK,cAAc,KAAK,IAAI,CAAC;AAG7D,UAAM,IAAI,QAAc,CAAC,SAAS,WAAW;AAC3C,WAAK,OAAQ,OAAO,KAAK,QAAQ,MAAM,MAAM;AAC3C,aAAK,YAAY,KAAK,IAAI;AAC1B,YAAI,KAAK,QAAQ,SAAS;AACxB,UAAAA,QAAO,KAAK,0BAA0B,KAAK,QAAQ,IAAI,mBAAmB,KAAK,QAAQ,QAAQ,EAAE;AAAA,QACnG;AACA,gBAAQ;AAAA,MACV,CAAC;AAED,WAAK,OAAQ,GAAG,SAAS,CAAC,UAAiC;AACzD,YAAI,MAAM,SAAS,cAAc;AAC/B,iBAAO,IAAI,MAAM,QAAQ,KAAK,QAAQ,IAAI,gDAAgD,CAAC;AAAA,QAC7F,OAAO;AACL,iBAAO,KAAK;AAAA,QACd;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAGD,UAAM,KAAK,aAAa;AAAA,EAC1B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,OAAsB;AAC1B,QAAI,KAAK,QAAQ;AACf,YAAM,IAAI,QAAc,CAAC,YAAY;AACnC,aAAK,OAAQ,MAAM,MAAM,QAAQ,CAAC;AAAA,MACpC,CAAC;AACD,WAAK,SAAS;AAAA,IAChB;AAEA,QAAI,KAAK,QAAQ;AACf,YAAM,KAAK,OAAO,MAAM;AACxB,WAAK,SAAS;AAAA,IAChB;AAGA,UAAM,KAAK,cAAc;AAEzB,QAAI,KAAK,QAAQ,SAAS;AACxB,MAAAA,QAAO,KAAK,gBAAgB;AAAA,IAC9B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,UAAkB;AAChB,WAAO,KAAK,QAAQ;AAAA,EACtB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,cAAc,KAA2B,KAAyC;AAE9F,QAAI,IAAI,WAAW,UAAU,IAAI,QAAQ,KAAK;AAC5C,UAAI,UAAU,KAAK,EAAE,gBAAgB,mBAAmB,CAAC;AACzD,UAAI,IAAI,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,YAAY,CAAC,CAAC;AAC9D;AAAA,IACF;AAGA,QAAI,OAAO;AACX,qBAAiB,SAAS,KAAK;AAC7B,cAAQ;AAAA,IACV;AAEA,QAAI;AACJ,QAAI;AACF,gBAAU,KAAK,MAAM,IAAI;AAAA,IAC3B,QAAQ;AACN,WAAK,aAAa,KAAK,KAAK,EAAE,SAAS,OAAO,OAAO,eAAe,CAAC;AACrE;AAAA,IACF;AAGA,QAAI;AACF,cAAQ,QAAQ,QAAQ;AAAA,QACtB,KAAK;AACH,gBAAM,KAAK,aAAa,KAAK,QAAQ,OAAO;AAC5C;AAAA,QACF,KAAK;AACH,gBAAM,KAAK,YAAY,KAAK,QAAQ,OAAO;AAC3C;AAAA,QACF,KAAK;AACH,eAAK,aAAa,GAAG;AACrB;AAAA,QACF,KAAK;AACH,gBAAM,KAAK,eAAe,GAAG;AAC7B;AAAA,QACF;AACE,eAAK,aAAa,KAAK,KAAK,EAAE,SAAS,OAAO,OAAO,iBAAiB,CAAC;AAAA,MAC3E;AAAA,IACF,SAAS,OAAY;AACnB,WAAK,aAAa,KAAK,KAAK,EAAE,SAAS,OAAO,OAAO,MAAM,QAAQ,CAAC;AAAA,IACtE;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,aACZ,KACA,SACe;AACf,QAAI,CAAC,KAAK,QAAQ;AAChB,WAAK,aAAa,KAAK,KAAK,EAAE,SAAS,OAAO,OAAO,yBAAyB,CAAC;AAC/E;AAAA,IACF;AAEA,UAAM,SAAS,MAAM,KAAK,OAAO,OAAO,OAAO;AAC/C,SAAK,aAA2B,KAAK,KAAK,EAAE,SAAS,MAAM,MAAM,OAAO,CAAC;AAAA,EAC3E;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,YACZ,KACA,SACe;AACf,QAAI,CAAC,KAAK,QAAQ;AAChB,WAAK,aAAa,KAAK,KAAK,EAAE,SAAS,OAAO,OAAO,yBAAyB,CAAC;AAC/E;AAAA,IACF;AAEA,UAAM,SAAS,MAAM,KAAK,OAAO,MAAM,OAAO;AAC9C,SAAK,aAA0B,KAAK,KAAK,EAAE,SAAS,MAAM,MAAM,OAAO,CAAC;AAAA,EAC1E;AAAA;AAAA;AAAA;AAAA,EAKQ,aAAa,KAAgC;AACnD,UAAM,SAAuB;AAAA,MAC3B,SAAS;AAAA,MACT,MAAM,KAAK,QAAQ;AAAA,MACnB,UAAU,KAAK,QAAQ;AAAA,MACvB,QAAQ,KAAK,IAAI,IAAI,KAAK;AAAA,MAC1B,KAAK,QAAQ;AAAA,IACf;AACA,SAAK,aAA2B,KAAK,KAAK,EAAE,SAAS,MAAM,MAAM,OAAO,CAAC;AAAA,EAC3E;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,eAAe,KAAyC;AACpE,SAAK,aAAa,KAAK,KAAK,EAAE,SAAS,MAAM,MAAM,EAAE,SAAS,gBAAgB,EAAE,CAAC;AAGjF,eAAW,MAAM;AACf,WAAK,KAAK,EAAE,KAAK,MAAM,QAAQ,KAAK,CAAC,CAAC;AAAA,IACxC,GAAG,GAAG;AAAA,EACR;AAAA;AAAA;AAAA;AAAA,EAKQ,aAAgB,KAA0B,YAAoB,MAA+B;AACnG,QAAI,UAAU,YAAY,EAAE,gBAAgB,mBAAmB,CAAC;AAChE,QAAI,IAAI,KAAK,UAAU,IAAI,CAAC;AAAA,EAC9B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,eAA8B;AAC1C,UAAM,KAAK,MAAM,OAAO,aAAa;AACrC,UAAM,OAAO,MAAM,OAAO,MAAM;AAChC,UAAM,KAAK,MAAM,OAAO,IAAI;AAE5B,UAAM,UAAU,KAAK,KAAK,GAAG,OAAO,GAAG,aAAa;AACpD,UAAM,OAAO,KAAK,UAAU;AAAA,MAC1B,KAAK,QAAQ;AAAA,MACb,MAAM,KAAK,QAAQ;AAAA,MACnB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IACpC,CAAC;AAED,UAAM,GAAG,UAAU,SAAS,IAAI;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBAA+B;AAC3C,UAAM,KAAK,MAAM,OAAO,aAAa;AACrC,UAAM,OAAO,MAAM,OAAO,MAAM;AAChC,UAAM,KAAK,MAAM,OAAO,IAAI;AAE5B,UAAM,UAAU,KAAK,KAAK,GAAG,OAAO,GAAG,aAAa;AACpD,QAAI;AACF,YAAM,GAAG,OAAO,OAAO;AAAA,IACzB,QAAQ;AAAA,IAER;AAAA,EACF;AACF;AAKA,eAAsB,iBAAkC;AACtD,QAAM,OAAO,MAAM,OAAO,MAAM;AAChC,QAAM,KAAK,MAAM,OAAO,IAAI;AAC5B,SAAO,KAAK,KAAK,GAAG,OAAO,GAAG,aAAa;AAC7C;AAKA,eAAsB,gBAAkF;AACtG,QAAM,KAAK,MAAM,OAAO,aAAa;AACrC,QAAM,UAAU,MAAM,eAAe;AAErC,MAAI;AACF,UAAM,OAAO,MAAM,GAAG,SAAS,SAAS,OAAO;AAC/C,UAAM,OAAO,KAAK,MAAM,IAAI;AAG5B,QAAI;AACF,cAAQ,KAAK,KAAK,KAAK,CAAC;AACxB,aAAO;AAAA,IACT,QAAQ;AAEN,YAAM,GAAG,OAAO,OAAO,EAAE,MAAM,MAAM;AAAA,MAAC,CAAC;AACvC,aAAO;AAAA,IACT;AAAA,EACF,QAAQ;AACN,WAAO;AAAA,EACT;AACF;;;AC9VA,OAAOC,WAAU;AAmBV,IAAM,eAAN,MAAmB;AAAA,EAChB;AAAA,EAER,YAAY,UAA+B,CAAC,GAAG;AAC7C,SAAK,UAAU;AAAA,MACb,MAAM,QAAQ,QAAQ;AAAA,MACtB,WAAW,QAAQ,aAAa;AAAA;AAAA,IAClC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,OAAO,SAAyE;AACpF,WAAO,KAAK,QAAsB;AAAA,MAChC,QAAQ;AAAA,MACR;AAAA,IACF,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,MAAM,SAAuE;AACjF,WAAO,KAAK,QAAqB;AAAA,MAC/B,QAAQ;AAAA,MACR;AAAA,IACF,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAgC;AACpC,WAAO,KAAK,QAAsB;AAAA,MAChC,QAAQ;AAAA,IACV,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAA0B;AAC9B,UAAM,KAAK,QAA6B;AAAA,MACtC,QAAQ;AAAA,IACV,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,YAA8B;AAClC,QAAI;AACF,YAAM,KAAK,OAAO;AAClB,aAAO;AAAA,IACT,QAAQ;AACN,aAAO;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,QAAW,MAA0B;AAC3C,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,OAAO,KAAK,UAAU,IAAI;AAEhC,YAAM,MAAMC,MAAK;AAAA,QACf;AAAA,UACE,UAAU;AAAA,UACV,MAAM,KAAK,QAAQ;AAAA,UACnB,MAAM;AAAA,UACN,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,kBAAkB,OAAO,WAAW,IAAI;AAAA,UAC1C;AAAA,UACA,SAAS,KAAK,QAAQ;AAAA,QACxB;AAAA,QACA,CAAC,QAAQ;AACP,cAAI,eAAe;AAEnB,cAAI,GAAG,QAAQ,CAAC,UAAU;AACxB,4BAAgB;AAAA,UAClB,CAAC;AAED,cAAI,GAAG,OAAO,MAAM;AAClB,gBAAI;AACF,oBAAM,WAAW,KAAK,MAAM,YAAY;AAExC,kBAAI,SAAS,SAAS;AACpB,wBAAQ,SAAS,IAAI;AAAA,cACvB,OAAO;AACL,uBAAO,IAAI,MAAM,SAAS,SAAS,sBAAsB,CAAC;AAAA,cAC5D;AAAA,YACF,SAAS,OAAO;AACd,qBAAO,IAAI,MAAM,oCAAoC,YAAY,EAAE,CAAC;AAAA,YACtE;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAEA,UAAI,GAAG,SAAS,CAAC,UAAiC;AAChD,YAAI,MAAM,SAAS,gBAAgB;AACjC,iBAAO,IAAI,MAAM,oCAAoC,KAAK,QAAQ,IAAI,kBAAkB,CAAC;AAAA,QAC3F,OAAO;AACL,iBAAO,KAAK;AAAA,QACd;AAAA,MACF,CAAC;AAED,UAAI,GAAG,WAAW,MAAM;AACtB,YAAI,QAAQ;AACZ,eAAO,IAAI,MAAM,qCAAqC,KAAK,QAAQ,SAAS,IAAI,CAAC;AAAA,MACnF,CAAC;AAED,UAAI,MAAM,IAAI;AACd,UAAI,IAAI;AAAA,IACV,CAAC;AAAA,EACH;AACF;AAKA,eAAsB,gBAAgB,OAAe,qBAAuC;AAC1F,QAAM,SAAS,IAAI,aAAa,EAAE,MAAM,WAAW,IAAK,CAAC;AACzD,SAAO,OAAO,UAAU;AAC1B;;;AxBjIA,SAAS,cAAc,qBAAqB;AAC5C,SAAS,SAAS,YAAY;AAC9B,SAAS,qBAAqB;AAG9B,IAAM,YAAY,QAAQ,cAAc,YAAY,GAAG,CAAC;AACxD,IAAM,MAAM,KAAK,MAAM,aAAa,KAAK,WAAW,oBAAoB,GAAG,OAAO,CAAC;AAEnF,IAAM,UAAU,IAAI,QAAQ;AAE5B,QACG,KAAK,QAAQ,EACb;AAAA,EACC;AACF,EACC,QAAQ,IAAI,OAAO;AAMtB,QACG,QAAQ,OAAO,EACf,YAAY,gCAAgC,EAC5C,OAAO,kBAAkB,+BAA+B,mBAAmB,KAAK,OAAO,mBAAmB,CAAC,EAC3G,OAAO,mBAAmB,qBAAqB,GAAG,EAClD,OAAO,iBAAiB,oCAAoC,EAC5D,OAAO,iBAAiB,wBAAwB,EAChD,OAAO,OAAO,YAAY;AACzB,QAAM,OAAO,SAAS,QAAQ,MAAM,EAAE;AAGtC,MAAI,MAAM,gBAAgB,IAAI,GAAG;AAC/B,YAAQ,MAAM,4CAA4C,IAAI,EAAE;AAChE,YAAQ,KAAK,CAAC;AAAA,EAChB;AAEA,QAAM,SAAS,IAAI,aAAa;AAAA,IAC9B;AAAA,IACA,UAAU,SAAS,QAAQ,UAAU,EAAE;AAAA,IACvC,SAAS,QAAQ,WAAW;AAAA,IAC5B,YAAY,QAAQ,cAAc;AAAA,EACpC,CAAC;AAED,MAAI;AACF,UAAM,OAAO,MAAM;AACnB,YAAQ,IAAI,iCAAiC,IAAI,mBAAmB,QAAQ,QAAQ,EAAE;AACtF,YAAQ,IAAI,0CAA0C;AAGtD,YAAQ,GAAG,UAAU,YAAY;AAC/B,cAAQ,IAAI,2BAA2B;AACvC,YAAM,OAAO,KAAK;AAClB,cAAQ,KAAK,CAAC;AAAA,IAChB,CAAC;AAED,YAAQ,GAAG,WAAW,YAAY;AAChC,YAAM,OAAO,KAAK;AAClB,cAAQ,KAAK,CAAC;AAAA,IAChB,CAAC;AAAA,EACH,SAAS,OAAY;AACnB,YAAQ,MAAM,UAAU,MAAM,OAAO,EAAE;AACvC,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF,CAAC;AAEH,QACG,QAAQ,MAAM,EACd,YAAY,gCAAgC,EAC5C,OAAO,kBAAkB,yBAAyB,mBAAmB,KAAK,OAAO,mBAAmB,CAAC,EACrG,OAAO,OAAO,YAAY;AACzB,QAAM,OAAO,SAAS,QAAQ,MAAM,EAAE;AACtC,QAAM,SAAS,IAAI,aAAa,EAAE,KAAK,CAAC;AAExC,MAAI;AACF,QAAI,CAAE,MAAM,OAAO,UAAU,GAAI;AAC/B,cAAQ,IAAI,uBAAuB;AACnC;AAAA,IACF;AAEA,UAAM,OAAO,SAAS;AACtB,YAAQ,IAAI,gBAAgB;AAAA,EAC9B,SAAS,OAAY;AACnB,YAAQ,MAAM,UAAU,MAAM,OAAO,EAAE;AACvC,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF,CAAC;AAEH,QACG,QAAQ,QAAQ,EAChB,YAAY,qBAAqB,EACjC,OAAO,kBAAkB,yBAAyB,mBAAmB,KAAK,OAAO,mBAAmB,CAAC,EACrG,OAAO,OAAO,YAAY;AAEzB,QAAM,aAAa,MAAM,cAAc;AAEvC,MAAI,CAAC,YAAY;AACf,YAAQ,IAAI,uBAAuB;AACnC;AAAA,EACF;AAGA,QAAM,OAAO,QAAQ,OAAO,SAAS,QAAQ,MAAM,EAAE,IAAI,WAAW;AAGpE,QAAM,SAAS,IAAI,aAAa,EAAE,KAAK,CAAC;AACxC,MAAI;AACF,UAAM,SAAS,MAAM,OAAO,OAAO;AACnC,YAAQ,IAAI,oBAAoB;AAChC,YAAQ,IAAI,WAAW,OAAO,IAAI,EAAE;AACpC,YAAQ,IAAI,UAAU,OAAO,GAAG,EAAE;AAClC,YAAQ,IAAI,gBAAgB,OAAO,QAAQ,EAAE;AAC7C,YAAQ,IAAI,aAAa,KAAK,MAAM,OAAO,SAAS,GAAI,CAAC,GAAG;AAAA,EAC9D,QAAQ;AACN,YAAQ,IAAI,wCAAwC;AAAA,EACtD;AACF,CAAC;AAMH,QACG,QAAQ,kBAAkB,EAC1B,YAAY,yBAAyB,EACrC;AAAA,EACC;AAAA,EACA;AAAA,EACA;AACF,EACC,OAAO,uBAAuB,iCAAiC,EAC/D,OAAO,yBAAyB,qBAAqB,GAAG,EACxD,OAAO,sBAAsB,mCAAmC,OAAO,EACvE,OAAO,iBAAiB,8CAA8C,EACtE,OAAO,yBAAyB,0BAA0B,EAC1D,OAAO,wBAAwB,4CAA4C,QAAQ,EACnF,OAAO,iBAAiB,mCAAmC,EAC3D,OAAO,gBAAgB,uCAAuC,EAC9D,OAAO,kBAAkB,yBAAyB,mBAAmB,KAAK,OAAO,mBAAmB,CAAC,EACrG,OAAO,iBAAiB,wBAAwB,EAChD,OAAO,qBAAqB,qDAAqD,EACjF,OAAO,8BAA8B,yDAAyD,EAC9F,OAAO,8BAA8B,yDAAyD,EAC9F,OAAO,mBAAmB,iDAAiD,EAC3E,OAAO,yBAAyB,8DAA8D,EAC9F,OAAO,OAAO,MAAgB,YAAY;AACzC,QAAM,OAAO,SAAS,QAAQ,MAAM,EAAE;AACtC,QAAM,gBAAgB,QAAQ,cAAc;AAG5C,MAAI,YAAY;AAChB,MAAI,CAAC,eAAe;AAClB,gBAAY,MAAM,gBAAgB,IAAI;AACtC,QAAI,QAAQ,WAAW,WAAW;AAChC,cAAQ,MAAM,wBAAwB,IAAI,EAAE;AAAA,IAC9C;AAAA,EACF;AAGA,QAAM,eAAe,YAAY,IAAI,aAAa,EAAE,KAAK,CAAC,IAAI;AAC9D,QAAM,mBAAmB,CAAC,YACtB,IAAI,aAAa;AAAA,IACf,SAAS,QAAQ,WAAW;AAAA,IAC5B,YAAY,QAAQ,cAAc;AAAA,EACpC,CAAC,IACD;AAEJ,MAAI;AACF,UAAM,UAAU,QAAQ,OAAO,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC;AAGrE,UAAM,eAAe,CAAC,YAAY,MAAM;AACxC,eAAW,UAAU,SAAS;AAC5B,UAAI,CAAC,aAAa,SAAS,MAAM,GAAG;AAClC,gBAAQ;AAAA,UACN,0BAA0B,MAAM,qBAAqB,aAAa,KAAK,IAAI,CAAC;AAAA,QAC9E;AACA,gBAAQ,KAAK,CAAC;AAAA,MAChB;AAAA,IACF;AAEA,QAAI,QAAQ,SAAS;AACnB,cAAQ,MAAM,YAAY,KAAK,MAAM,YAAY;AACjD,cAAQ,MAAM,YAAY,QAAQ,KAAK,IAAI,CAAC,EAAE;AAAA,IAChD;AAGA,UAAM,cAAc,QAAQ,cACxB,QAAQ,YAAY,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,IAC1D;AACJ,UAAM,cAAc,QAAQ,cACxB,QAAQ,YAAY,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,IAC1D;AAGJ,UAAM,cAAc,QAAQ,aACxB,QAAQ,WAAW,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,IACzD;AAEJ,UAAM,gBAAgB;AAAA,MACpB;AAAA,MACA;AAAA,MACA,kBAAkB,SAAS,QAAQ,aAAa,EAAE;AAAA,MAClD,WAAW,SAAS,QAAQ,SAAS,EAAE;AAAA,MACvC,gBAAgB,SAAS,QAAQ,cAAc,EAAE;AAAA,MACjD,OAAO,QAAQ,QAAQ,EAAE,KAAK,QAAQ,MAAM,IAAI;AAAA,MAChD,WAAW,QAAQ;AAAA,MACnB,SAAS,QAAQ,WAAW;AAAA,MAC5B,YAAY,QAAQ,cAAc;AAAA;AAAA,MAElC,iBAAiB,QAAQ,gBAAgB;AAAA;AAAA,MACzC;AAAA,MACA;AAAA;AAAA,MAEA,aAAa,QAAQ;AAAA,MACrB;AAAA,MACA,YAAY,QAAQ,UAChB,CAAC,EAAE,WAAW,OAAO,WAAW,MAAgE;AAC9F,gBAAQ,MAAM,IAAI,SAAS,IAAI,KAAK,KAAK,UAAU,EAAE;AAAA,MACvD,IACA;AAAA,IACN;AAEA,UAAM,SAAS,YACX,MAAM,aAAc,OAAO,aAAa,IACxC,MAAM,iBAAkB,OAAO,aAAa;AAGhD,UAAM,SAAS,KAAK,UAAU,QAAQ,MAAM,CAAC;AAG7C,QAAI,QAAQ,QAAQ;AAClB,oBAAc,QAAQ,QAAQ,MAAM;AACpC,UAAI,QAAQ,SAAS;AACnB,gBAAQ,MAAM,qBAAqB,QAAQ,MAAM,EAAE;AAAA,MACrD;AAAA,IACF,OAAO;AACL,cAAQ,IAAI,MAAM;AAAA,IACpB;AAGA,QAAI,QAAQ,SAAS;AACnB,cAAQ,MAAM;AAAA,SAAY;AAC1B,cAAQ;AAAA,QACN,iBAAiB,OAAO,cAAc,cAAc,IAAI,OAAO,cAAc,SAAS;AAAA,MACxF;AACA,cAAQ,MAAM,eAAe,OAAO,cAAc,aAAa,IAAI;AAAA,IACrE;AAGA,QAAI,OAAO,cAAc,aAAa,GAAG;AACvC,cAAQ,KAAK,CAAC;AAAA,IAChB;AAAA,EACF,SAAS,OAAY;AACnB,YAAQ,MAAM,UAAU,MAAM,OAAO,EAAE;AACvC,YAAQ,KAAK,CAAC;AAAA,EAChB,UAAE;AACA,QAAI,kBAAkB;AACpB,YAAM,iBAAiB,MAAM;AAC7B,cAAQ,KAAK,CAAC;AAAA,IAChB;AAAA,EACF;AACF,CAAC;AAMH,QACG,QAAQ,aAAa,EACrB,YAAY,yDAAyD,EACrE,OAAO,mBAAmB,uBAAuB,GAAG,EACpD,OAAO,uBAAuB,6BAA6B,IAAI,EAC/D,OAAO,gBAAgB,yCAAyC,EAChE,OAAO,0BAA0B,kEAAkE,UAAU,EAC7G,OAAO,uBAAuB,iCAAiC,EAC/D,OAAO,gBAAgB,0CAA0C,MAAM,EACvE,OAAO,sBAAsB,mDAAmD,EAChF,OAAO,wBAAwB,iDAAiD,EAChF,OAAO,wBAAwB,iDAAiD,EAChF,OAAO,iBAAiB,8CAA8C,EACtE,OAAO,yBAAyB,0BAA0B,EAC1D,OAAO,iBAAiB,mCAAmC,EAC3D,OAAO,gBAAgB,uCAAuC,EAC9D,OAAO,kBAAkB,yBAAyB,mBAAmB,KAAK,OAAO,mBAAmB,CAAC,EACrG,OAAO,iBAAiB,wBAAwB,EAChD,OAAO,OAAO,KAAa,YAAY;AACtC,QAAM,OAAO,SAAS,QAAQ,MAAM,EAAE;AACtC,QAAM,gBAAgB,QAAQ,cAAc;AAG5C,MAAI,YAAY;AAChB,MAAI,CAAC,eAAe;AAClB,gBAAY,MAAM,gBAAgB,IAAI;AACtC,QAAI,QAAQ,WAAW,WAAW;AAChC,cAAQ,MAAM,wBAAwB,IAAI,EAAE;AAAA,IAC9C;AAAA,EACF;AAGA,QAAM,eAAe,YAAY,IAAI,aAAa,EAAE,KAAK,CAAC,IAAI;AAC9D,QAAM,mBAAmB,CAAC,YACtB,IAAI,aAAa;AAAA,IACf,SAAS,QAAQ,WAAW;AAAA,IAC5B,YAAY,QAAQ,cAAc;AAAA,EACpC,CAAC,IACD;AAEJ,MAAI;AACF,QAAI,QAAQ,SAAS;AACnB,cAAQ,MAAM,YAAY,GAAG,KAAK;AAClC,cAAQ,MAAM,cAAc,QAAQ,KAAK,gBAAgB,QAAQ,QAAQ,EAAE;AAAA,IAC7E;AAGA,UAAM,kBAAkB,QAAQ,UAC5B,QAAQ,QAAQ,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,IACtD;AACJ,UAAM,kBAAkB,QAAQ,UAC5B,QAAQ,QAAQ,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,IACtD;AAEJ,UAAM,eAAe;AAAA,MACnB;AAAA,MACA,OAAO,SAAS,QAAQ,OAAO,EAAE;AAAA,MACjC,UAAU,SAAS,QAAQ,UAAU,EAAE;AAAA,MACvC,QAAQ,QAAQ,UAAU;AAAA,MAC1B,SAAS,SAAS,QAAQ,OAAO,EAAE;AAAA,MACnC,WAAW,QAAQ,UAAU,SAAS,QAAQ,SAAS,EAAE,IAAI;AAAA,MAC7D;AAAA,MACA;AAAA,MACA,OAAO,QAAQ,QAAQ,EAAE,KAAK,QAAQ,MAAM,IAAI;AAAA,MAChD,WAAW,QAAQ;AAAA,MACnB,SAAS,QAAQ,WAAW;AAAA,MAC5B,YAAY,QAAQ,cAAc;AAAA,IACpC;AAGA,UAAM,UAAU,QAAQ,OAAO,MAAM,GAAG,EAAE,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC;AACrE,UAAM,0BAA0B;AAAA,MAC9B,GAAG;AAAA,MACH;AAAA,IACF;AAEA,UAAM,SAAS,YACX,MAAM,aAAc,MAAM,uBAAuB,IACjD,MAAM,iBAAkB,MAAM,uBAAuB;AAGzD,UAAM,SAAS,KAAK,UAAU,QAAQ,MAAM,CAAC;AAG7C,QAAI,QAAQ,QAAQ;AAClB,oBAAc,QAAQ,QAAQ,MAAM;AACpC,UAAI,QAAQ,SAAS;AACnB,gBAAQ,MAAM,qBAAqB,QAAQ,MAAM,EAAE;AAAA,MACrD;AAAA,IACF,OAAO;AACL,cAAQ,IAAI,MAAM;AAAA,IACpB;AAGA,QAAI,QAAQ,SAAS;AACnB,cAAQ,MAAM;AAAA,SAAY;AAC1B,cAAQ,MAAM,iBAAiB,OAAO,KAAK,MAAM,OAAO;AACxD,cAAQ,MAAM,eAAe,OAAO,SAAS,aAAa,IAAI;AAAA,IAChE;AAAA,EACF,SAAS,OAAY;AACnB,YAAQ,MAAM,UAAU,MAAM,OAAO,EAAE;AACvC,YAAQ,KAAK,CAAC;AAAA,EAChB,UAAE;AACA,QAAI,kBAAkB;AACpB,YAAM,iBAAiB,MAAM;AAC7B,cAAQ,KAAK,CAAC;AAAA,IAChB;AAAA,EACF;AACF,CAAC;AAMH,QAAQ,MAAM;","names":["parseHTML","URL","parseHTML","logger","MIN_CONTENT_LENGTH","logger","CLOUDFLARE_INFRA_PATTERNS","MIN_CONTENT_LENGTH","logger","normalizeUrl","logger","parseHTML","pLimit","parseHTML","logger","logger","http","http"]}